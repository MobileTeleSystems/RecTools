{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: will remove\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import torch\n",
    "import typing as tp\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from lightning_fabric import seed_everything\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from rectools import Columns, ExternalIds\n",
    "from rectools.dataset import Dataset\n",
    "from rectools.metrics import NDCG, Recall, Serendipity, calc_metrics\n",
    "\n",
    "from rectools.models import BERT4RecModel, SASRecModel\n",
    "from rectools.models.nn.item_net import IdEmbeddingsItemNet\n",
    "from rectools.models.nn.transformer_base import TransformerModelBase\n",
    "\n",
    "# Enable deterministic behaviour with CUDA >= 10.2\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_en.zip -O data_en.zip\n",
    "# !unzip -o data_en.zip\n",
    "# !rm data_en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52318, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  total_dur  watched_pct\n",
       "0   176549     9506 2021-05-11       4250         72.0\n",
       "1   699317     1659 2021-05-29       8317        100.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "DATA_PATH = Path(\"./data_en\")\n",
    "items = pd.read_csv(DATA_PATH / 'items_en.csv', index_col=0)\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "\n",
    "# TODO: for test\n",
    "unique_users = interactions[Columns.User].unique()[: 2_000]\n",
    "interactions = interactions[interactions[Columns.User].isin(unique_users)]\n",
    "\n",
    "print(interactions.shape)\n",
    "interactions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6179)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[Columns.User].nunique(), interactions[Columns.Item].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52318, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  weight\n",
       "0   176549     9506 2021-05-11       3\n",
       "1   699317     1659 2021-05-29       3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process interactions\n",
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "raw_interactions = interactions[[\"user_id\", \"item_id\", \"datetime\", \"weight\"]]\n",
    "print(raw_interactions.shape)\n",
    "raw_interactions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process item features\n",
    "# items = items.loc[items[Columns.Item].isin(raw_interactions[Columns.Item])].copy()\n",
    "# items[\"genre\"] = items[\"genres\"].str.lower().str.replace(\", \", \",\", regex=False).str.split(\",\")\n",
    "# genre_feature = items[[\"item_id\", \"genre\"]].explode(\"genre\")\n",
    "# genre_feature.columns = [\"id\", \"value\"]\n",
    "# genre_feature[\"feature\"] = \"genre\"\n",
    "# content_feature = items.reindex(columns=[Columns.Item, \"content_type\"])\n",
    "# content_feature.columns = [\"id\", \"value\"]\n",
    "# content_feature[\"feature\"] = \"content_type\"\n",
    "# item_features = pd.concat((genre_feature, content_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE=60\n",
    "torch.use_deterministic_algorithms(True)\n",
    "seed_everything(RANDOM_STATE, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(user_id_map=IdMap(external_ids=array([ 176549,  699317,  656683, ...,  465028, 1055957,  761297])), item_id_map=IdMap(external_ids=array([ 9506,  1659,  7107, ...,  9107, 13252, 13105])), interactions=Interactions(df=       user_id  item_id  weight   datetime\n",
       "0            0        0     3.0 2021-05-11\n",
       "1            1        1     3.0 2021-05-29\n",
       "2            2        2     1.0 2021-05-09\n",
       "3            3        3     3.0 2021-07-05\n",
       "4            4        0     3.0 2021-04-30\n",
       "...        ...      ...     ...        ...\n",
       "52313      754     3450     1.0 2021-03-23\n",
       "52314       73     1988     3.0 2021-07-16\n",
       "52315     1365     1921     3.0 2021-04-24\n",
       "52316      452     1456     3.0 2021-04-30\n",
       "52317      884     1610     3.0 2021-03-23\n",
       "\n",
       "[52318 rows x 4 columns]), user_features=None, item_features=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_no_features = Dataset.construct(raw_interactions)\n",
    "dataset_no_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir(model: TransformerModelBase) -> Path:\n",
    "    \"\"\"\n",
    "    Get logging directory.\n",
    "    \"\"\"\n",
    "    path = model.fit_trainer.log_dir\n",
    "    return Path(path) / \"metrics.csv\"\n",
    "\n",
    "\n",
    "def get_losses(epoch_metrics_df: pd.DataFrame, is_val: bool) -> pd.DataFrame:\n",
    "    loss_df = epoch_metrics_df[[\"epoch\", \"train/loss\"]].dropna()\n",
    "    if is_val:\n",
    "        val_loss_df = epoch_metrics_df[[\"epoch\", \"val/loss\"]].dropna()\n",
    "        loss_df = pd.merge(loss_df, val_loss_df, how=\"inner\", on=\"epoch\")\n",
    "    return loss_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_val_metrics(epoch_metrics_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    metrics_df = epoch_metrics_df.drop(columns=[\"train/loss\", \"val/loss\"]).dropna()\n",
    "    return metrics_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_log_values(model: TransformerModelBase, is_val: bool = False) -> tp.Tuple[pd.DataFrame, tp.Optional[pd.DataFrame]]:\n",
    "    log_path = get_log_dir(model)\n",
    "    epoch_metrics_df = pd.read_csv(log_path)\n",
    "\n",
    "    loss_df = get_losses(epoch_metrics_df, is_val)\n",
    "    val_metrics = None\n",
    "    if is_val:\n",
    "        val_metrics = get_val_metrics(epoch_metrics_df)\n",
    "    return loss_df, val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2205.04507"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Next Action**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from rectools.models.nn.transformer_data_preparator import SessionEncoderDataPreparatorBase\n",
    "\n",
    "\n",
    "class NextItemDataPreparator(SessionEncoderDataPreparatorBase):\n",
    "    \"\"\"Data preparator for SASRecModel.\"\"\"\n",
    "\n",
    "    train_session_max_len_addition: int = 1\n",
    "\n",
    "    def _collate_fn_train(\n",
    "        self,\n",
    "        batch: List[Tuple[List[int], List[float]]],\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Truncate each session from right to keep `session_max_len` items.\n",
    "        Do left padding until `session_max_len` is reached.\n",
    "        Split to `x`, `y`, and `yw`.\n",
    "        \"\"\"\n",
    "        batch_size = len(batch)\n",
    "        x = np.zeros((batch_size, self.session_max_len))\n",
    "        y = np.zeros((batch_size, 1))\n",
    "        yw = np.zeros((batch_size, 1))\n",
    "        for i, (ses, ses_weights) in enumerate(batch):\n",
    "            x[i, -len(ses) + 1 :] = ses[:-1]  # ses: [session_len] -> x[i]: [session_max_len]\n",
    "            y[i] = ses[-1]  # ses: [session_len] -> y[i]: [1]\n",
    "            yw[i] = ses_weights[-1]  # ses_weights: [session_len] -> yw[i]: [1]\n",
    "\n",
    "        batch_dict = {\"x\": torch.LongTensor(x), \"y\": torch.LongTensor(y), \"yw\": torch.FloatTensor(yw)}\n",
    "        if self.n_negatives is not None:\n",
    "            negatives = torch.randint(\n",
    "                low=self.n_item_extra_tokens,\n",
    "                high=self.item_id_map.size,\n",
    "                size=(batch_size, 1, self.n_negatives),\n",
    "            )  # [batch_size, 1, n_negatives]\n",
    "            batch_dict[\"negatives\"] = negatives\n",
    "        return batch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models.nn.transformer_base import SessionEncoderLightningModule\n",
    "\n",
    "\n",
    "class NextItemSessionEncoder(SessionEncoderLightningModule):\n",
    "\n",
    "    def training_step(self, batch: tp.Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        x, y, w = batch[\"x\"], batch[\"y\"], batch[\"yw\"]\n",
    "        if self.loss == \"softmax\":\n",
    "            logits = self._get_full_catalog_logits(x)[:, -1: :]\n",
    "            loss = self._calc_softmax_loss(logits, y, w)\n",
    "        elif self.loss == \"BCE\":\n",
    "            negatives = batch[\"negatives\"]\n",
    "            logits = self._get_pos_neg_logits(x, y, negatives)[:, -1: :]\n",
    "            loss = self._calc_bce_loss(logits, y, w)\n",
    "        elif self.loss == \"gBCE\":\n",
    "            negatives = batch[\"negatives\"]\n",
    "            logits = self._get_pos_neg_logits(x, y, negatives)[:, -1: :]\n",
    "            loss = self._calc_gbce_loss(logits, y, w, negatives)\n",
    "        else:\n",
    "            loss = self._calc_custom_loss(batch, batch_idx)\n",
    "\n",
    "        self.log(self.train_loss_name, loss, on_step=False, on_epoch=True, prog_bar=self.verbose > 0)\n",
    "\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models.nn.transformer_base import TransformerModelBase\n",
    "\n",
    "PADDING_VALUE = \"PAD\"\n",
    "\n",
    "\n",
    "class NextItemTransformer(TransformerModelBase):\n",
    "    # TODO: add to base model\n",
    "    def _init_data_preparator(self) -> None:\n",
    "        self.data_preparator: SessionEncoderDataPreparatorBase = self.data_preparator_type(\n",
    "            session_max_len=self.session_max_len,\n",
    "            n_negatives=self.n_negatives if self.loss != \"softmax\" else None,\n",
    "            batch_size=self.batch_size,\n",
    "            dataloader_num_workers=self.dataloader_num_workers,\n",
    "            train_min_user_interactions=self.train_min_user_interactions,\n",
    "            item_extra_tokens=(PADDING_VALUE,),\n",
    "            get_val_mask_func=self.get_val_mask_func,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_EPOCHS = 3\n",
    "MAX_EPOCHS = 3\n",
    "TRAIN_MIN_USER_INTERACTIONS = 5\n",
    "SESSION_MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "nextitem_trainer = Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=[0],\n",
    "    min_epochs=MIN_EPOCHS,\n",
    "    max_epochs=MAX_EPOCHS, \n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextitem_model = NextItemTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=nextitem_trainer,\n",
    "    data_preparator_type=NextItemDataPreparator,\n",
    "    lightning_module_type=NextItemSessionEncoder,\n",
    ")\n",
    "\n",
    "N_NEGATIVES = 5\n",
    "\n",
    "nextaction_bce_model = NextItemTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"BCE\",\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=nextitem_trainer,\n",
    "    data_preparator_type=NextItemDataPreparator,\n",
    "    lightning_module_type=NextItemSessionEncoder,\n",
    ")\n",
    "\n",
    "nextaction_gbce_model = NextItemTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"gBCE\",\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=nextitem_trainer,\n",
    "    data_preparator_type=NextItemDataPreparator,\n",
    "    lightning_module_type=NextItemSessionEncoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.684     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5fb121e0984120a6509ee788607bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 161 ms, total: 2.42 s\n",
      "Wall time: 1.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NextItemTransformer at 0x7f7c204e31c0>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nextitem_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.684     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187069a915ba47a8a937d545e67e4dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 81.7 ms, total: 2.14 s\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NextItemTransformer at 0x7f7c1bc07790>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nextaction_bce_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.684     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106bbbc4d1684bf3aef65d1d6dde8eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 143 ms, total: 2.38 s\n",
      "Wall time: 1.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NextItemTransformer at 0x7f7c1bc076a0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nextaction_gbce_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.713676</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1.622266</td>\n",
       "      <td>bce</td>\n",
       "      <td>0</td>\n",
       "      <td>1.490729</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.933022</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480650</td>\n",
       "      <td>bce</td>\n",
       "      <td>1</td>\n",
       "      <td>1.378032</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15.447347</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>1.133395</td>\n",
       "      <td>bce</td>\n",
       "      <td>2</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train/loss loss_type  epoch  train/loss loss_type  epoch  \\\n",
       "0      0   19.713676   softmax      0    1.622266       bce      0   \n",
       "1      1   16.933022   softmax      1    1.480650       bce      1   \n",
       "2      2   15.447347   softmax      2    1.133395       bce      2   \n",
       "\n",
       "   train/loss loss_type  \n",
       "0    1.490729      gbce  \n",
       "1    1.378032      gbce  \n",
       "2    1.052926      gbce  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_loss_df, _ = get_log_values(nextitem_model, is_val=False)\n",
    "softmax_loss_df[\"loss_type\"] = \"softmax\"\n",
    "bce_loss_df, _ = get_log_values(nextaction_bce_model, is_val=False)\n",
    "bce_loss_df[\"loss_type\"] = \"bce\"å\n",
    "gbce_loss_df, _ = get_log_values(nextaction_gbce_model, is_val=False)\n",
    "gbce_loss_df[\"loss_type\"] = \"gbce\"\n",
    "pd.concat([softmax_loss_df, bce_loss_df, gbce_loss_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextitem_model_with_casual_mask = NextItemTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=True,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=nextitem_trainer,\n",
    "    data_preparator_type=NextItemDataPreparator,\n",
    "    lightning_module_type=NextItemSessionEncoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.684     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca08d2e045c46eca946c7c21c0ed933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.49 s, sys: 65.6 ms, total: 2.56 s\n",
      "Wall time: 1.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NextItemTransformer at 0x7f7c28295e20>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nextitem_model_with_casual_mask.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.471478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.581562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15.517271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train/loss\n",
       "0      0   19.471478\n",
       "1      1   16.581562\n",
       "2      2   15.517271"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df, _ = get_log_values(nextitem_model_with_casual_mask, is_val=False)\n",
    "loss_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "session_max_len = 10\n",
    "train_session_max_len_addition = 1\n",
    "x = np.zeros((batch_size, session_max_len))\n",
    "y = np.zeros((batch_size, session_max_len))\n",
    "yw = np.zeros((batch_size, session_max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 16, 19, 19, 12, 10,  5, 11, 12,  7, 13],\n",
       "        [16, 18, 11, 16, 16, 15,  9, 19, 13,  3, 18],\n",
       "        [ 7, 17, 11,  3,  2, 12, 16, 14, 17, 14, 10],\n",
       "        [ 3,  6, 13, 11,  6, 14,  8,  4, 15,  4, 10],\n",
       "        [11,  4, 15, 16, 11, 12,  4, 16, 13, 15, 11],\n",
       "        [11,  3,  3, 13, 15, 12,  6, 19, 16,  8,  5],\n",
       "        [15,  6,  5,  2, 16, 19, 12, 12,  2, 14, 18],\n",
       "        [18,  8, 15,  7,  4,  4, 10,  5,  5,  5, 17],\n",
       "        [ 4,  3, 19,  5, 10, 13, 10, 15,  8, 17,  6],\n",
       "        [10,  9, 18, 15, 12,  5,  3, 18, 17, 15,  7]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses = torch.randint(2, 20, size=(batch_size, session_max_len + train_session_max_len_addition))\n",
    "ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11, 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-len(ses[0]), len(ses[0][2 :-train_session_max_len_addition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 16, 19, 19, 12, 10,  5, 11, 12,  7, 13])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses1 = ses[0]\n",
    "ses1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7., 16., 19., 19., 12., 10.,  5., 11., 12.,  7.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, -len(ses1) + 1 :] = ses1[: -1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 19., 19., 12., 10.,  5., 11., 12.,  7., 13.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, -len(ses1) + 1 :] = ses1[1:]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-len(ses1) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_ACTIONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K_ACTIONS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrectools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_data_preparator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SessionEncoderDataPreparatorBase\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAllActionDataPreparator\u001b[39;00m(SessionEncoderDataPreparatorBase):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Data preparator for SASRecModel.\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     train_session_max_len_addition: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m K_ACTIONS\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mAllActionDataPreparator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAllActionDataPreparator\u001b[39;00m(SessionEncoderDataPreparatorBase):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Data preparator for SASRecModel.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     train_session_max_len_addition: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mK_ACTIONS\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collate_fn_train\u001b[39m(\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     13\u001b[0m         batch: List[Tuple[List[\u001b[38;5;28mint\u001b[39m], List[\u001b[38;5;28mfloat\u001b[39m]]],\n\u001b[1;32m     14\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        Truncate each session from right to keep `session_max_len` items.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m        Do left padding until `session_max_len` is reached.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        Split to `x`, `y`, and `yw`.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K_ACTIONS' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from rectools.models.nn.transformer_data_preparator import SessionEncoderDataPreparatorBase\n",
    "\n",
    "\n",
    "class AllActionDataPreparator(SessionEncoderDataPreparatorBase):\n",
    "    \"\"\"Data preparator for SASRecModel.\"\"\"\n",
    "\n",
    "    train_session_max_len_addition: int = K_ACTIONS\n",
    "\n",
    "    def _collate_fn_train(\n",
    "        self,\n",
    "        batch: List[Tuple[List[int], List[float]]],\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Truncate each session from right to keep `session_max_len` items.\n",
    "        Do left padding until `session_max_len` is reached.\n",
    "        Split to `x`, `y`, and `yw`.\n",
    "        \"\"\"\n",
    "        batch_size = len(batch)\n",
    "        x = np.zeros((batch_size, self.session_max_len))\n",
    "        y = np.zeros((batch_size, self.train_session_max_len_addition))\n",
    "        yw = np.zeros((batch_size, self.train_session_max_len_addition))\n",
    "        for i, (ses, ses_weights) in enumerate(batch):\n",
    "            x[i, -len(ses) + self.train_session_max_len_addition :] = ses[: -self.train_session_max_len_addition]  # ses: [session_len] -> x[i]: [session_max_len]\n",
    "            y[i, -self.train_session_max_len_addition :] = ses[-self.train_session_max_len_addition :]  # ses: [session_len] -> y[i]: [train_session_max_len_addition]\n",
    "            yw[i, -self.train_session_max_len_addition :] = ses_weights[-self.train_session_max_len_addition :]  # ses_weights: [session_len] -> yw[i]: [train_session_max_len_addition]\n",
    "\n",
    "        batch_dict = {\"x\": torch.LongTensor(x), \"y\": torch.LongTensor(y), \"yw\": torch.FloatTensor(yw)}\n",
    "        if self.n_negatives is not None:\n",
    "            negatives = torch.randint(\n",
    "                low=self.n_item_extra_tokens,\n",
    "                high=self.item_id_map.size,\n",
    "                size=(batch_size, self.train_session_max_len_addition, self.n_negatives),\n",
    "            )  # [batch_size, train_session_max_len_addition, n_negatives]\n",
    "            batch_dict[\"negatives\"] = negatives\n",
    "        return batch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models.nn.transformer_base import SessionEncoderLightningModule\n",
    "\n",
    "\n",
    "class AllActionSessionEncoder(SessionEncoderLightningModule):\n",
    "\n",
    "    def training_step(self, batch: tp.Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        prediction_k_actions = self.data_preparator.train_session_max_len_addition\n",
    "\n",
    "        x, y, w = batch[\"x\"], batch[\"y\"], batch[\"yw\"]\n",
    "        if self.loss == \"softmax\":\n",
    "            logits = self._get_full_catalog_logits(x)[:, -1: :]\n",
    "            # [batch_size, prediction_k_actions, n_items]\n",
    "            repeated_logits = logits.repeat(1, 1, prediction_k_actions, 1).squeeze()\n",
    "            loss = self._calc_softmax_loss(repeated_logits, y, w)\n",
    "        elif self.loss == \"BCE\":\n",
    "            negatives = batch[\"negatives\"]\n",
    "            # [batch_size, prediction_k_actions, n_negatives + 1]\n",
    "            repeated_logits = self._get_pos_neg_logits(x, y, negatives, prediction_k_actions)\n",
    "            loss = self._calc_bce_loss(repeated_logits, y, w)\n",
    "        elif self.loss == \"gBCE\":\n",
    "            negatives = batch[\"negatives\"]\n",
    "            # [batch_size, prediction_k_actions, n_negatives + 1]\n",
    "            repeated_logits = self._get_pos_neg_logits(x, y, negatives, prediction_k_actions)\n",
    "            loss = self._calc_gbce_loss(repeated_logits, y, w, negatives)\n",
    "        else:\n",
    "            loss = self._calc_custom_loss(batch, batch_idx)\n",
    "\n",
    "        self.log(self.train_loss_name, loss, on_step=False, on_epoch=True, prog_bar=self.verbose > 0)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def _get_pos_neg_logits(self, x: torch.Tensor, y: torch.Tensor, negatives: torch.Tensor, prediction_k_actions: int) -> torch.Tensor:\n",
    "        # [n_items + n_item_extra_tokens, n_factors], [batch_size, session_max_len, n_factors]\n",
    "        item_embs, session_embs = self.torch_model(x)\n",
    "        # [batch_size, prediction_k_actions, n_factors]\n",
    "        encoded_sessions = session_embs[:, -1:, :].repeat(1, 1, prediction_k_actions, 1).squeeze()\n",
    "        pos_neg = torch.cat([y.unsqueeze(-1), negatives], dim=-1)  # [batch_size, prediction_k_actions, n_negatives + 1]\n",
    "        pos_neg_embs = item_embs[pos_neg]  # [batch_size, session_max_len, n_negatives + 1, n_factors]\n",
    "        # [batch_size, prediction_k_actions, n_negatives + 1]\n",
    "        logits = (pos_neg_embs @ encoded_sessions.unsqueeze(-1)).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models.nn.transformer_base import TransformerModelBase\n",
    "\n",
    "PADDING_VALUE = \"PAD\"\n",
    "\n",
    "\n",
    "class AllActionPredictionTransformer(TransformerModelBase):\n",
    "\n",
    "    def _init_data_preparator(self) -> None:\n",
    "        if self.session_max_len > self.data_preparator_type.train_session_max_len_addition:\n",
    "            self.data_preparator: SessionEncoderDataPreparatorBase = self.data_preparator_type(\n",
    "                session_max_len=self.session_max_len,\n",
    "                n_negatives=self.n_negatives if self.loss != \"softmax\" else None,\n",
    "                batch_size=self.batch_size,\n",
    "                dataloader_num_workers=self.dataloader_num_workers,\n",
    "                train_min_user_interactions=self.train_min_user_interactions,\n",
    "                item_extra_tokens=(PADDING_VALUE,),\n",
    "                get_val_mask_func=self.get_val_mask_func,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"`session_max_len` must be more than `train_session_max_len_addition`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_EPOCHS = 3\n",
    "MAX_EPOCHS = 3\n",
    "TRAIN_MIN_USER_INTERACTIONS = K_ACTIONS + 5\n",
    "SESSION_MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "allaction_trainer = Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=[0],\n",
    "    min_epochs=MIN_EPOCHS,\n",
    "    max_epochs=MAX_EPOCHS, \n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`session_max_len` must be more than `train_session_max_len_addition`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[346], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m allaction_model_raise \u001b[38;5;241m=\u001b[39m \u001b[43mAllActionPredictionTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_pos_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_min_user_interactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_MIN_USER_INTERACTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_max_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK_ACTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_causal_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_net_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIdEmbeddingsItemNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use only item ids in ItemNetBlock\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnextitem_trainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_preparator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAllActionDataPreparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlightning_module_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAllActionSessionEncoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m N_NEGATIVES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     23\u001b[0m allaction_bce_model \u001b[38;5;241m=\u001b[39m AllActionPredictionTransformer(\n\u001b[1;32m     24\u001b[0m     n_factors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     25\u001b[0m     n_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     lightning_module_type\u001b[38;5;241m=\u001b[39mAllActionSessionEncoder,\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/models/nn/transformer_base.py:664\u001b[0m, in \u001b[0;36mTransformerModelBase.__init__\u001b[0;34m(self, data_preparator_type, transformer_layers_type, n_blocks, n_heads, n_factors, use_pos_emb, use_causal_attn, use_key_padding_mask, dropout_rate, session_max_len, dataloader_num_workers, batch_size, loss, n_negatives, gbce_t, lr, epochs, verbose, deterministic, recommend_batch_size, recommend_accelerator, recommend_devices, recommend_n_threads, recommend_use_gpu_ranking, train_min_user_interactions, trainer, item_net_block_types, pos_encoding_type, lightning_module_type, get_val_mask_func, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_val_mask_func \u001b[38;5;241m=\u001b[39m get_val_mask_func\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_torch_model()\n\u001b[0;32m--> 664\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_data_preparator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_trainer()\n",
      "Cell \u001b[0;32mIn[343], line 20\u001b[0m, in \u001b[0;36mAllActionPredictionTransformer._init_data_preparator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preparator: SessionEncoderDataPreparatorBase \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preparator_type(\n\u001b[1;32m     11\u001b[0m         session_max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_max_len,\n\u001b[1;32m     12\u001b[0m         n_negatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_negatives \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         get_val_mask_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_val_mask_func,\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`session_max_len` must be more than `train_session_max_len_addition`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `session_max_len` must be more than `train_session_max_len_addition`"
     ]
    }
   ],
   "source": [
    "allaction_model_raise = AllActionPredictionTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=K_ACTIONS,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=allaction_trainer,\n",
    "    data_preparator_type=AllActionDataPreparator,\n",
    "    lightning_module_type=AllActionSessionEncoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "allaction_model = AllActionPredictionTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=allaction_trainer,\n",
    "    data_preparator_type=AllActionDataPreparator,\n",
    "    lightning_module_type=AllActionSessionEncoder,\n",
    ")\n",
    "\n",
    "\n",
    "N_NEGATIVES = 5\n",
    "\n",
    "allaction_bce_model = AllActionPredictionTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"BCE\",\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=nextitem_trainer,\n",
    "    data_preparator_type=AllActionDataPreparator,\n",
    "    lightning_module_type=AllActionSessionEncoder,\n",
    ")\n",
    "\n",
    "allaction_gbce_model = AllActionPredictionTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"gBCE\",\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=allaction_trainer,\n",
    "    data_preparator_type=AllActionDataPreparator,\n",
    "    lightning_module_type=AllActionSessionEncoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e19a285ad4a4175b9fb301dda314e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 102 ms, total: 2.65 s\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AllActionPredictionTransformer at 0x7f7c1167a3d0>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "allaction_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a42ef8a1bd44d496cf62a2f8c2d1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 66.7 ms, total: 1.97 s\n",
      "Wall time: 836 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AllActionPredictionTransformer at 0x7f7c1167a100>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "allaction_bce_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ffb2551b89466a8dd47e406bcf8dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 26.5 ms, total: 1.75 s\n",
      "Wall time: 871 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AllActionPredictionTransformer at 0x7f7c1167a430>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "allaction_gbce_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.867401</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>1.606314</td>\n",
       "      <td>bce</td>\n",
       "      <td>0</td>\n",
       "      <td>1.460153</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.023518</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>1.259503</td>\n",
       "      <td>bce</td>\n",
       "      <td>1</td>\n",
       "      <td>1.073478</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17.088499</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>0.901277</td>\n",
       "      <td>bce</td>\n",
       "      <td>2</td>\n",
       "      <td>0.642338</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train/loss loss_type  epoch  train/loss loss_type  epoch  \\\n",
       "0      0   19.867401   softmax      0    1.606314       bce      0   \n",
       "1      1   18.023518   softmax      1    1.259503       bce      1   \n",
       "2      2   17.088499   softmax      2    0.901277       bce      2   \n",
       "\n",
       "   train/loss loss_type  \n",
       "0    1.460153      gbce  \n",
       "1    1.073478      gbce  \n",
       "2    0.642338      gbce  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_loss_df, _ = get_log_values(allaction_model, is_val=False)\n",
    "softmax_loss_df[\"loss_type\"] = \"softmax\"\n",
    "bce_loss_df, _ = get_log_values(allaction_bce_model, is_val=False)\n",
    "bce_loss_df[\"loss_type\"] = \"bce\"\n",
    "gbce_loss_df, _ = get_log_values(allaction_gbce_model, is_val=False)\n",
    "gbce_loss_df[\"loss_type\"] = \"gbce\"\n",
    "pd.concat([softmax_loss_df, bce_loss_df, gbce_loss_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "allaction_model_casual = AllActionPredictionTransformer(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=True,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=allaction_trainer,\n",
    "    data_preparator_type=AllActionDataPreparator,\n",
    "    lightning_module_type=AllActionSessionEncoder,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 421 K \n",
      "---------------------------------------------------------------\n",
      "421 K     Trainable params\n",
      "0         Non-trainable params\n",
      "421 K     Total params\n",
      "1.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315afeacb1af42cab0f6b20548b2fd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 60.1 ms, total: 2.28 s\n",
      "Wall time: 796 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AllActionPredictionTransformer at 0x7f7c12c97be0>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "allaction_model_casual.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.867401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.023518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17.088499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train/loss\n",
       "0      0   19.867401\n",
       "1      1   18.023518\n",
       "2      2   17.088499"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df, _ = get_log_values(allaction_model, is_val=False)\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**without ItemNetConstructor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import typing_extensions as tpe\n",
    "import torch.nn as nn\n",
    "\n",
    "from rectools.models.nn.item_net import IdEmbeddingsItemNet, ItemNetBase, ItemNetConstructor\n",
    "from rectools.models.nn.transformer_data_preparator import SessionEncoderDataPreparatorBase\n",
    "from rectools.models import BERT4RecModel\n",
    "from rectools.models.nn.bert4rec import (\n",
    "    BERT4RecModelConfig, \n",
    "    BERT4RecDataPreparator,\n",
    "    PADDING_VALUE, \n",
    "    MASKING_VALUE,\n",
    ") \n",
    "from rectools.models.nn.item_net import CatFeaturesItemNet\n",
    "from rectools.models.nn.transformer_base import (\n",
    "    SessionEncoderLightningModule,\n",
    "    SessionEncoderLightningModuleBase,\n",
    "    TransformerBasedSessionEncoder\n",
    ")\n",
    "from rectools.models.nn.transformer_net_blocks import (\n",
    "    LearnableInversePositionalEncoding,\n",
    "    PreLNTransformerLayers,\n",
    "    PositionalEncodingBase,\n",
    "    TransformerLayersBase,\n",
    ")\n",
    "\n",
    "# TODO: add MLM Data n-gramm?\n",
    "\n",
    "\n",
    "class AlBertIdEmbeddingsItemNet(IdEmbeddingsItemNet):\n",
    "    \n",
    "    def __init__(self, n_factors: int, n_items: int, dropout_rate: float, emb_factors: int):\n",
    "        super().__init__(\n",
    "            n_factors=emb_factors,\n",
    "            n_items=n_items,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.fc_proj = nn.Linear(emb_factors, n_factors)\n",
    "\n",
    "    def forward(self, items: torch.Tensor) -> torch.Tensor:\n",
    "        item_embs = self.ids_emb(items.to(self.device))\n",
    "        item_proj = self.fc_proj(item_embs)\n",
    "        item_proj = self.drop_layer(item_proj)\n",
    "        return item_proj\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: Dataset, n_factors: int, dropout_rate: float, emb_factors: int) -> tpe.Self:\n",
    "        n_items = dataset.item_id_map.size\n",
    "        return cls(n_factors, n_items, dropout_rate, emb_factors)\n",
    "\n",
    "\n",
    "class AlBertItemNetConstructor(ItemNetConstructor):\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(\n",
    "        cls,\n",
    "        dataset: Dataset,\n",
    "        n_factors: int,\n",
    "        dropout_rate: float,\n",
    "        item_net_block_types: tp.Sequence[tp.Type[ItemNetBase]],\n",
    "        emb_factors: tp.Optional[int] = None,\n",
    "    ) -> tpe.Self:\n",
    "        \"\"\"\n",
    "        Construct ItemNet from RecTools dataset and from various blocks of item networks.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : Dataset\n",
    "            RecTools dataset.\n",
    "        n_factors : int\n",
    "            Latent embedding size of item embeddings.\n",
    "        dropout_rate : float\n",
    "            Probability of a hidden unit of item embedding to be zeroed.\n",
    "        item_net_block_types : sequence of `type(ItemNetBase)`\n",
    "            Sequence item network block types.\n",
    "        \"\"\"\n",
    "        n_items = dataset.item_id_map.size\n",
    "\n",
    "        item_net_blocks: tp.List[ItemNetBase] = []\n",
    "        for item_net in item_net_block_types:\n",
    "            # AlBert Embs only for Item ids.\n",
    "            if emb_factors is not None:\n",
    "                item_net_block = item_net.from_dataset(dataset, n_factors, dropout_rate, emb_factors)\n",
    "            else:\n",
    "                item_net_block = item_net.from_dataset(dataset, n_factors, dropout_rate)\n",
    "            if item_net_block is not None:\n",
    "                item_net_blocks.append(item_net_block)\n",
    "\n",
    "        return cls(n_items, item_net_blocks)    \n",
    "    # TODO: add `from_dataset_scheme`\n",
    "\n",
    "\n",
    "class AlBERTSessionEncoder(TransformerBasedSessionEncoder):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_blocks: int,\n",
    "        n_hidden_groups: int,\n",
    "        n_inner_groups: int,\n",
    "        n_factors: int,\n",
    "        emb_factors: int,\n",
    "        n_heads: int,\n",
    "        session_max_len: int,\n",
    "        dropout_rate: float,\n",
    "        use_pos_emb: bool = True,\n",
    "        use_causal_attn: bool = True,\n",
    "        use_key_padding_mask: bool = False,\n",
    "        transformer_layers_type: tp.Type[TransformerLayersBase] = PreLNTransformerLayers,\n",
    "        item_net_block_types: tp.Sequence[tp.Type[ItemNetBase]] = (IdEmbeddingsItemNet, CatFeaturesItemNet),\n",
    "        pos_encoding_type: tp.Type[PositionalEncodingBase] = LearnableInversePositionalEncoding,\n",
    "    ) -> None:\n",
    "        # TODO\n",
    "        # n_hidden_blocks = int(n_hidden_groups * n_inner_groups)\n",
    "        # self.n_hidden_blocks = n_blocks\n",
    "        # self.n_inner_groups = n_inner_groups\n",
    "        # self.n_layers_per_group = n_blocks / n_hidden_groups\n",
    "\n",
    "        super().__init__(\n",
    "            n_blocks=n_blocks,\n",
    "            n_factors=n_factors,\n",
    "            n_heads=n_heads,\n",
    "            session_max_len=session_max_len,\n",
    "            dropout_rate=dropout_rate,\n",
    "            use_pos_emb=use_pos_emb,\n",
    "            use_causal_attn=use_causal_attn,\n",
    "            use_key_padding_mask=use_key_padding_mask,\n",
    "            transformer_layers_type=transformer_layers_type,\n",
    "            item_net_block_types=item_net_block_types,\n",
    "            pos_encoding_type=pos_encoding_type,\n",
    "        )\n",
    "        del self.transformer_layers\n",
    "\n",
    "        self.transformer_layer_groups = nn.ModuleList(\n",
    "            [\n",
    "                transformer_layers_type(\n",
    "                    # number of encoder layer (AlBERTLayers)\n",
    "                    # https://github.com/huggingface/transformers/blob/main/src/transformers/models/albert/modeling_albert.py#L428\n",
    "                    n_blocks=n_inner_groups,\n",
    "                    n_factors=n_factors,\n",
    "                    n_heads=n_heads,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "                # number of hidden groups (same weights)  AlBERTLayerGroups\n",
    "                # https://github.com/huggingface/transformers/blob/main/src/transformers/models/albert/modeling_albert.py#L469\n",
    "                for _ in range(n_hidden_groups)\n",
    "            ]\n",
    "        )\n",
    "        self.n_blocks = n_blocks\n",
    "        self.emb_factors = emb_factors\n",
    "\n",
    "        self.n_layers_per_group = n_blocks / n_hidden_groups\n",
    "\n",
    "    def construct_item_net(self, dataset: Dataset) -> None:\n",
    "        \"\"\"\n",
    "        Construct network for item embeddings from dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : Dataset\n",
    "            RecTools dataset with user-item interactions.\n",
    "        \"\"\"\n",
    "        self.item_model = AlBertItemNetConstructor.from_dataset(\n",
    "            dataset, self.n_factors, self.dropout_rate, self.item_net_block_types, self.emb_factors\n",
    "        )\n",
    "\n",
    "    def encode_sessions(self, sessions: torch.Tensor, item_embs: torch.Tensor) -> torch.Tensor:\n",
    "        session_max_len = sessions.shape[1]\n",
    "        attn_mask = None\n",
    "        key_padding_mask = None\n",
    "\n",
    "        timeline_mask = (sessions != 0).unsqueeze(-1)  # [batch_size, session_max_len, 1]\n",
    "\n",
    "        seqs = item_embs[sessions]  # [batch_size, session_max_len, n_factors]\n",
    "        seqs = self.pos_encoding(seqs)\n",
    "        seqs = self.emb_dropout(seqs)\n",
    "\n",
    "        if self.use_causal_attn:\n",
    "            attn_mask = ~torch.tril(\n",
    "                torch.ones((session_max_len, session_max_len), dtype=torch.bool, device=sessions.device)\n",
    "            )\n",
    "        if self.use_key_padding_mask:\n",
    "            key_padding_mask = sessions == 0\n",
    "            if attn_mask is not None:  # merge masks to prevent nan gradients for torch < 2.5.0\n",
    "                attn_mask = self._merge_masks(attn_mask, key_padding_mask, seqs)\n",
    "                key_padding_mask = None\n",
    "\n",
    "        for layer_idx_in_group in range(self.n_blocks):\n",
    "            group_idx = int(layer_idx_in_group / self.n_layers_per_group)\n",
    "            # for layer_idx_in_inner_group in range(self.n_inner_groups): TODO\n",
    "            seqs = self.transformer_layer_groups[group_idx](seqs, timeline_mask, attn_mask, key_padding_mask)\n",
    "        return seqs\n",
    "\n",
    "\n",
    "class AlBERT4RecModelConfig(BERT4RecModelConfig):\n",
    "\n",
    "    n_hidden_groups: int = 1\n",
    "    n_inner_groups: int = 1\n",
    "\n",
    "\n",
    "class AlBERT4RecModel(BERT4RecModel):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/pdf/1909.11942\n",
    "    \"\"\"\n",
    "    \n",
    "    config_class = AlBERT4RecModelConfig\n",
    "\n",
    "    def __init__(  # pylint: disable=too-many-arguments, too-many-locals\n",
    "        self,\n",
    "        n_blocks: int = 2,\n",
    "        n_hidden_groups: int = 1,\n",
    "        n_inner_groups: int = 1,\n",
    "        n_heads: int = 4,\n",
    "        n_factors: int = 256,\n",
    "        emb_factors: int = 64,\n",
    "        use_pos_emb: bool = True,\n",
    "        use_causal_attn: bool = False,\n",
    "        use_key_padding_mask: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        epochs: int = 3,\n",
    "        verbose: int = 0,\n",
    "        deterministic: bool = False,\n",
    "        recommend_batch_size: int = 256,\n",
    "        recommend_accelerator: str = \"auto\",\n",
    "        recommend_devices: tp.Union[int, tp.List[int]] = 1,\n",
    "        recommend_n_threads: int = 0,\n",
    "        recommend_use_gpu_ranking: bool = True,\n",
    "        session_max_len: int = 100,\n",
    "        n_negatives: int = 1,\n",
    "        batch_size: int = 128,\n",
    "        loss: str = \"softmax\",\n",
    "        gbce_t: float = 0.2,\n",
    "        lr: float = 0.001,\n",
    "        dataloader_num_workers: int = 0,\n",
    "        train_min_user_interactions: int = 2,\n",
    "        mask_prob: float = 0.15,\n",
    "        trainer: tp.Optional[Trainer] = None,\n",
    "        item_net_block_types: tp.Sequence[tp.Type[ItemNetBase]] = (AlBertIdEmbeddingsItemNet, ),\n",
    "        pos_encoding_type: tp.Type[PositionalEncodingBase] = LearnableInversePositionalEncoding,\n",
    "        transformer_layers_type: tp.Type[TransformerLayersBase] = PreLNTransformerLayers,\n",
    "        data_preparator_type: tp.Type[SessionEncoderDataPreparatorBase] = BERT4RecDataPreparator,\n",
    "        lightning_module_type: tp.Type[SessionEncoderLightningModuleBase] = SessionEncoderLightningModule,\n",
    "        get_val_mask_func: tp.Optional[tp.Callable] = None,\n",
    "    ):\n",
    "        self.n_hidden_groups = n_hidden_groups\n",
    "        self.n_inner_groups = n_inner_groups\n",
    "        self.emb_factors = emb_factors\n",
    "\n",
    "        if n_blocks < n_hidden_groups:\n",
    "            warnings.warn(\n",
    "                \"When `n_hidden_groups` less than `n_blocks` that will use in the forward only one hidden group.\"\n",
    "            ) \n",
    "\n",
    "        super().__init__(\n",
    "            transformer_layers_type=transformer_layers_type,\n",
    "            data_preparator_type=data_preparator_type,\n",
    "            n_blocks=n_blocks,\n",
    "            n_heads=n_heads,\n",
    "            n_factors=n_factors,\n",
    "            use_pos_emb=use_pos_emb,\n",
    "            use_causal_attn=use_causal_attn,\n",
    "            use_key_padding_mask=use_key_padding_mask,\n",
    "            dropout_rate=dropout_rate,\n",
    "            session_max_len=session_max_len,\n",
    "            dataloader_num_workers=dataloader_num_workers,\n",
    "            batch_size=batch_size,\n",
    "            loss=loss,\n",
    "            n_negatives=n_negatives,\n",
    "            gbce_t=gbce_t,\n",
    "            lr=lr,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose,\n",
    "            deterministic=deterministic,\n",
    "            recommend_batch_size=recommend_batch_size,\n",
    "            recommend_accelerator=recommend_accelerator,\n",
    "            recommend_devices=recommend_devices,\n",
    "            recommend_n_threads=recommend_n_threads,\n",
    "            recommend_use_gpu_ranking=recommend_use_gpu_ranking,\n",
    "            train_min_user_interactions=train_min_user_interactions,\n",
    "            mask_prob=mask_prob,\n",
    "            trainer=trainer,\n",
    "            item_net_block_types=item_net_block_types,\n",
    "            pos_encoding_type=pos_encoding_type,\n",
    "            lightning_module_type=lightning_module_type,\n",
    "            get_val_mask_func=get_val_mask_func,\n",
    "        )\n",
    "\n",
    "    # def _init_data_preparator(self) -> None:\n",
    "    #     self.data_preparator: SessionEncoderDataPreparatorBase = self.data_preparator_type(\n",
    "    #         session_max_len=self.session_max_len,\n",
    "    #         n_negatives=self.n_negatives if self.loss != \"softmax\" else None,\n",
    "    #         batch_size=self.batch_size,\n",
    "    #         dataloader_num_workers=self.dataloader_num_workers,\n",
    "    #         train_min_user_interactions=self.train_min_user_interactions,\n",
    "    #         item_extra_tokens=(PADDING_VALUE, MASKING_VALUE),\n",
    "    #         mask_prob=self.mask_prob,\n",
    "    #         get_val_mask_func=self.get_val_mask_func,\n",
    "    #     )\n",
    "    \n",
    "    def _init_torch_model(self) -> None:\n",
    "        self._torch_model = AlBERTSessionEncoder(\n",
    "            n_blocks=self.n_blocks,\n",
    "            n_hidden_groups=self.n_hidden_groups,\n",
    "            n_inner_groups=self.n_inner_groups,\n",
    "            n_factors=self.n_factors,\n",
    "            emb_factors=self.emb_factors,\n",
    "            n_heads=self.n_heads,\n",
    "            session_max_len=self.session_max_len,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_pos_emb=self.use_pos_emb,\n",
    "            use_causal_attn=self.use_causal_attn,\n",
    "            use_key_padding_mask=self.use_key_padding_mask,\n",
    "            transformer_layers_type=self.transformer_layers_type,\n",
    "            item_net_block_types=self.item_net_block_types,\n",
    "            pos_encoding_type=self.pos_encoding_type,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "MIN_EPOCHS = 3\n",
    "MAX_EPOCHS = 3\n",
    "TRAIN_MIN_USER_INTERACTIONS = K_ACTIONS + 5\n",
    "SESSION_MAX_LEN = 50\n",
    "N_NEGATIVES = 5\n",
    "\n",
    "albert_trainer = Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=[0],\n",
    "    min_epochs=MIN_EPOCHS,\n",
    "    max_epochs=MAX_EPOCHS, \n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_model = AlBERT4RecModel(\n",
    "    n_factors=64,\n",
    "    emb_factors=16,\n",
    "    n_blocks=4,\n",
    "    n_hidden_groups=2,\n",
    "    n_inner_groups=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(AlBertIdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=albert_trainer,\n",
    ")\n",
    "\n",
    "\n",
    "N_NEGATIVES = 5\n",
    "\n",
    "albert_model_bce = AlBERT4RecModel(\n",
    "    n_factors=64,\n",
    "    emb_factors=16,\n",
    "    n_blocks=4,\n",
    "    n_hidden_groups=2,\n",
    "    n_inner_groups=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"BCE\",\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(AlBertIdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=albert_trainer,\n",
    ")\n",
    "\n",
    "albert_model_gbce = AlBERT4RecModel(\n",
    "    n_factors=64,\n",
    "    emb_factors=16,\n",
    "    n_blocks=4,\n",
    "    n_hidden_groups=2,\n",
    "    n_inner_groups=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    use_causal_attn=False,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"gBCE\",\n",
    "    n_negatives=N_NEGATIVES,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(AlBertIdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=albert_trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                 | Params\n",
      "-----------------------------------------------------\n",
      "0 | torch_model | AlBERTSessionEncoder | 282 K \n",
      "-----------------------------------------------------\n",
      "282 K     Trainable params\n",
      "0         Non-trainable params\n",
      "282 K     Total params\n",
      "1.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910cfe451b1d40978a8f3f773e2a114f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 58 ms, total: 3.02 s\n",
      "Wall time: 1.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AlBERT4RecModel at 0x7fdde79717f0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "albert_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                 | Params\n",
      "-----------------------------------------------------\n",
      "0 | torch_model | AlBERTSessionEncoder | 282 K \n",
      "-----------------------------------------------------\n",
      "282 K     Trainable params\n",
      "0         Non-trainable params\n",
      "282 K     Total params\n",
      "1.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adbae48bc0d41518a2f9d12b23586c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 s, sys: 42.4 ms, total: 4.69 s\n",
      "Wall time: 1.85 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AlBERT4RecModel at 0x7fddfad60c40>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "albert_model_bce.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/../../rectools/dataset/identifiers.py:60: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  unq_values = pd.unique(values)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                 | Params\n",
      "-----------------------------------------------------\n",
      "0 | torch_model | AlBERTSessionEncoder | 282 K \n",
      "-----------------------------------------------------\n",
      "282 K     Trainable params\n",
      "0         Non-trainable params\n",
      "282 K     Total params\n",
      "1.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fda2609a464d4eb08c5aaa39e604a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 54.9 ms, total: 4.62 s\n",
      "Wall time: 1.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.AlBERT4RecModel at 0x7fdde7971070>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "albert_model_gbce.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>loss_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23.841927</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0</td>\n",
       "      <td>3.703355</td>\n",
       "      <td>bce</td>\n",
       "      <td>0</td>\n",
       "      <td>2.883951</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22.312714</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>2.293790</td>\n",
       "      <td>bce</td>\n",
       "      <td>1</td>\n",
       "      <td>1.834833</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21.233828</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>1.843714</td>\n",
       "      <td>bce</td>\n",
       "      <td>2</td>\n",
       "      <td>1.557601</td>\n",
       "      <td>gbce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train/loss loss_type  epoch  train/loss loss_type  epoch  \\\n",
       "0      0   23.841927   softmax      0    3.703355       bce      0   \n",
       "1      1   22.312714   softmax      1    2.293790       bce      1   \n",
       "2      2   21.233828   softmax      2    1.843714       bce      2   \n",
       "\n",
       "   train/loss loss_type  \n",
       "0    2.883951      gbce  \n",
       "1    1.834833      gbce  \n",
       "2    1.557601      gbce  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_loss_df, _ = get_log_values(albert_model, is_val=False)\n",
    "softmax_loss_df[\"loss_type\"] = \"softmax\"\n",
    "bce_loss_df, _ = get_log_values(albert_model_bce, is_val=False)\n",
    "bce_loss_df[\"loss_type\"] = \"bce\"\n",
    "gbce_loss_df, _ = get_log_values(albert_model_gbce, is_val=False)\n",
    "gbce_loss_df[\"loss_type\"] = \"gbce\"\n",
    "pd.concat([softmax_loss_df, bce_loss_df, gbce_loss_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreLNTransformerLayers(\n",
       "  (multi_head_attn): ModuleList(\n",
       "    (0-3): 4 x MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm_1): ModuleList(\n",
       "    (0-3): 4 x LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout_1): ModuleList(\n",
       "    (0-3): 4 x Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer_norm_2): ModuleList(\n",
       "    (0-3): 4 x LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (feed_forward): ModuleList(\n",
       "    (0-3): 4 x PointWiseFeedForward(\n",
       "      (ff_linear_1): Linear(in_features=8, out_features=32, bias=True)\n",
       "      (ff_dropout_1): Dropout(p=0, inplace=False)\n",
       "      (ff_activation): GELU(approximate='none')\n",
       "      (ff_linear_2): Linear(in_features=32, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout_2): ModuleList(\n",
       "    (0-3): 4 x Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (dropout_3): ModuleList(\n",
       "    (0-3): 4 x Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = PreLNTransformerLayers(\n",
    "    n_blocks=4, n_factors=8, n_heads=8, dropout_rate=0\n",
    ")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
