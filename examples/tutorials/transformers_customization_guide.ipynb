{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Models Customization Guide\n",
    "\n",
    "RecTools provides many options to change any part of the model with custom modules: from training objective to special transformer layers logic. Current guide provides just a few examples of the various customizations that can be done.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* Prepare data\n",
    "* \"Next Action\" training objective from Pinnerformer\n",
    "    - Custom data preparator and lightning module\n",
    "    - Create `NextActionTransformer`\n",
    "    - Enable unidirectional attention\n",
    "* Albert\n",
    "    - Custom transformer layers and item net constructor\n",
    "    - Pass Albert modules to `BERT4RecModel`\n",
    "    - Pass Albert modules to `SASRecModel`\n",
    "* How about `NextActionTransformer` with Albert logic and causal attention?\n",
    "    - Combining custom modules together\n",
    "* Configs support for custom models\n",
    "* Full list of customization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as tp\n",
    "import typing_extensions as tpe\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from lightning_fabric import seed_everything\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.dataset import Dataset\n",
    "from rectools.models import BERT4RecModel, SASRecModel\n",
    "from rectools.dataset.dataset import DatasetSchema\n",
    "from rectools.models.nn.item_net import (\n",
    "    ItemNetBase,\n",
    "    SumOfEmbeddingsConstructor,\n",
    ")\n",
    "from rectools.models.nn.transformers.net_blocks import (\n",
    "    PreLNTransformerLayer,\n",
    "    TransformerLayersBase,\n",
    ")\n",
    "from rectools.models.nn.transformers.constants import MASKING_VALUE\n",
    "from rectools.models.nn.transformers.bert4rec import BERT4RecDataPreparator\n",
    "from rectools.models.nn.transformers.lightning import TransformerLightningModule\n",
    "\n",
    "# Enable deterministic behaviour with CUDA >= 10.2\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_original\")\n",
    "\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": \"datetime\"})\n",
    ")\n",
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "dataset = Dataset.construct(\n",
    "    interactions_df=interactions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE=60\n",
    "torch.use_deterministic_algorithms(True)\n",
    "seed_everything(RANDOM_STATE, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get custom trainer\n",
    "def get_debug_trainer() -> Trainer:\n",
    "    return Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        devices=1,\n",
    "        min_epochs=1,\n",
    "        max_epochs=1,\n",
    "        deterministic=True,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "        limit_train_batches=2,  # limit train batches for quick debug runs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Next Action\" training objective from Pinnerformer\n",
    "[PinnerFormer: Sequence Modeling for User Representation at Pinterest](https://arxiv.org/pdf/2205.04507)\n",
    "\n",
    "This training objective aims to predict the most recent action for each user. Thus only one target should be taken from each user sequence.\n",
    "\n",
    "We will take BERT4RecModel as our base class and just change one single detail in data preparation: let's put \"MASK\" token replacing the last position of each user sequence. Everything else will work out of the box.\n",
    "\n",
    "For computational efficiency we will return `y` and `yw` (and `negatives`) in the shape of `(batch_size, 1)` instead of `(batch_size, session_max_len)`.\n",
    "To process this reshaped batch correctly during training we will also rewrite training step in lightning module.\n",
    "\n",
    "We could have filled `y` and `yw` with zeros except for the last target item. This way trainig step should have been left unchanged. But it's less efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data preparator and lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextActionDataPreparator(BERT4RecDataPreparator):\n",
    "    \n",
    "    def _collate_fn_train(\n",
    "        self,\n",
    "        batch: tp.List[tp.Tuple[tp.List[int], tp.List[float]]],\n",
    "    ) -> tp.Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Truncate each session from right to keep `session_max_len` items.\n",
    "        Do left padding until `session_max_len` is reached.\n",
    "        Split to `x`, `y`, and `yw`.\n",
    "        \"\"\"\n",
    "        batch_size = len(batch)\n",
    "        x = np.zeros((batch_size, self.session_max_len))\n",
    "        y = np.zeros((batch_size, 1))\n",
    "        yw = np.zeros((batch_size, 1))\n",
    "        for i, (ses, ses_weights) in enumerate(batch):\n",
    "            session = ses.copy()\n",
    "            session[-1] = self.extra_token_ids[MASKING_VALUE]  # Replace last token with \"MASK\"\n",
    "            x[i, -len(ses) :] = session\n",
    "            y[i] = ses[-1]\n",
    "            yw[i] = ses_weights[-1]\n",
    "\n",
    "        batch_dict = {\"x\": torch.LongTensor(x), \"y\": torch.LongTensor(y), \"yw\": torch.FloatTensor(yw)}\n",
    "        if self.n_negatives is not None:\n",
    "            negatives = torch.randint(\n",
    "                low=self.n_item_extra_tokens,\n",
    "                high=self.item_id_map.size,\n",
    "                size=(batch_size, 1, self.n_negatives),\n",
    "            )\n",
    "            batch_dict[\"negatives\"] = negatives\n",
    "        return batch_dict\n",
    "\n",
    "\n",
    "class NextActionLightningModule(TransformerLightningModule):\n",
    "\n",
    "    def training_step(self, batch: tp.Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        x, y, w = batch[\"x\"], batch[\"y\"], batch[\"yw\"]\n",
    "        if self.loss == \"softmax\":\n",
    "            logits = self._get_full_catalog_logits(x)[:, -1: :]  # take only token last hidden state\n",
    "            loss = self._calc_softmax_loss(logits, y, w)\n",
    "        elif self.loss == \"BCE\":\n",
    "            negatives = batch[\"negatives\"]\n",
    "            logits = self._get_pos_neg_logits(x, y, negatives)[:, -1: :]  # take only last token hidden state\n",
    "            loss = self._calc_bce_loss(logits, y, w)\n",
    "        elif self.loss == \"gBCE\":\n",
    "            negatives = batch[\"negatives\"]\n",
    "            logits = self._get_pos_neg_logits(x, y, negatives)[:, -1: :]  # take only last token hidden state\n",
    "            loss = self._calc_gbce_loss(logits, y, w, negatives)\n",
    "        else:\n",
    "            loss = self._calc_custom_loss(batch, batch_idx)\n",
    "\n",
    "        self.log(self.train_loss_name, loss, on_step=False, on_epoch=True, prog_bar=self.verbose > 0)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `NextActionTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.transformers.bert4rec.BERT4RecModel at 0x7fa8bad34b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_action_model = BERT4RecModel(\n",
    "    data_preparator_type=NextActionDataPreparator,\n",
    "    lightning_module_type=NextActionLightningModule,\n",
    "    get_trainer_func = get_debug_trainer,\n",
    ")\n",
    "\n",
    "next_action_model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable unidirectional attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.transformers.bert4rec.BERT4RecModel at 0x7fa7498c83a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_action_model_causal = BERT4RecModel(\n",
    "    data_preparator_type=NextActionDataPreparator,\n",
    "    lightning_module_type=NextActionLightningModule,\n",
    "    get_trainer_func = get_debug_trainer,\n",
    "    use_causal_attn = True,  # simple flag\n",
    ")\n",
    "\n",
    "next_action_model_causal.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALBERT\n",
    "[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)\n",
    "\n",
    "Albert has two parameter-reduction techniques to lower memory consumption and increase the training speed which can actually be used together or separately:\n",
    "1. Learning embeddings of smaller size and then projecting them to the required size through a Liner projection (\"Factorized embedding parameterization\")\n",
    "2. Sharing weights between transformer layers (\"Cross-layer parameter sharing\")\n",
    "\n",
    "We will implement both techiques in custom classes for transformer layers and for item net constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom item net constructor and transformer layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Albert logic for embeddings - Factorized embedding parameterization\n",
    "\n",
    "class AlBERT4RecSumOfEmbeddingsConstructor(SumOfEmbeddingsConstructor):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_items: int,\n",
    "        n_factors: int,\n",
    "        item_net_blocks: tp.Sequence[ItemNetBase],\n",
    "        emb_factors: int = 16,  # accept new kwarg for lower dimensional space size\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            n_items=n_items,\n",
    "            item_net_blocks=item_net_blocks,\n",
    "        )\n",
    "        self.item_emb_proj = nn.Linear(emb_factors, n_factors)  # Project to actual required hidden space\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(\n",
    "        cls,\n",
    "        dataset: Dataset,\n",
    "        n_factors: int,\n",
    "        dropout_rate: float,\n",
    "        item_net_block_types: tp.Sequence[tp.Type[ItemNetBase]],\n",
    "        emb_factors: int,  # accept new kwarg for lower dimensional space size\n",
    "    ) -> tpe.Self:\n",
    "        n_items = dataset.item_id_map.size\n",
    "\n",
    "        item_net_blocks: tp.List[ItemNetBase] = []\n",
    "        for item_net in item_net_block_types:\n",
    "            # Item net blocks will work in lower dimensional space\n",
    "            item_net_block = item_net.from_dataset(dataset, emb_factors, dropout_rate)\n",
    "            if item_net_block is not None:\n",
    "                item_net_blocks.append(item_net_block)\n",
    "\n",
    "        return cls(n_items, n_factors, item_net_blocks, emb_factors)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset_schema(\n",
    "        cls,\n",
    "        dataset_schema: DatasetSchema,\n",
    "        n_factors: int,\n",
    "        dropout_rate: float,\n",
    "        item_net_block_types: tp.Sequence[tp.Type[ItemNetBase]],\n",
    "        emb_factors: int,  # accept new kwarg for lower dimensional space size\n",
    "    ) -> tpe.Self:\n",
    "        n_items = dataset_schema.items.n_hot\n",
    "\n",
    "        item_net_blocks: tp.List[ItemNetBase] = []\n",
    "        for item_net in item_net_block_types:\n",
    "            item_net_block = item_net.from_dataset_schema(dataset_schema, emb_factors, dropout_rate)\n",
    "            if item_net_block is not None:\n",
    "                item_net_blocks.append(item_net_block)\n",
    "\n",
    "        return cls(n_items, n_factors, item_net_blocks, emb_factors)\n",
    "\n",
    "    def forward(self, items: torch.Tensor) -> torch.Tensor:\n",
    "        item_embs = super().forward(items)  # Create embeddings in lower dimensional space\n",
    "        item_embs = self.item_emb_proj(item_embs)  # Project to actual required hidden space\n",
    "        return item_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Albert logic for transformer layers - Cross-layer parameter sharing\n",
    "    \n",
    "class AlBERT4RecPreLNTransformerLayers(TransformerLayersBase):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_blocks: int,\n",
    "        n_factors: int,\n",
    "        n_heads: int,\n",
    "        dropout_rate: float,\n",
    "        ff_factors_multiplier: int = 4,\n",
    "        n_hidden_groups: int=1,  # accept new kwarg\n",
    "        n_inner_groups: int=1,  # accept new kwarg\n",
    "        \n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_hidden_groups = n_hidden_groups\n",
    "        self.n_inner_groups = n_inner_groups\n",
    "        n_fitted_blocks = int(n_hidden_groups * n_inner_groups)\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                PreLNTransformerLayer(\n",
    "                    # number of encoder layer (AlBERTLayers)\n",
    "                    # https://github.com/huggingface/transformers/blob/main/src/transformers/models/albert/modeling_albert.py#L428\n",
    "                    n_factors,\n",
    "                    n_heads,\n",
    "                    dropout_rate,\n",
    "                    ff_factors_multiplier,\n",
    "                )\n",
    "                # https://github.com/huggingface/transformers/blob/main/src/transformers/models/albert/modeling_albert.py#L469\n",
    "                for _ in range(n_fitted_blocks)\n",
    "            ]\n",
    "        )\n",
    "        self.n_layers_per_group = n_blocks / n_hidden_groups\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        seqs: torch.Tensor,\n",
    "        timeline_mask: torch.Tensor,\n",
    "        attn_mask: tp.Optional[torch.Tensor],\n",
    "        key_padding_mask: tp.Optional[torch.Tensor],\n",
    "    ) -> torch.Tensor:\n",
    "        for block_idx in range(self.n_blocks):\n",
    "            group_idx = int(block_idx / self.n_layers_per_group)\n",
    "            for inner_layer_idx in range(self.n_inner_groups):\n",
    "                layer_idx = group_idx * self.n_inner_groups + inner_layer_idx\n",
    "                seqs = self.transformer_blocks[block_idx](seqs, attn_mask, key_padding_mask)\n",
    "        return seqs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass Albert modules to `BERT4RecModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.transformers.bert4rec.BERT4RecModel at 0x7fa722cd5970>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONSTRUCTOR_KWARGS = {\n",
    "    \"emb_factors\": 32,\n",
    "}\n",
    "\n",
    "TRANSFORMER_LAYERS_KWARGS = {\n",
    "    \"n_hidden_groups\": 2,\n",
    "    \"n_inner_groups\": 1,\n",
    "}\n",
    "\n",
    "albert_model = BERT4RecModel(\n",
    "    item_net_constructor_type=AlBERT4RecSumOfEmbeddingsConstructor,  # custom item net constructor\n",
    "    item_net_constructor_kwargs=CONSTRUCTOR_KWARGS,  # kwargs for custom constructor\n",
    "    transformer_layers_type=AlBERT4RecPreLNTransformerLayers,  # custom transformer layers\n",
    "    transformer_layers_kwargs=TRANSFORMER_LAYERS_KWARGS, # kwargs for custom transformer layers\n",
    "    get_trainer_func = get_debug_trainer,\n",
    ")\n",
    "albert_model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass Albert modules to `SASRecModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.transformers.sasrec.SASRecModel at 0x7fa6dacc9700>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alsasrec_model = SASRecModel(\n",
    "    item_net_constructor_type=AlBERT4RecSumOfEmbeddingsConstructor,  # custom item net constructor\n",
    "    item_net_constructor_kwargs=CONSTRUCTOR_KWARGS,  # kwargs for custom constructor\n",
    "    transformer_layers_type=AlBERT4RecPreLNTransformerLayers,  # custom transformer layers\n",
    "    transformer_layers_kwargs=TRANSFORMER_LAYERS_KWARGS, # kwargs for custom transformer layers\n",
    "    get_trainer_func = get_debug_trainer,\n",
    ")\n",
    "alsasrec_model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about `NextActionTransformer` with Albert logic and causal attention?\n",
    "Just because we can!\n",
    "### Combining custom modules together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.transformers.bert4rec.BERT4RecModel at 0x7fa689e40cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_action_albert_causal = BERT4RecModel(\n",
    "    item_net_constructor_type=AlBERT4RecSumOfEmbeddingsConstructor,  # custom item net constructor\n",
    "    item_net_constructor_kwargs=CONSTRUCTOR_KWARGS,  # kwargs for custom constructor\n",
    "    transformer_layers_type=AlBERT4RecPreLNTransformerLayers,  # custom transformer layers\n",
    "    transformer_layers_kwargs=TRANSFORMER_LAYERS_KWARGS, # kwargs for custom transformer layers\n",
    "    data_preparator_type=NextActionDataPreparator,  # custom data preparator\n",
    "    lightning_module_type=NextActionLightningModule,  # custom lightning module\n",
    "    use_causal_attn=True,  # Apply causal attention mask\n",
    "    get_trainer_func = get_debug_trainer,\n",
    ")\n",
    "next_action_albert_causal.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs support for custom models\n",
    "All custom models fully support initialization from configs and other RecTools benefits. For models with keyword arguments we suggest to use `from_params` method that accepts configs in a flat dict form. See example below:\n",
    "\n",
    "**Important: only JSON serializable custom keyword argument values are accepted during customization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls': 'BERT4RecModel',\n",
       " 'verbose': 0,\n",
       " 'data_preparator_type': '__main__.NextActionDataPreparator',\n",
       " 'n_blocks': 2,\n",
       " 'n_heads': 4,\n",
       " 'n_factors': 256,\n",
       " 'use_pos_emb': True,\n",
       " 'use_causal_attn': True,\n",
       " 'use_key_padding_mask': True,\n",
       " 'dropout_rate': 0.2,\n",
       " 'session_max_len': 100,\n",
       " 'dataloader_num_workers': 0,\n",
       " 'batch_size': 128,\n",
       " 'loss': 'softmax',\n",
       " 'n_negatives': 1,\n",
       " 'gbce_t': 0.2,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 3,\n",
       " 'deterministic': False,\n",
       " 'recommend_batch_size': 256,\n",
       " 'recommend_device': None,\n",
       " 'recommend_n_threads': 0,\n",
       " 'recommend_use_torch_ranking': True,\n",
       " 'train_min_user_interactions': 2,\n",
       " 'item_net_block_types': ['rectools.models.nn.item_net.IdEmbeddingsItemNet',\n",
       "  'rectools.models.nn.item_net.CatFeaturesItemNet'],\n",
       " 'item_net_constructor_type': '__main__.AlBERT4RecSumOfEmbeddingsConstructor',\n",
       " 'pos_encoding_type': 'rectools.models.nn.transformers.net_blocks.LearnableInversePositionalEncoding',\n",
       " 'transformer_layers_type': '__main__.AlBERT4RecPreLNTransformerLayers',\n",
       " 'lightning_module_type': '__main__.NextActionLightningModule',\n",
       " 'get_val_mask_func': None,\n",
       " 'get_trainer_func': '__main__.get_debug_trainer',\n",
       " 'data_preparator_kwargs': None,\n",
       " 'transformer_layers_kwargs.n_hidden_groups': 2,\n",
       " 'transformer_layers_kwargs.n_inner_groups': 1,\n",
       " 'item_net_constructor_kwargs.emb_factors': 32,\n",
       " 'pos_encoding_kwargs': None,\n",
       " 'lightning_module_kwargs': None,\n",
       " 'mask_prob': 0.15}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = next_action_albert_causal.get_params(simple_types=True)\n",
    "params\n",
    "# see below that model params include our custom keyword arguments:\n",
    "# \"transformer_layers_kwargs.n_hidden_groups\", \n",
    "# \"transformer_layers_kwargs.n_inner_groups\"\n",
    "# and \"item_net_constructor_kwargs.emb_factors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.transformers.bert4rec.BERT4RecModel at 0x7fa689e40460>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERT4RecModel.from_params(params)\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full list of customization options\n",
    "\n",
    "These blocks of RecTools transfofmer models can be replaced with custom classes (WITH an option to add required keyword arguments for initialization):\n",
    "- data preparator (`data_preparator_type`, `data_preparator_kwargs`)\n",
    "    - forming training objectives\n",
    "    - providing train, val and recommend dataloaders preparation\n",
    "- lightning module (`lightning_module_type`, `lightning_module_kwargs`)\n",
    "    - tying of user session latent represenation and candidate embeddings\n",
    "    - training, validation and recommending logic\n",
    "    - losses computation\n",
    "    - weights initialization\n",
    "    - optimizer configuration\n",
    "- item net constructor (`item_net_constructor_type`, `item_net_constructor_kwargs`)\n",
    "    - way for aggregating outputs from item net blocks\n",
    "- transformer layers (`transformer_layers_type`, `transformer_layers_kwargs`)\n",
    "- positional encoding (`pos_encoding_type`, `pos_encoding_kwargs`)\n",
    "\n",
    "These blocks of RecTools transfofmer models can be replaced with custom classes (WITHOUT an option to add keyword arguments):\n",
    "- item net blocks (`item_net_block_types`)\n",
    "\n",
    "These keyword model arguments have great effect on model architecture:\n",
    "- `use_causal_attn` (applies unidirectional attention instead of bidirectional when set to ``True``)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rectools",
   "language": "python",
   "name": "rectools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
