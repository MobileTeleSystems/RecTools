{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Models Advanced Training Guide\n",
    "This guide is showing advanced features of RecTools transformer models training.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* Prepare data\n",
    "* Advanced training guide\n",
    "    * Validation fold\n",
    "    * Validation loss\n",
    "    * Callback for Early Stopping\n",
    "    * Callbacks for Checkpoints (+ loading checkpoints)\n",
    "    * Callbacks for RecSys metrics (+ checkpoints on RecSys metrics)\n",
    "* Advanced training full example\n",
    "    * Running full training with all of the described validation features on Kion dataset\n",
    "* More RecTools features for transformers\n",
    "    * Saving and loading models\n",
    "    * Configs for transformer models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import typing as tp\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightning_fabric import seed_everything\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "\n",
    "from rectools import Columns, ExternalIds\n",
    "from rectools.dataset import Dataset\n",
    "from rectools.metrics import NDCG, Recall, Serendipity, calc_metrics\n",
    "from rectools.models import BERT4RecModel, SASRecModel, load_model\n",
    "from rectools.models.nn.item_net import IdEmbeddingsItemNet\n",
    "from rectools.models.nn.transformer_base import TransformerModelBase\n",
    "\n",
    "# Enable deterministic behaviour with CUDA >= 10.2\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# !wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_en.zip -O data_en.zip\n",
    "# !unzip -o data_en.zip\n",
    "# !rm data_en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476251, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  total_dur  watched_pct\n",
       "0   176549     9506 2021-05-11       4250         72.0\n",
       "1   699317     1659 2021-05-29       8317        100.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "DATA_PATH = Path(\"./data_en\")\n",
    "items = pd.read_csv(DATA_PATH / 'items_en.csv', index_col=0)\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "\n",
    "print(interactions.shape)\n",
    "interactions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962179, 15706)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[Columns.User].nunique(), interactions[Columns.Item].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476251, 4)\n"
     ]
    }
   ],
   "source": [
    "# Process interactions\n",
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "raw_interactions = interactions[[\"user_id\", \"item_id\", \"datetime\", \"weight\"]]\n",
    "print(raw_interactions.shape)\n",
    "raw_interactions.head(2)\n",
    "\n",
    "dataset = Dataset.construct(raw_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE=60\n",
    "torch.use_deterministic_algorithms(True)\n",
    "seed_everything(RANDOM_STATE, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation fold\n",
    "\n",
    "Models do not create validation fold during `fit` by default. However, there is a simple way to force it.\n",
    "\n",
    "Let's assume that we want to use Leave-One-Out validation for specific set of users. To apply it we need to implement `get_val_mask_func` with required logic and pass it to model during initialization. \n",
    "\n",
    "This function should receive interactions with standard RecTools columns and return a binary mask which identifies interactions that should not be used during model training. But instrad should be used for validation loss calculation. They will also be available for Lightning Callbacks to allow RecSys metrics computations.\n",
    "\n",
    "*Please make sure you do not use `partial` while doing this. Partial functions cannot be by serialized using RecTools.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement `get_val_mask_func`\n",
    "\n",
    "N_VAL_USERS = 2048\n",
    "unique_users = raw_interactions[Columns.User].unique()\n",
    "VAL_USERS = unique_users[: N_VAL_USERS]\n",
    "\n",
    "def leave_one_out_mask_for_users(interactions: pd.DataFrame, val_users: ExternalIds) -> np.ndarray:\n",
    "    rank = (\n",
    "        interactions\n",
    "        .sort_values(Columns.Datetime, ascending=False, kind=\"stable\")\n",
    "        .groupby(Columns.User, sort=False)\n",
    "        .cumcount()\n",
    "    )\n",
    "    val_mask = (\n",
    "        (interactions[Columns.User].isin(val_users))\n",
    "        & (rank == 0)\n",
    "    )\n",
    "    return val_mask.values\n",
    "\n",
    "# We do not use `partial` for correct serialization of the model\n",
    "def get_val_mask_func(interactions: pd.DataFrame):\n",
    "    return leave_one_out_mask_for_users(interactions, val_users = VAL_USERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = SASRecModel(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    train_min_user_interactions=5,\n",
    "    session_max_len=50,\n",
    "    verbose=0,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet,),\n",
    "    get_val_mask_func=get_val_mask_func,  # pass our custom `get_val_mask_func`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loss\n",
    "\n",
    "Let's check how the validation loss is being logged.\n",
    "We just want to quickly check functionality for now so let's create a custom Lightning trainer for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.sasrec.SASRecModel at 0x2acd90c10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='cpu',  # TODO: change\n",
    "    devices=1,\n",
    "    min_epochs=2,\n",
    "    max_epochs=2, \n",
    "    deterministic=True,\n",
    "    limit_train_batches=2,  # use only 2 batches for each epoch for a test run\n",
    "    enable_checkpointing=False,\n",
    "    logger = CSVLogger(\"test_logs\"),\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "# Replace default trainer with our custom one\n",
    "model._trainer = trainer\n",
    "\n",
    "# Fit model. Validation fold and validation loss computation will be done under the hood.\n",
    "model.fit(dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at model logs. We can access logs directory with `model.fit_trainer.log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams.yaml metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# What's inside the logs directory?\n",
    "!ls $model.fit_trainer.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch,step,train_loss,val_loss\n",
      "0,1,,22.41293716430664\n",
      "0,1,22.974777221679688,\n",
      "1,3,,22.27031898498535\n",
      "1,3,22.650423049926758,\n"
     ]
    }
   ],
   "source": [
    "# Losses and metrics are in the `metrics.csv`\n",
    "# Let's look at logs\n",
    "\n",
    "!tail $model.fit_trainer.log_dir/metrics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback for Early Stopping\n",
    "\n",
    "Now that we have validation loss logged, let's use ot for model Early Stopping. It will ensure that model will not resume training if validation loss (or any other custom metric) doesn't impove. We have Lightning Callbacks for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=SASRecModel.val_loss_name,   # or just pass \"val_loss\" here\n",
    "    mode=\"min\",\n",
    "    min_delta=1.  # just for a quick test of functionality\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='cpu',  # TODO: change\n",
    "    devices=1,\n",
    "    min_epochs=1,  # minimum number of epochs to train before early stopping\n",
    "    max_epochs=20,  # maximum number of epochs to train\n",
    "    deterministic=True,\n",
    "    limit_train_batches=2,  # use only 2 batches for each epoch for a test run\n",
    "    enable_checkpointing=False,\n",
    "    logger = CSVLogger(\"test_logs\"),\n",
    "    callbacks=early_stopping_callback,  # pass our callback\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "# Replace default trainer with our custom one\n",
    "model._trainer = trainer\n",
    "\n",
    "# Fit model. Everything will happen under the hood\n",
    "model.fit(dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here model stopped training after 4 epochs because validation loss wasn't improving by our specified `min_delta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch,step,train_loss,val_loss\n",
      "0,1,,22.35995864868164\n",
      "0,1,22.873361587524414,\n",
      "1,3,,22.200777053833008\n",
      "1,3,22.538841247558594,\n",
      "2,5,,21.98937225341797\n",
      "2,5,22.36414909362793,\n",
      "3,7,,21.726999282836914\n",
      "3,7,22.734487533569336,\n"
     ]
    }
   ],
   "source": [
    "# Let's check out logs\n",
    "!tail $model.fit_trainer.log_dir/metrics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback for Checkpoints\n",
    "Checkpoints are model states that are saved periodically during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint after last epoch\n",
    "last_epoch_ckpt = ModelCheckpoint(filename=\"last_epoch\")\n",
    "\n",
    "# Checkpoints based on validation loss\n",
    "least_val_loss_ckpt = ModelCheckpoint(\n",
    "    monitor=SASRecModel.val_loss_name,   # or just pass \"val_loss\" here,\n",
    "    mode=\"min\",\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",\n",
    "    save_top_k=2,  # Let's save top 2 checkpoints for validation loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='cpu',  # TODO: change\n",
    "    devices=1,\n",
    "    min_epochs=1,\n",
    "    max_epochs=6,\n",
    "    deterministic=True,\n",
    "    limit_train_batches=2,  # use only 2 batches for each epoch for a test run\n",
    "    logger = CSVLogger(\"test_logs\"),\n",
    "    callbacks=[last_epoch_ckpt, least_val_loss_ckpt],  # pass our callbacks for checkpoints\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "# Replace default trainer with our custom one\n",
    "model._trainer = trainer\n",
    "\n",
    "# Fit model. Everything will happen under the hood\n",
    "model.fit(dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at model checkpoints that were saved. By default they are neing saved to `checkpoints` directory in  `model.fit_trainer.log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4-val_loss=21.50.ckpt last_epoch.ckpt\n",
      "epoch=5-val_loss=21.20.ckpt\n"
     ]
    }
   ],
   "source": [
    "# We have 2 checkpoints for 2 best validation loss values and one for last epoch\n",
    "!ls $model.fit_trainer.log_dir/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading checkpoints is very simple with `load_from_checkpoint` method.\n",
    "Note that there are some important limitations: \n",
    "- loaded model will have a default trainer set as `_trainer`. For custom trainer just assign it manually.\n",
    "- loaded model will not have `fit_trainer`\n",
    "\n",
    "But it is fully ready for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f871bacabb3c4f8e87ff31aebff84e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>15297</td>\n",
       "      <td>0.714833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176549</td>\n",
       "      <td>3734</td>\n",
       "      <td>0.657935</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176549</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.621941</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176549</td>\n",
       "      <td>11237</td>\n",
       "      <td>0.578909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176549</td>\n",
       "      <td>4880</td>\n",
       "      <td>0.555269</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>176549</td>\n",
       "      <td>13865</td>\n",
       "      <td>0.548460</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>176549</td>\n",
       "      <td>4495</td>\n",
       "      <td>0.530932</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>176549</td>\n",
       "      <td>4457</td>\n",
       "      <td>0.494696</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>176549</td>\n",
       "      <td>10440</td>\n",
       "      <td>0.493136</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>176549</td>\n",
       "      <td>9996</td>\n",
       "      <td>0.491958</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id     score  rank\n",
       "0   176549    15297  0.714833     1\n",
       "1   176549     3734  0.657935     2\n",
       "2   176549     1844  0.621941     3\n",
       "3   176549    11237  0.578909     4\n",
       "4   176549     4880  0.555269     5\n",
       "5   176549    13865  0.548460     6\n",
       "6   176549     4495  0.530932     7\n",
       "7   176549     4457  0.494696     8\n",
       "8   176549    10440  0.493136     9\n",
       "9   176549     9996  0.491958    10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = os.path.join(model.fit_trainer.log_dir, \"checkpoints\", \"last_epoch.ckpt\")\n",
    "loaded = SASRecModel.load_from_checkpoint(ckpt_path)\n",
    "loaded.recommend(users=VAL_USERS[:1], dataset=dataset, filter_viewed=True, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks for RecSys metrics during training\n",
    "\n",
    "Monitoring RecSys metrics (or any other custom things) on validation fold is not available out of the box, but we can create a custom Lightning Callback for that.\n",
    "\n",
    "Below is an example of calculating standard RecTools metrics on validation fold during training. We use it as an explicit example that any customization is possible. But it is recommend to implement metrics calculation using `torch` for faster computations.\n",
    "\n",
    "Please look at PyTorch Lightning documentation for more details on custom callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement custom Callback for RecTools metrics computation within validation epochs during training.\n",
    "\n",
    "class ValidationMetrics(Callback):\n",
    "    \n",
    "    def __init__(self, top_k: int, val_metrics: tp.Dict, verbose: int = 0) -> None:\n",
    "        self.top_k = top_k\n",
    "        self.val_metrics = val_metrics\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.epoch_n_users: int = 0\n",
    "        self.batch_metrics: tp.List[tp.Dict[str, float]] = []\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, \n",
    "        trainer: Trainer, \n",
    "        pl_module: LightningModule, \n",
    "        outputs: tp.Dict[str, torch.Tensor], \n",
    "        batch: tp.Dict[str, torch.Tensor], \n",
    "        batch_idx: int, \n",
    "        dataloader_idx: int = 0\n",
    "    ) -> None:\n",
    "        logits = outputs[\"logits\"]\n",
    "        if logits is None:\n",
    "            logits = pl_module.torch_model.encode_sessions(batch[\"x\"], pl_module.item_embs)[:, -1, :]\n",
    "        _, sorted_batch_recos = logits.topk(k=self.top_k)\n",
    "\n",
    "        batch_recos = sorted_batch_recos.tolist()\n",
    "        targets = batch[\"y\"].tolist()\n",
    "\n",
    "        batch_val_users = list(\n",
    "            itertools.chain.from_iterable(\n",
    "                itertools.repeat(idx, len(recos)) for idx, recos in enumerate(batch_recos)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        batch_target_users = list(\n",
    "            itertools.chain.from_iterable(\n",
    "                itertools.repeat(idx, len(targets)) for idx, targets in enumerate(targets)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        batch_recos_df = pd.DataFrame(\n",
    "            {\n",
    "                Columns.User: batch_val_users,\n",
    "                Columns.Item: list(itertools.chain.from_iterable(batch_recos)),\n",
    "            }\n",
    "        )\n",
    "        batch_recos_df[Columns.Rank] = batch_recos_df.groupby(Columns.User, sort=False).cumcount() + 1\n",
    "\n",
    "        interactions = pd.DataFrame(\n",
    "            {\n",
    "                Columns.User: batch_target_users,\n",
    "                Columns.Item: list(itertools.chain.from_iterable(targets)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        prev_interactions = pl_module.data_preparator.train_dataset.interactions.df\n",
    "        catalog = prev_interactions[Columns.Item].unique()\n",
    "\n",
    "        batch_metrics = calc_metrics(\n",
    "            self.val_metrics, \n",
    "            batch_recos_df,\n",
    "            interactions, \n",
    "            prev_interactions,\n",
    "            catalog\n",
    "        )\n",
    "\n",
    "        batch_n_users = batch[\"x\"].shape[0]\n",
    "        self.batch_metrics.append({metric: value * batch_n_users for metric, value in batch_metrics.items()})\n",
    "        self.epoch_n_users += batch_n_users\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
    "        epoch_metrics = dict(sum(map(Counter, self.batch_metrics), Counter()))\n",
    "        epoch_metrics = {metric: value / self.epoch_n_users for metric, value in epoch_metrics.items()}\n",
    "\n",
    "        self.log_dict(epoch_metrics, on_step=False, on_epoch=True, prog_bar=self.verbose > 0)\n",
    "\n",
    "        self.batch_metrics.clear()\n",
    "        self.epoch_n_users = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When custom metrics callback is implemented, we can use the values of these metrics for both Early Stopping and Checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize callbacks for metrics calculation and checkpoint based on NDCG value\n",
    "\n",
    "metrics = {\n",
    "    \"NDCG@10\": NDCG(k=10),\n",
    "    \"Recall@10\": Recall(k=10),\n",
    "    \"Serendipity@10\": Serendipity(k=10),\n",
    "}\n",
    "top_k = max([metric.k for metric in metrics.values()])\n",
    "\n",
    "# Callback for calculating RecSys metrics\n",
    "val_metrics_callback = ValidationMetrics(top_k=top_k, val_metrics=metrics, verbose=0)\n",
    "\n",
    "# Callback for checkpoint based on maximization of NDCG@10\n",
    "best_ndcg_ckpt = ModelCheckpoint(\n",
    "    monitor=\"NDCG@10\",\n",
    "    mode=\"max\",\n",
    "    filename=\"{epoch}-{NDCG@10:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name        | Type                           | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 987 K  | train\n",
      "-----------------------------------------------------------------------\n",
      "987 K     Trainable params\n",
      "0         Non-trainable params\n",
      "987 K     Total params\n",
      "3.951     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49881906f144cb9a5f3ec9f1a36c079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd88091fca404c36b2fad769e7257688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a48a9f03794ab9a4e55abc65b85c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877ea612efa94b0483e72f0371684cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bdd58938ee438486fa6bf3453f2e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f184f15d2c48638b90a8c7afb33ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a364a7b6fa084dfeb75e88d7d1838d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7575b91420a844a883471c041f3027f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.sasrec.SASRecModel at 0x296553d60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='cpu',  # TODO: change\n",
    "    devices=1,\n",
    "    min_epochs=1,\n",
    "    max_epochs=6,\n",
    "    deterministic=True,\n",
    "    limit_train_batches=2,  # use only 2 batches for each epoch for a test run\n",
    "    logger = CSVLogger(\"test_logs\"),\n",
    "    callbacks=[val_metrics_callback, best_ndcg_ckpt],  # pass our callbacks\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "\n",
    "# Replace default trainer with our custom one\n",
    "model._trainer = trainer\n",
    "\n",
    "# Fit model. Everything will happen under the hood\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have checkpoint for best NDCG@10 model in the usual directory for checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5-NDCG@10=0.01.ckpt\n"
     ]
    }
   ],
   "source": [
    "!ls $model.fit_trainer.log_dir/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also now have metrics in our logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10,Recall@10,Serendipity@10,epoch,step,train_loss,val_loss\n",
      "0.0006136037991382182,0.005259697791188955,4.036495283799013e-06,0,1,,22.36232566833496\n",
      ",,,0,1,22.85256004333496,\n",
      "0.00378932966850698,0.04470742866396904,5.4826059567858465e-06,1,3,,22.194259643554688\n",
      ",,,1,3,22.471229553222656,\n",
      "0.004971458576619625,0.048652201890945435,5.865532330062706e-06,2,5,,21.967544555664062\n",
      ",,,2,5,22.728843688964844,\n",
      "0.008074083365499973,0.04996712505817413,5.288889951771125e-06,3,7,,21.701507568359375\n",
      ",,,3,7,22.52100372314453,\n",
      "0.010768753476440907,0.0788954645395279,3.748174322026898e-06,4,9,,21.411954879760742\n"
     ]
    }
   ],
   "source": [
    "!head $model.fit_trainer.log_dir/metrics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load them to read more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.852560</td>\n",
       "      <td>22.362326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22.471230</td>\n",
       "      <td>22.194260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22.728844</td>\n",
       "      <td>21.967545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22.521004</td>\n",
       "      <td>21.701508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22.202381</td>\n",
       "      <td>21.411955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss   val_loss\n",
       "0      0   22.852560  22.362326\n",
       "1      1   22.471230  22.194260\n",
       "2      2   22.728844  21.967545\n",
       "3      3   22.521004  21.701508\n",
       "4      4   22.202381  21.411955"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_logs(model: TransformerModelBase) -> tp.Tuple[pd.DataFrame, ...]:\n",
    "    log_path = Path(model.fit_trainer.log_dir) / \"metrics.csv\"\n",
    "    epoch_metrics_df = pd.read_csv(log_path)\n",
    "    \n",
    "    loss_df = epoch_metrics_df[[\"epoch\", \"train_loss\"]].dropna()\n",
    "    val_loss_df = epoch_metrics_df[[\"epoch\", \"val_loss\"]].dropna()\n",
    "    loss_df = pd.merge(loss_df, val_loss_df, how=\"inner\", on=\"epoch\")\n",
    "    loss_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    metrics_df = epoch_metrics_df.drop(columns=[\"train_loss\", \"val_loss\"]).dropna()\n",
    "    metrics_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return loss_df, metrics_df\n",
    "\n",
    "loss_df, metrics_df = get_logs(model)\n",
    "\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Serendipity@10</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.044707</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.048652</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.078895</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NDCG@10  Recall@10  Serendipity@10  epoch  step\n",
       "0  0.000614   0.005260        0.000004      0     1\n",
       "1  0.003789   0.044707        0.000005      1     3\n",
       "2  0.004971   0.048652        0.000006      2     5\n",
       "3  0.008074   0.049967        0.000005      3     7\n",
       "4  0.010769   0.078895        0.000004      4     9"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced training full example\n",
    "Running full training with all of the described validation features on Kion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SASRecModel(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    train_min_user_interactions=5,\n",
    "    session_max_len=50,\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet,),\n",
    "    get_val_mask_func=get_val_mask_func,  # pass our custom `get_val_mask_func`\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"NDCG@10\",\n",
    "    patience=5,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='cpu',  # TODO: change\n",
    "    devices=1,\n",
    "    min_epochs=1,\n",
    "    max_epochs=100,\n",
    "    deterministic=True,\n",
    "    logger = CSVLogger(\"sasrec_logs\"),\n",
    "    callbacks=[\n",
    "        val_metrics_callback,  # calculate RecSys metrics\n",
    "        best_ndcg_ckpt,  # save best NDCG model checkpoint\n",
    "        last_epoch_ckpt,  # save model checkpoint after the last train epoch\n",
    "        early_stopping_callback,  # early stopping on NDCG\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Replace default trainer with our custom one\n",
    "model._trainer = trainer\n",
    "\n",
    "# Fit model. Everything will happen under the hood\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df, metrics_df = get_logs(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $model.fit_trainer.log_dir/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More RecTools features for transformers\n",
    "### Saving and loading models\n",
    "Transformer models can be saved and loaded just like any other RecTools models. \n",
    "\n",
    "*Note that you can't use these common functions for savings and loading lightning checkpoints. Use `load_from_checkpoint` method instead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11938679"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rectools.models.nn.sasrec.SASRecModel'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf8442adc1c4040a2740451be727684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>15297</td>\n",
       "      <td>0.760289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176549</td>\n",
       "      <td>4260</td>\n",
       "      <td>0.634466</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176549</td>\n",
       "      <td>4880</td>\n",
       "      <td>0.593727</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176549</td>\n",
       "      <td>6809</td>\n",
       "      <td>0.592482</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176549</td>\n",
       "      <td>12360</td>\n",
       "      <td>0.574020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>176549</td>\n",
       "      <td>7210</td>\n",
       "      <td>0.553542</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>176549</td>\n",
       "      <td>2657</td>\n",
       "      <td>0.542704</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>176549</td>\n",
       "      <td>4151</td>\n",
       "      <td>0.534909</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>176549</td>\n",
       "      <td>13865</td>\n",
       "      <td>0.533222</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>176549</td>\n",
       "      <td>11863</td>\n",
       "      <td>0.523369</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id     score  rank\n",
       "0   176549    15297  0.760289     1\n",
       "1   176549     4260  0.634466     2\n",
       "2   176549     4880  0.593727     3\n",
       "3   176549     6809  0.592482     4\n",
       "4   176549    12360  0.574020     5\n",
       "5   176549     7210  0.553542     6\n",
       "6   176549     2657  0.542704     7\n",
       "7   176549     4151  0.534909     8\n",
       "8   176549    13865  0.533222     9\n",
       "9   176549    11863  0.523369    10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = load_model(\"my_model.pkl\")\n",
    "print(type(loaded))\n",
    "loaded.recommend(users=VAL_USERS[:1], dataset=dataset, filter_viewed=True, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs for transformer models\n",
    "\n",
    "`from_config`, `get_config` and `get_params` methods are fully available for transformers just like for any other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cls': 'SASRecModel',\n",
       " 'verbose': 0,\n",
       " 'data_preparator_type': 'rectools.models.nn.sasrec.SASRecDataPreparator',\n",
       " 'n_blocks': 1,\n",
       " 'n_heads': 1,\n",
       " 'n_factors': 64,\n",
       " 'use_pos_emb': True,\n",
       " 'use_causal_attn': True,\n",
       " 'use_key_padding_mask': False,\n",
       " 'dropout_rate': 0.2,\n",
       " 'session_max_len': 100,\n",
       " 'dataloader_num_workers': 0,\n",
       " 'batch_size': 128,\n",
       " 'loss': 'softmax',\n",
       " 'n_negatives': 1,\n",
       " 'gbce_t': 0.2,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 2,\n",
       " 'deterministic': False,\n",
       " 'recommend_batch_size': 256,\n",
       " 'recommend_accelerator': 'auto',\n",
       " 'recommend_devices': 1,\n",
       " 'recommend_n_threads': 0,\n",
       " 'recommend_use_gpu_ranking': True,\n",
       " 'train_min_user_interactions': 2,\n",
       " 'item_net_block_types': ['rectools.models.nn.item_net.IdEmbeddingsItemNet',\n",
       "  'rectools.models.nn.item_net.CatFeaturesItemNet'],\n",
       " 'pos_encoding_type': 'rectools.models.nn.transformer_net_blocks.LearnableInversePositionalEncoding',\n",
       " 'transformer_layers_type': 'rectools.models.nn.sasrec.SASRecTransformerLayers',\n",
       " 'lightning_module_type': 'rectools.models.nn.transformer_base.SessionEncoderLightningModule',\n",
       " 'get_val_mask_func': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"epochs\": 2,\n",
    "    \"n_blocks\": 1,\n",
    "    \"n_heads\": 1,\n",
    "    \"n_factors\": 64, \n",
    "}\n",
    "\n",
    "model = SASRecModel.from_config(config)\n",
    "model.get_params(simple_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer models in RecTools may accept functions and classes as arguments. These types of arguments are fully compatible with RecTools configs. You can eigther pass them as python objects or as strings that define their import paths.\n",
    "\n",
    "Below is an example of both approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cls': 'SASRecModel',\n",
       " 'verbose': 0,\n",
       " 'data_preparator_type': 'rectools.models.nn.sasrec.SASRecDataPreparator',\n",
       " 'n_blocks': 2,\n",
       " 'n_heads': 4,\n",
       " 'n_factors': 256,\n",
       " 'use_pos_emb': True,\n",
       " 'use_causal_attn': True,\n",
       " 'use_key_padding_mask': False,\n",
       " 'dropout_rate': 0.2,\n",
       " 'session_max_len': 100,\n",
       " 'dataloader_num_workers': 0,\n",
       " 'batch_size': 128,\n",
       " 'loss': 'softmax',\n",
       " 'n_negatives': 1,\n",
       " 'gbce_t': 0.2,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 3,\n",
       " 'deterministic': False,\n",
       " 'recommend_batch_size': 256,\n",
       " 'recommend_accelerator': 'auto',\n",
       " 'recommend_devices': 1,\n",
       " 'recommend_n_threads': 0,\n",
       " 'recommend_use_gpu_ranking': True,\n",
       " 'train_min_user_interactions': 2,\n",
       " 'item_net_block_types': ['rectools.models.nn.item_net.IdEmbeddingsItemNet',\n",
       "  'rectools.models.nn.item_net.CatFeaturesItemNet'],\n",
       " 'pos_encoding_type': 'rectools.models.nn.transformer_net_blocks.LearnableInversePositionalEncoding',\n",
       " 'transformer_layers_type': 'rectools.models.nn.sasrec.SASRecTransformerLayers',\n",
       " 'lightning_module_type': 'rectools.models.nn.transformer_base.SessionEncoderLightningModule',\n",
       " 'get_val_mask_func': '__main__.get_val_mask_func'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"get_val_mask_func\": get_val_mask_func,  # function to get validation mask\n",
    "    \"transformer_layers_type\": \"rectools.models.nn.sasrec.SASRecTransformerLayers\",  # path to transformer layers class\n",
    "}\n",
    "\n",
    "model = SASRecModel.from_config(config)\n",
    "model.get_params(simple_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `trainer` can't be handled by configs due to it's complicated structure.\n",
    "You can pass custom trainer with manual assignment after model initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._trainer = trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
