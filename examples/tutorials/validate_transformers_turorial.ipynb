{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: will remove\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import torch\n",
    "import typing as tp\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from lightning_fabric import seed_everything\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from rectools import Columns, ExternalIds\n",
    "from rectools.dataset import Dataset\n",
    "from rectools.metrics import NDCG, Recall, Serendipity, calc_metrics\n",
    "\n",
    "from rectools.models.nn.sasrec import SASRecModel\n",
    "from rectools.models.nn.item_net import IdEmbeddingsItemNet\n",
    "from rectools.models.nn.transformer_base import TransformerModelBase\n",
    "\n",
    "# Enable deterministic behaviour with CUDA >= 10.2\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_en.zip -O data_en.zip\n",
    "!unzip -o data_en.zip\n",
    "!rm data_en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52318, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  total_dur  watched_pct\n",
       "0   176549     9506 2021-05-11       4250         72.0\n",
       "1   699317     1659 2021-05-29       8317        100.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "DATA_PATH = Path(\"./data_en\")\n",
    "items = pd.read_csv(DATA_PATH / 'items_en.csv', index_col=0)\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "\n",
    "# # TODO: for test\n",
    "# unique_users = interactions[Columns.User].unique()[: 2_000]\n",
    "# interactions = interactions[interactions[Columns.User].isin(unique_users)]\n",
    "\n",
    "print(interactions.shape)\n",
    "interactions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6179)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[Columns.User].nunique(), interactions[Columns.Item].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52318, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  weight\n",
       "0   176549     9506 2021-05-11       3\n",
       "1   699317     1659 2021-05-29       3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process interactions\n",
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "raw_interactions = interactions[[\"user_id\", \"item_id\", \"datetime\", \"weight\"]]\n",
    "print(raw_interactions.shape)\n",
    "raw_interactions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process item features\n",
    "# items = items.loc[items[Columns.Item].isin(raw_interactions[Columns.Item])].copy()\n",
    "# items[\"genre\"] = items[\"genres\"].str.lower().str.replace(\", \", \",\", regex=False).str.split(\",\")\n",
    "# genre_feature = items[[\"item_id\", \"genre\"]].explode(\"genre\")\n",
    "# genre_feature.columns = [\"id\", \"value\"]\n",
    "# genre_feature[\"feature\"] = \"genre\"\n",
    "# content_feature = items.reindex(columns=[Columns.Item, \"content_type\"])\n",
    "# content_feature.columns = [\"id\", \"value\"]\n",
    "# content_feature[\"feature\"] = \"content_type\"\n",
    "# item_features = pd.concat((genre_feature, content_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE=60\n",
    "torch.use_deterministic_algorithms(True)\n",
    "seed_everything(RANDOM_STATE, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(user_id_map=IdMap(external_ids=array([ 176549,  699317,  656683, ...,  465028, 1055957,  761297])), item_id_map=IdMap(external_ids=array([ 9506,  1659,  7107, ...,  9107, 13252, 13105])), interactions=Interactions(df=       user_id  item_id  weight   datetime\n",
       "0            0        0     3.0 2021-05-11\n",
       "1            1        1     3.0 2021-05-29\n",
       "2            2        2     1.0 2021-05-09\n",
       "3            3        3     3.0 2021-07-05\n",
       "4            4        0     3.0 2021-04-30\n",
       "...        ...      ...     ...        ...\n",
       "52313      754     3450     1.0 2021-03-23\n",
       "52314       73     1988     3.0 2021-07-16\n",
       "52315     1365     1921     3.0 2021-04-24\n",
       "52316      452     1456     3.0 2021-04-30\n",
       "52317      884     1610     3.0 2021-03-23\n",
       "\n",
       "[52318 rows x 4 columns]), user_features=None, item_features=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_no_features = Dataset.construct(raw_interactions)\n",
    "dataset_no_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custome Validation** (Leave-One-Out Strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functionality for obtaining logged metrics after fitting model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir(model: TransformerModelBase) -> Path:\n",
    "    \"\"\"\n",
    "    Get logging directory.\n",
    "    \"\"\"\n",
    "    path = model.fit_trainer.logger.log_dir\n",
    "    return Path(path) / \"metrics.csv\"\n",
    "\n",
    "\n",
    "def get_losses(epoch_metrics_df: pd.DataFrame, is_val: bool) -> pd.DataFrame:\n",
    "    loss_df = epoch_metrics_df[[\"epoch\", \"train/loss\"]].dropna()\n",
    "    if is_val:\n",
    "        val_loss_df = epoch_metrics_df[[\"epoch\", \"val/loss\"]].dropna()\n",
    "        loss_df = pd.merge(loss_df, val_loss_df, how=\"inner\", on=\"epoch\")\n",
    "    return loss_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_val_metrics(epoch_metrics_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    metrics_df = epoch_metrics_df.drop(columns=[\"train/loss\", \"val/loss\"]).dropna()\n",
    "    return metrics_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_log_values(model: TransformerModelBase, is_val: bool = False) -> tp.Tuple[pd.DataFrame, tp.Optional[pd.DataFrame]]:\n",
    "    log_path = get_log_dir(model)\n",
    "    epoch_metrics_df = pd.read_csv(log_path)\n",
    "\n",
    "    loss_df = get_losses(epoch_metrics_df, is_val)\n",
    "    val_metrics = None\n",
    "    if is_val:\n",
    "        val_metrics = get_val_metrics(epoch_metrics_df)\n",
    "    return loss_df, val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callback for calculation RecSys metrics on validation step:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class ValidationMetrics(Callback):\n",
    "    \n",
    "    def __init__(self, top_k_saved_val_reco: int, val_metrics: tp.Dict, verbose: int = 0) -> None:\n",
    "        self.top_k_saved_val_reco = top_k_saved_val_reco\n",
    "        self.val_metrics = val_metrics\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.epoch_n_users: int = 0\n",
    "        self.batch_metrics: tp.List[tp.Dict[str, float]] = []\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, \n",
    "        trainer: Trainer, \n",
    "        pl_module: LightningModule, \n",
    "        outputs: tp.Dict[str, torch.Tensor], \n",
    "        batch: tp.Dict[str, torch.Tensor], \n",
    "        batch_idx: int, \n",
    "        dataloader_idx: int = 0\n",
    "    ) -> None:\n",
    "        logits = outputs[\"logits\"]\n",
    "        if logits is None:\n",
    "            logits = pl_module.torch_model.encode_sessions(batch[\"x\"], pl_module.item_embs)[:, -1, :]\n",
    "        _, sorted_batch_recos = logits.topk(k=self.top_k_saved_val_reco)\n",
    "\n",
    "        batch_recos = sorted_batch_recos.tolist()\n",
    "        targets = batch[\"y\"].tolist()\n",
    "\n",
    "        batch_val_users = list(\n",
    "            itertools.chain.from_iterable(\n",
    "                itertools.repeat(idx, len(recos)) for idx, recos in enumerate(batch_recos)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        batch_target_users = list(\n",
    "            itertools.chain.from_iterable(\n",
    "                itertools.repeat(idx, len(targets)) for idx, targets in enumerate(targets)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        batch_recos_df = pd.DataFrame(\n",
    "            {\n",
    "                Columns.User: batch_val_users,\n",
    "                Columns.Item: list(itertools.chain.from_iterable(batch_recos)),\n",
    "            }\n",
    "        )\n",
    "        batch_recos_df[Columns.Rank] = batch_recos_df.groupby(Columns.User, sort=False).cumcount() + 1\n",
    "\n",
    "        interactions = pd.DataFrame(\n",
    "            {\n",
    "                Columns.User: batch_target_users,\n",
    "                Columns.Item: list(itertools.chain.from_iterable(targets)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        prev_interactions = pl_module.data_preparator.train_dataset.interactions.df\n",
    "        catalog = prev_interactions[Columns.Item].unique()\n",
    "\n",
    "        batch_metrics = calc_metrics(\n",
    "            self.val_metrics, \n",
    "            batch_recos_df,\n",
    "            interactions, \n",
    "            prev_interactions,\n",
    "            catalog\n",
    "        )\n",
    "\n",
    "        batch_n_users = batch[\"x\"].shape[0]\n",
    "        self.batch_metrics.append({metric: value * batch_n_users for metric, value in batch_metrics.items()})\n",
    "        self.epoch_n_users += batch_n_users\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
    "        epoch_metrics = dict(sum(map(Counter, self.batch_metrics), Counter()))\n",
    "        epoch_metrics = {metric: value / self.epoch_n_users for metric, value in epoch_metrics.items()}\n",
    "\n",
    "        self.log_dict(epoch_metrics, on_step=False, on_epoch=True, prog_bar=self.verbose > 0)\n",
    "\n",
    "        self.batch_metrics.clear()\n",
    "        self.epoch_n_users = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000,), (200,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_K_OUT = 1\n",
    "N_VAL_USERS = 200\n",
    "\n",
    "unique_users = raw_interactions[Columns.User].unique()\n",
    "VAL_USERS = unique_users[: N_VAL_USERS]\n",
    "\n",
    "VAL_METRICS = {\n",
    "    \"NDCG@10\": NDCG(k=10),\n",
    "    \"Recall@10\": Recall(k=10),\n",
    "    \"Serendipity@10\": Serendipity(k=10),\n",
    "}\n",
    "VAL_MAX_K = max([metric.k for metric in VAL_METRICS.values()])\n",
    "\n",
    "MIN_EPOCHS = 2\n",
    "MAX_EPOCHS = 2\n",
    "\n",
    "MONITOR_METRIC = \"NDCG@10\"\n",
    "MODE_MONITOR_METRIC = \"max\"\n",
    "\n",
    "callback_metrics = ValidationMetrics(top_k_saved_val_reco=VAL_MAX_K, val_metrics=VAL_METRICS, verbose=1)\n",
    "callback_early_stopping = EarlyStopping(monitor=MONITOR_METRIC, patience=MIN_EPOCHS, min_delta=0.0, mode=MODE_MONITOR_METRIC)\n",
    "CALLBACKS = [callback_metrics, callback_early_stopping]\n",
    "\n",
    "TRAIN_MIN_USER_INTERACTIONS = 5\n",
    "SESSION_MAX_LEN = 50\n",
    "\n",
    "unique_users.shape, VAL_USERS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom function for split data on train and validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_mask(interactions: pd.DataFrame, val_users: ExternalIds) -> pd.Series:\n",
    "    rank = (\n",
    "        interactions\n",
    "        .sort_values(Columns.Datetime, ascending=False, kind=\"stable\")\n",
    "        .groupby(Columns.User, sort=False)\n",
    "        .cumcount()\n",
    "        + 1\n",
    "    )\n",
    "    val_mask = (\n",
    "        (interactions[Columns.User].isin(val_users))\n",
    "        & (rank <= VAL_K_OUT)\n",
    "    )\n",
    "    return val_mask\n",
    "\n",
    "\n",
    "GET_VAL_MASK = partial(\n",
    "    get_val_mask, \n",
    "    val_users=VAL_USERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=[1],\n",
    "    min_epochs=MIN_EPOCHS,\n",
    "    max_epochs=MAX_EPOCHS, \n",
    "    deterministic=True,\n",
    "    callbacks=CALLBACKS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sasrec_non_default_model = SASRecModel(\n",
    "    n_factors=64,\n",
    "    n_blocks=2,\n",
    "    n_heads=2,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    train_min_user_interactions=TRAIN_MIN_USER_INTERACTIONS,\n",
    "    session_max_len=SESSION_MAX_LEN,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    loss=\"softmax\",\n",
    "    verbose=1,\n",
    "    deterministic=True,\n",
    "    item_net_block_types=(IdEmbeddingsItemNet, ),  # Use only item ids in ItemNetBlock\n",
    "    trainer=trainer,\n",
    "    get_val_mask_func=GET_VAL_MASK,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                           | Params\n",
      "---------------------------------------------------------------\n",
      "0 | torch_model | TransformerBasedSessionEncoder | 371 K \n",
      "---------------------------------------------------------------\n",
      "371 K     Trainable params\n",
      "0         Non-trainable params\n",
      "371 K     Total params\n",
      "1.486     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6cfa351cd94ed492d8d32760cf3338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e0b5b8f5e8497f8dce7c03a9b9696e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119b90e628b54fbd85d06104d615b0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f92ac5b968346e5a4c334845b879e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.5 s, sys: 624 ms, total: 5.12 s\n",
      "Wall time: 2.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.nn.sasrec.SASRecModel at 0x7f03b3732c10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sasrec_non_default_model.fit(dataset_no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/home/amsemenov2/git/RecTools_origin/RecTools/examples/tutorials/lightning_logs/version_245/metrics.csv')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_log_dir(sasrec_non_default_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df, val_metrics_df = get_log_values(sasrec_non_default_model, is_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>val/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.252808</td>\n",
       "      <td>18.232187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19.276144</td>\n",
       "      <td>17.129280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train/loss   val/loss\n",
       "0      0   20.252808  18.232187\n",
       "1      1   19.276144  17.129280"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Serendipity@10</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.438642e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>5.754568e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NDCG@10  Recall@10  Serendipity@10  epoch  step\n",
       "0  0.005760   0.050000    1.438642e-07      0    12\n",
       "1  0.009044   0.085714    5.754568e-07      1    25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
