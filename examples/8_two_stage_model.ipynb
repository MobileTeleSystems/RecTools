{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/oirvach1/RecTools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TwoStageModel` user guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models import PopularModel, ImplicitItemKNNWrapperModel\n",
    "from implicit.nearest_neighbours import CosineRecommender\n",
    "from rectools.model_selection import TimeRangeSplitter\n",
    "from rectools.dataset import Dataset\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rectools import Columns\n",
    "from rectools.models.rerank import TwoStageModel, CandidateGenerator, RerankerBase, CatBoostRerankerWrapper\n",
    "from lightgbm import LGBMClassifier, LGBMRanker\n",
    "from catboost import CatBoostClassifier, CatBoostRanker\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_original.zip\n",
      "   creating: data_original/\n",
      "  inflating: data_original/interactions.csv  \n",
      "  inflating: __MACOSX/data_original/._interactions.csv  \n",
      "  inflating: data_original/users.csv  \n",
      "  inflating: __MACOSX/data_original/._users.csv  \n",
      "  inflating: data_original/items.csv  \n",
      "  inflating: __MACOSX/data_original/._items.csv  \n",
      "CPU times: user 425 ms, sys: 161 ms, total: 586 ms\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "\n",
    "DATA_PATH = Path(\"data_original\")\n",
    "users = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "items = pd.read_csv(DATA_PATH / 'items.csv')\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "interactions[\"weight\"] = 1\n",
    "dataset = Dataset.construct(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare first stage models\n",
    "first_stage = [\n",
    "    CandidateGenerator(PopularModel(), 30, True, True), \n",
    "    CandidateGenerator(ImplicitItemKNNWrapperModel(CosineRecommender()), 30, True, True)\n",
    "]\n",
    "\n",
    "# Prepare splitter for selecting reranker train. Only one fold is expected!\n",
    "splitter = TimeRangeSplitter(\"7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TwoStageModel\n",
    "# RerankerBase is not really used in final pipeline, we just didn't write the final class right now\n",
    "# We can also pass negative sampler but here we are just using the default one\n",
    "\n",
    "two_stage = TwoStageModel(first_stage, splitter, RerankerBase(RidgeClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset interactions\n",
    "# Fit first stage models on history dataset\n",
    "# Generate recommendations from first stage -> Get candidates for reranker\n",
    "# Add targets to all candidates\n",
    "# Sample negatives (here defult PerUserNegativeSampler is used) (we should probably make a public method to get data before sampling)\n",
    "candidates = two_stage.get_train_with_targets_for_reranker(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>PopularModel_1_score</th>\n",
       "      <th>PopularModel_1_rank</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_score</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870705</td>\n",
       "      <td>8636</td>\n",
       "      <td>34148.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.868300</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461643</td>\n",
       "      <td>14526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063427</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>457329</td>\n",
       "      <td>1517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149156</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>709024</td>\n",
       "      <td>14431</td>\n",
       "      <td>20276.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337461</td>\n",
       "      <td>7417</td>\n",
       "      <td>17346.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>294808</td>\n",
       "      <td>142</td>\n",
       "      <td>42877.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>359631</td>\n",
       "      <td>3784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245184</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1004603</td>\n",
       "      <td>6636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591062</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>653465</td>\n",
       "      <td>6809</td>\n",
       "      <td>39498.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>644766</td>\n",
       "      <td>12173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108739</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>783583</td>\n",
       "      <td>5518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065381</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44486</td>\n",
       "      <td>10440</td>\n",
       "      <td>189923.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>864763</td>\n",
       "      <td>1785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.583494</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>789242</td>\n",
       "      <td>849</td>\n",
       "      <td>13610.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>425826</td>\n",
       "      <td>4495</td>\n",
       "      <td>19571.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.439469</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>274035</td>\n",
       "      <td>4495</td>\n",
       "      <td>19571.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.352311</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>231080</td>\n",
       "      <td>11985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291417</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>703937</td>\n",
       "      <td>4495</td>\n",
       "      <td>19571.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>496024</td>\n",
       "      <td>13865</td>\n",
       "      <td>115095.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.087161</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170005</td>\n",
       "      <td>1449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153249</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  PopularModel_1_score  PopularModel_1_rank  \\\n",
       "0    870705     8636               34148.0                  8.0   \n",
       "1    461643    14526                   NaN                  NaN   \n",
       "2    457329     1517                   NaN                  NaN   \n",
       "3    709024    14431               20276.0                 12.0   \n",
       "4    337461     7417               17346.0                 20.0   \n",
       "5    294808      142               42877.0                  9.0   \n",
       "6    359631     3784                   NaN                  NaN   \n",
       "7   1004603     6636                   NaN                  NaN   \n",
       "8    653465     6809               39498.0                 10.0   \n",
       "9    644766    12173                   NaN                  NaN   \n",
       "10   783583     5518                   NaN                  NaN   \n",
       "11    44486    10440              189923.0                  1.0   \n",
       "12   864763     1785                   NaN                  NaN   \n",
       "13   789242      849               13610.0                 29.0   \n",
       "14   425826     4495               19571.0                 19.0   \n",
       "15   274035     4495               19571.0                 19.0   \n",
       "16   231080    11985                   NaN                  NaN   \n",
       "17   703937     4495               19571.0                 22.0   \n",
       "18   496024    13865              115095.0                  4.0   \n",
       "19   170005     1449                   NaN                  NaN   \n",
       "\n",
       "    ImplicitItemKNNWrapperModel_1_score  ImplicitItemKNNWrapperModel_1_rank  \\\n",
       "0                              0.868300                                 7.0   \n",
       "1                              0.063427                                24.0   \n",
       "2                              0.149156                                24.0   \n",
       "3                                   NaN                                 NaN   \n",
       "4                                   NaN                                 NaN   \n",
       "5                                   NaN                                 NaN   \n",
       "6                              0.245184                                24.0   \n",
       "7                              0.591062                                14.0   \n",
       "8                                   NaN                                 NaN   \n",
       "9                              0.108739                                26.0   \n",
       "10                             0.065381                                23.0   \n",
       "11                                  NaN                                 NaN   \n",
       "12                             2.583494                                 8.0   \n",
       "13                                  NaN                                 NaN   \n",
       "14                             0.439469                                 8.0   \n",
       "15                             0.352311                                 9.0   \n",
       "16                             0.291417                                10.0   \n",
       "17                                  NaN                                 NaN   \n",
       "18                             0.087161                                12.0   \n",
       "19                             0.153249                                24.0   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "5        0  \n",
       "6        0  \n",
       "7        0  \n",
       "8        1  \n",
       "9        0  \n",
       "10       0  \n",
       "11       0  \n",
       "12       1  \n",
       "13       0  \n",
       "14       0  \n",
       "15       0  \n",
       "16       0  \n",
       "17       1  \n",
       "18       0  \n",
       "19       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is train data for boosting or any other reranker. id columns will be dropped before training\n",
    "candidates.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we want to easily add features to candidates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant 1: from external source\n",
    "Other options are:\n",
    "- Get features from dataset\n",
    "- Fet time-based features using_fold info from splitter\n",
    "- Combine any of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models.rerank import CandidatesFeatureCollectorBase\n",
    "import typing as tp\n",
    "from rectools.models.base import AnyIds\n",
    "\n",
    "# Write custome feature collecting funcs for users, items and user/item pairs\n",
    "class CustomFeatureCollector(CandidatesFeatureCollectorBase):\n",
    "    def _get_user_features(\n",
    "        self, users: AnyIds, dataset: Dataset, fold_info: tp.Optional[tp.Dict[str, tp.Any]], external_ids: bool\n",
    "    ) -> pd.DataFrame:\n",
    "        user_features = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "        return user_features[user_features[Columns.User].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we specify our custom feature collector for TwoStageModel\n",
    "\n",
    "two_stage = TwoStageModel(first_stage, splitter, RerankerBase(RidgeClassifier()), feature_collector=CustomFeatureCollector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = two_stage.get_train_with_targets_for_reranker(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>PopularModel_1_score</th>\n",
       "      <th>PopularModel_1_rank</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_score</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_rank</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>979121</td>\n",
       "      <td>7107</td>\n",
       "      <td>16279.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>age_65_inf</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58982</td>\n",
       "      <td>2657</td>\n",
       "      <td>66415.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.394153</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>659982</td>\n",
       "      <td>12995</td>\n",
       "      <td>21577.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>М</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244104</td>\n",
       "      <td>4740</td>\n",
       "      <td>33831.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>781714</td>\n",
       "      <td>12995</td>\n",
       "      <td>21577.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.045084</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100203</td>\n",
       "      <td>14120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084311</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898376</td>\n",
       "      <td>16166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219737</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>551827</td>\n",
       "      <td>15531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312845</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>age_55_64</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>М</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>811434</td>\n",
       "      <td>6809</td>\n",
       "      <td>39498.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>591233</td>\n",
       "      <td>1844</td>\n",
       "      <td>24009.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>248795</td>\n",
       "      <td>12743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103223</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1065349</td>\n",
       "      <td>12192</td>\n",
       "      <td>31907.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.661924</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>508389</td>\n",
       "      <td>10942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088153</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>Ж</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>297741</td>\n",
       "      <td>8175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089087</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>920471</td>\n",
       "      <td>6402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179833</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>655761</td>\n",
       "      <td>8666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.651011</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1088944</td>\n",
       "      <td>8636</td>\n",
       "      <td>34148.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>813822</td>\n",
       "      <td>14703</td>\n",
       "      <td>16864.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>770697</td>\n",
       "      <td>11985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243271</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>559957</td>\n",
       "      <td>6809</td>\n",
       "      <td>39498.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>М</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  PopularModel_1_score  PopularModel_1_rank  \\\n",
       "0    979121     7107               16279.0                 26.0   \n",
       "1     58982     2657               66415.0                  5.0   \n",
       "2    659982    12995               21577.0                 18.0   \n",
       "3    244104     4740               33831.0                 12.0   \n",
       "4    781714    12995               21577.0                 16.0   \n",
       "5    100203    14120                   NaN                  NaN   \n",
       "6    898376    16166                   NaN                  NaN   \n",
       "7    551827    15531                   NaN                  NaN   \n",
       "8    811434     6809               39498.0                  9.0   \n",
       "9    591233     1844               24009.0                 15.0   \n",
       "10   248795    12743                   NaN                  NaN   \n",
       "11  1065349    12192               31907.0                 11.0   \n",
       "12   508389    10942                   NaN                  NaN   \n",
       "13   297741     8175                   NaN                  NaN   \n",
       "14   920471     6402                   NaN                  NaN   \n",
       "15   655761     8666                   NaN                  NaN   \n",
       "16  1088944     8636               34148.0                 12.0   \n",
       "17   813822    14703               16864.0                 25.0   \n",
       "18   770697    11985                   NaN                  NaN   \n",
       "19   559957     6809               39498.0                  9.0   \n",
       "\n",
       "    ImplicitItemKNNWrapperModel_1_score  ImplicitItemKNNWrapperModel_1_rank  \\\n",
       "0                                   NaN                                 NaN   \n",
       "1                              0.394153                                 7.0   \n",
       "2                                   NaN                                 NaN   \n",
       "3                                   NaN                                 NaN   \n",
       "4                              1.045084                                 7.0   \n",
       "5                              0.084311                                27.0   \n",
       "6                              0.219737                                 6.0   \n",
       "7                              0.312845                                12.0   \n",
       "8                                   NaN                                 NaN   \n",
       "9                                   NaN                                 NaN   \n",
       "10                             0.103223                                17.0   \n",
       "11                             0.661924                                 8.0   \n",
       "12                             0.088153                                 5.0   \n",
       "13                             0.089087                                10.0   \n",
       "14                             0.179833                                24.0   \n",
       "15                             0.651011                                13.0   \n",
       "16                                  NaN                                 NaN   \n",
       "17                                  NaN                                 NaN   \n",
       "18                             0.243271                                 5.0   \n",
       "19                                  NaN                                 NaN   \n",
       "\n",
       "    target         age        income  sex  kids_flg  \n",
       "0        0  age_65_inf  income_20_40    М       0.0  \n",
       "1        0   age_35_44  income_20_40    М       1.0  \n",
       "2        0   age_18_24  income_40_60    М       0.0  \n",
       "3        0   age_25_34  income_20_40    М       0.0  \n",
       "4        0   age_35_44  income_20_40    Ж       1.0  \n",
       "5        0   age_45_54  income_20_40    М       1.0  \n",
       "6        0   age_35_44  income_20_40    Ж       0.0  \n",
       "7        0   age_55_64  income_40_60    М       0.0  \n",
       "8        0   age_18_24  income_20_40    М       1.0  \n",
       "9        0         NaN           NaN  NaN       NaN  \n",
       "10       0         NaN           NaN  NaN       NaN  \n",
       "11       1   age_45_54  income_20_40    Ж       1.0  \n",
       "12       0   age_25_34  income_60_90    Ж       1.0  \n",
       "13       0         NaN           NaN  NaN       0.0  \n",
       "14       1   age_25_34  income_20_40    М       0.0  \n",
       "15       0         NaN           NaN  NaN       NaN  \n",
       "16       0         NaN           NaN  NaN       NaN  \n",
       "17       0   age_25_34  income_20_40    Ж       0.0  \n",
       "18       1         NaN  income_40_60    Ж       0.0  \n",
       "19       0   age_35_44  income_40_60    М       0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now our candidates also have features for users\n",
    "candidates.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "\n",
    "DATA_PATH = Path(\"data_original\")\n",
    "users = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "items = pd.read_csv(DATA_PATH / 'items.csv')\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "interactions[\"weight\"] = 1\n",
    "dataset = Dataset.construct(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare first stage models\n",
    "first_stage = [\n",
    "    CandidateGenerator(\n",
    "        model=PopularModel(),\n",
    "        num_candidates=30,\n",
    "        keep_ranks=True,\n",
    "        keep_scores=True,\n",
    "        scores_fillna_value=1.01, # when working with the GradientBoostingClassifier, you need to fill in the empty scores (e.g. max score)\n",
    "        ranks_fillna_value=31  # when working with the GradientBoostingClassifier, you need to fill in the empty ranks (e.g. min rank)\n",
    "    ), \n",
    "    CandidateGenerator(\n",
    "        model=ImplicitItemKNNWrapperModel(CosineRecommender()),\n",
    "        num_candidates=30,\n",
    "        keep_ranks=True,\n",
    "        keep_scores=True,\n",
    "        scores_fillna_value=1.01, # when working with the GradientBoostingClassifier, you need to fill in the empty scores (e.g. max score)\n",
    "        ranks_fillna_value=31  # when working with the GradientBoostingClassifier, you need to fill in the empty ranks (e.g. min rank)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Prepare splitter for selecting reranker train. Only one fold is expected!\n",
    "splitter = TimeRangeSplitter(\"7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_stage = TwoStageModel(first_stage,\n",
    "                          splitter,\n",
    "                          RerankerBase(GradientBoostingClassifier())\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rectools.models.rerank.TwoStageModel at 0x7f19244538b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_stage.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = two_stage.recommend(\n",
    "                    users=dataset.user_id_map.external_ids, \n",
    "                    dataset=dataset,\n",
    "                    k=10,\n",
    "                    filter_viewed=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13958790</th>\n",
       "      <td>1097557</td>\n",
       "      <td>10440</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958792</th>\n",
       "      <td>1097557</td>\n",
       "      <td>13865</td>\n",
       "      <td>0.505172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958791</th>\n",
       "      <td>1097557</td>\n",
       "      <td>9728</td>\n",
       "      <td>0.471941</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958793</th>\n",
       "      <td>1097557</td>\n",
       "      <td>3734</td>\n",
       "      <td>0.356907</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958794</th>\n",
       "      <td>1097557</td>\n",
       "      <td>2657</td>\n",
       "      <td>0.289822</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0.227925</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>0</td>\n",
       "      <td>4880</td>\n",
       "      <td>0.221551</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18578</th>\n",
       "      <td>0</td>\n",
       "      <td>9996</td>\n",
       "      <td>0.208693</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18597</th>\n",
       "      <td>0</td>\n",
       "      <td>12173</td>\n",
       "      <td>0.194356</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28875979</th>\n",
       "      <td>0</td>\n",
       "      <td>12324</td>\n",
       "      <td>0.174891</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9621790 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id     score  rank\n",
       "13958790  1097557    10440  0.616494     1\n",
       "13958792  1097557    13865  0.505172     2\n",
       "13958791  1097557     9728  0.471941     3\n",
       "13958793  1097557     3734  0.356907     4\n",
       "13958794  1097557     2657  0.289822     5\n",
       "...           ...      ...       ...   ...\n",
       "18576           0      142  0.227925     6\n",
       "18575           0     4880  0.221551     7\n",
       "18578           0     9996  0.208693     8\n",
       "18597           0    12173  0.194356     9\n",
       "28875979        0    12324  0.174891    10\n",
       "\n",
       "[9621790 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CrossValidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostClassifier guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To successfully launch CatBoostClassifier at the ranking stage, it is necessary to **process categorical features**: fill in empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "\n",
    "DATA_PATH = Path(\"data_original\")\n",
    "users = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "items = pd.read_csv(DATA_PATH / 'items.csv')\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "interactions[\"weight\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your any helper functions for working with loaded data\n",
    "def encode_and_clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_encode = encode_cat_cols(df)    \n",
    "    cols_with_nan = df_encode.columns[df_encode.isna().any()].tolist()\n",
    "    df_encode[cols_with_nan] = df_encode[cols_with_nan].fillna(df_encode[cols_with_nan].median())\n",
    "    return df_encode\n",
    "\n",
    "def encode_cat_cols(df: pd.DataFrame) -> pd.DataFrame:    \n",
    "    df_cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[df_cat_cols] = df[df_cat_cols].astype('category')\n",
    "    \n",
    "    for col in df_cat_cols:\n",
    "        cat_col = df[col].astype('category').cat\n",
    "        df[col] = cat_col.codes.astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding categorical data and handling missing values\n",
    "users = encode_and_clean_data(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962179, 840197)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check if all users who have interactions have a feature description (users)\n",
    "interactions[Columns.User].nunique(), users[Columns.User].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we leave only interactions where users have a characteristic description\n",
    "user_ids_with_feature = np.intersect1d(interactions[Columns.User].unique(), users[Columns.User].unique())\n",
    "interactions = interactions.query(f\"{Columns.User} in @user_ids_with_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.construct(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare first stage models\n",
    "first_stage = [\n",
    "    CandidateGenerator(\n",
    "        model=PopularModel(),\n",
    "        num_candidates=30,\n",
    "        keep_ranks=True,\n",
    "        keep_scores=True,\n",
    "    ), \n",
    "    CandidateGenerator(\n",
    "        model=ImplicitItemKNNWrapperModel(CosineRecommender()),\n",
    "        num_candidates=30,\n",
    "        keep_ranks=True,\n",
    "        keep_scores=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Prepare splitter for selecting reranker train. Only one fold is expected!\n",
    "splitter = TimeRangeSplitter(\"7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write custome feature collecting funcs for users, items and user/item pairs\n",
    "class CustomFeatureCollectorCatBoost(CandidatesFeatureCollectorBase):\n",
    "    def _get_user_features(\n",
    "        self, users: AnyIds, dataset: Dataset, fold_info: tp.Optional[tp.Dict[str, tp.Any]], external_ids: bool\n",
    "    ) -> pd.DataFrame:\n",
    "        user_features = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "        user_features = encode_and_clean_data(user_features)\n",
    "        return user_features[user_features[Columns.User].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we specify our custom feature collector for TwoStageModel\n",
    "# To transfer CatBoostClassifier we use CatBoostRerankerWrapper (for faster work with large amounts of data)\n",
    "\n",
    "two_stage = TwoStageModel(first_stage,\n",
    "                          splitter,\n",
    "                          CatBoostRerankerWrapper(CatBoostClassifier()),\n",
    "                          feature_collector=CustomFeatureCollectorCatBoost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = two_stage.get_train_with_targets_for_reranker(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>PopularModel_1_score</th>\n",
       "      <th>PopularModel_1_rank</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_score</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_rank</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1048737</td>\n",
       "      <td>16228</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.210147</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>574743</td>\n",
       "      <td>14703</td>\n",
       "      <td>14455.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681048</td>\n",
       "      <td>11778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166380</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>936296</td>\n",
       "      <td>10440</td>\n",
       "      <td>125533.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>390427</td>\n",
       "      <td>1844</td>\n",
       "      <td>20398.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155509</td>\n",
       "      <td>3734</td>\n",
       "      <td>56265.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.531710</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1022018</td>\n",
       "      <td>11502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120386</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>756483</td>\n",
       "      <td>15806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075165</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>763097</td>\n",
       "      <td>7107</td>\n",
       "      <td>14110.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>632618</td>\n",
       "      <td>142</td>\n",
       "      <td>32749.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.610799</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>997841</td>\n",
       "      <td>4880</td>\n",
       "      <td>41935.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.099902</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86486</td>\n",
       "      <td>15851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162823</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>611029</td>\n",
       "      <td>7612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792738</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12691</td>\n",
       "      <td>12995</td>\n",
       "      <td>18300.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.231592</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>934425</td>\n",
       "      <td>1844</td>\n",
       "      <td>20398.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160663</td>\n",
       "      <td>9728</td>\n",
       "      <td>101721.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>962697</td>\n",
       "      <td>14431</td>\n",
       "      <td>17069.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1016922</td>\n",
       "      <td>7107</td>\n",
       "      <td>14110.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>942693</td>\n",
       "      <td>3734</td>\n",
       "      <td>56265.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.703437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>734271</td>\n",
       "      <td>4740</td>\n",
       "      <td>22025.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  PopularModel_1_score  PopularModel_1_rank  \\\n",
       "0   1048737    16228               11855.0                 21.0   \n",
       "1    574743    14703               14455.0                 21.0   \n",
       "2    681048    11778                   NaN                  NaN   \n",
       "3    936296    10440              125533.0                  1.0   \n",
       "4    390427     1844               20398.0                 15.0   \n",
       "5    155509     3734               56265.0                  4.0   \n",
       "6   1022018    11502                   NaN                  NaN   \n",
       "7    756483    15806                   NaN                  NaN   \n",
       "8    763097     7107               14110.0                 28.0   \n",
       "9    632618      142               32749.0                  7.0   \n",
       "10   997841     4880               41935.0                  7.0   \n",
       "11    86486    15851                   NaN                  NaN   \n",
       "12   611029     7612                   NaN                  NaN   \n",
       "13    12691    12995               18300.0                 15.0   \n",
       "14   934425     1844               20398.0                 16.0   \n",
       "15   160663     9728              101721.0                  3.0   \n",
       "16   962697    14431               17069.0                 20.0   \n",
       "17  1016922     7107               14110.0                 24.0   \n",
       "18   942693     3734               56265.0                  3.0   \n",
       "19   734271     4740               22025.0                 14.0   \n",
       "\n",
       "    ImplicitItemKNNWrapperModel_1_score  ImplicitItemKNNWrapperModel_1_rank  \\\n",
       "0                              0.210147                                29.0   \n",
       "1                                   NaN                                 NaN   \n",
       "2                              0.166380                                12.0   \n",
       "3                              0.627350                                 2.0   \n",
       "4                                   NaN                                 NaN   \n",
       "5                              0.531710                                 4.0   \n",
       "6                              0.120386                                15.0   \n",
       "7                              0.075165                                28.0   \n",
       "8                                   NaN                                 NaN   \n",
       "9                              0.610799                                 7.0   \n",
       "10                             0.099902                                16.0   \n",
       "11                             0.162823                                14.0   \n",
       "12                             0.792738                                13.0   \n",
       "13                             0.231592                                16.0   \n",
       "14                                  NaN                                 NaN   \n",
       "15                             0.438135                                15.0   \n",
       "16                                  NaN                                 NaN   \n",
       "17                                  NaN                                 NaN   \n",
       "18                             0.703437                                 2.0   \n",
       "19                                  NaN                                 NaN   \n",
       "\n",
       "    target age income sex  kids_flg  \n",
       "0        0  -1     -1  -1         0  \n",
       "1        0   2      3   1         0  \n",
       "2        0   5      2   0         0  \n",
       "3        1   2      3   1         0  \n",
       "4        0   4      3   1         0  \n",
       "5        0   2      3   0         1  \n",
       "6        0   3      5   1         0  \n",
       "7        0   1      2   1         1  \n",
       "8        0   1      2   0         0  \n",
       "9        0   2      2   0         0  \n",
       "10       0   2      2   1         1  \n",
       "11       0   2      2   0         1  \n",
       "12       0   2      2   0         0  \n",
       "13       0   4      2   1         0  \n",
       "14       0   4      2   1         0  \n",
       "15       1   1      3   1         0  \n",
       "16       0   5      2   0         0  \n",
       "17       0   2      4   0         0  \n",
       "18       1   1      3   1         0  \n",
       "19       0   2      3   1         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now our candidates also have features for users\n",
    "# CatBoostClassifier can work with empty values of numeric data\n",
    "candidates.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['age', 'income', 'sex']\n",
    "\n",
    "# example parameters for running model training \n",
    "# more valid parameters here https://catboost.ai/en/docs/concepts/python-reference_pool\n",
    "fit_params = {\n",
    "    'cat_features': cat_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.122961\n",
      "0:\tlearn: 0.6228306\ttotal: 138ms\tremaining: 2m 17s\n",
      "1:\tlearn: 0.5715496\ttotal: 202ms\tremaining: 1m 40s\n",
      "2:\tlearn: 0.5343433\ttotal: 261ms\tremaining: 1m 26s\n",
      "3:\tlearn: 0.5066188\ttotal: 313ms\tremaining: 1m 18s\n",
      "4:\tlearn: 0.4860988\ttotal: 366ms\tremaining: 1m 12s\n",
      "5:\tlearn: 0.4707388\ttotal: 414ms\tremaining: 1m 8s\n",
      "6:\tlearn: 0.4587273\ttotal: 463ms\tremaining: 1m 5s\n",
      "7:\tlearn: 0.4502151\ttotal: 506ms\tremaining: 1m 2s\n",
      "8:\tlearn: 0.4435678\ttotal: 556ms\tremaining: 1m 1s\n",
      "9:\tlearn: 0.4385905\ttotal: 603ms\tremaining: 59.7s\n",
      "10:\tlearn: 0.4348583\ttotal: 655ms\tremaining: 58.9s\n",
      "11:\tlearn: 0.4309688\ttotal: 702ms\tremaining: 57.8s\n",
      "12:\tlearn: 0.4280513\ttotal: 748ms\tremaining: 56.8s\n",
      "13:\tlearn: 0.4255529\ttotal: 793ms\tremaining: 55.9s\n",
      "14:\tlearn: 0.4237005\ttotal: 844ms\tremaining: 55.4s\n",
      "15:\tlearn: 0.4216868\ttotal: 890ms\tremaining: 54.7s\n",
      "16:\tlearn: 0.4202455\ttotal: 938ms\tremaining: 54.2s\n",
      "17:\tlearn: 0.4193165\ttotal: 988ms\tremaining: 53.9s\n",
      "18:\tlearn: 0.4187122\ttotal: 1.04s\tremaining: 53.5s\n",
      "19:\tlearn: 0.4181141\ttotal: 1.08s\tremaining: 53.1s\n",
      "20:\tlearn: 0.4176978\ttotal: 1.13s\tremaining: 52.9s\n",
      "21:\tlearn: 0.4170463\ttotal: 1.18s\tremaining: 52.5s\n",
      "22:\tlearn: 0.4162416\ttotal: 1.23s\tremaining: 52.1s\n",
      "23:\tlearn: 0.4157826\ttotal: 1.28s\tremaining: 51.9s\n",
      "24:\tlearn: 0.4155254\ttotal: 1.32s\tremaining: 51.7s\n",
      "25:\tlearn: 0.4153210\ttotal: 1.38s\tremaining: 51.5s\n",
      "26:\tlearn: 0.4146188\ttotal: 1.42s\tremaining: 51.3s\n",
      "27:\tlearn: 0.4143634\ttotal: 1.48s\tremaining: 51.3s\n",
      "28:\tlearn: 0.4141830\ttotal: 1.53s\tremaining: 51.2s\n",
      "29:\tlearn: 0.4137377\ttotal: 1.57s\tremaining: 50.9s\n",
      "30:\tlearn: 0.4133231\ttotal: 1.62s\tremaining: 50.7s\n",
      "31:\tlearn: 0.4130450\ttotal: 1.67s\tremaining: 50.4s\n",
      "32:\tlearn: 0.4129569\ttotal: 1.72s\tremaining: 50.3s\n",
      "33:\tlearn: 0.4128069\ttotal: 1.77s\tremaining: 50.2s\n",
      "34:\tlearn: 0.4126193\ttotal: 1.82s\tremaining: 50.1s\n",
      "35:\tlearn: 0.4125410\ttotal: 1.87s\tremaining: 50s\n",
      "36:\tlearn: 0.4124676\ttotal: 1.92s\tremaining: 49.9s\n",
      "37:\tlearn: 0.4117645\ttotal: 1.97s\tremaining: 49.8s\n",
      "38:\tlearn: 0.4116772\ttotal: 2.02s\tremaining: 49.8s\n",
      "39:\tlearn: 0.4116336\ttotal: 2.07s\tremaining: 49.7s\n",
      "40:\tlearn: 0.4113824\ttotal: 2.12s\tremaining: 49.5s\n",
      "41:\tlearn: 0.4112766\ttotal: 2.16s\tremaining: 49.4s\n",
      "42:\tlearn: 0.4111013\ttotal: 2.21s\tremaining: 49.2s\n",
      "43:\tlearn: 0.4109747\ttotal: 2.27s\tremaining: 49.4s\n",
      "44:\tlearn: 0.4109060\ttotal: 2.33s\tremaining: 49.4s\n",
      "45:\tlearn: 0.4107499\ttotal: 2.38s\tremaining: 49.3s\n",
      "46:\tlearn: 0.4106623\ttotal: 2.43s\tremaining: 49.3s\n",
      "47:\tlearn: 0.4106592\ttotal: 2.46s\tremaining: 48.8s\n",
      "48:\tlearn: 0.4106018\ttotal: 2.65s\tremaining: 51.5s\n",
      "49:\tlearn: 0.4105719\ttotal: 2.94s\tremaining: 55.9s\n",
      "50:\tlearn: 0.4104124\ttotal: 3.17s\tremaining: 59s\n",
      "51:\tlearn: 0.4103203\ttotal: 3.44s\tremaining: 1m 2s\n",
      "52:\tlearn: 0.4102884\ttotal: 3.69s\tremaining: 1m 5s\n",
      "53:\tlearn: 0.4101995\ttotal: 3.94s\tremaining: 1m 9s\n",
      "54:\tlearn: 0.4101331\ttotal: 4.28s\tremaining: 1m 13s\n",
      "55:\tlearn: 0.4100734\ttotal: 4.54s\tremaining: 1m 16s\n",
      "56:\tlearn: 0.4098357\ttotal: 4.8s\tremaining: 1m 19s\n",
      "57:\tlearn: 0.4097761\ttotal: 5.02s\tremaining: 1m 21s\n",
      "58:\tlearn: 0.4097226\ttotal: 5.26s\tremaining: 1m 23s\n",
      "59:\tlearn: 0.4096477\ttotal: 5.5s\tremaining: 1m 26s\n",
      "60:\tlearn: 0.4096188\ttotal: 5.62s\tremaining: 1m 26s\n",
      "61:\tlearn: 0.4095743\ttotal: 5.75s\tremaining: 1m 27s\n",
      "62:\tlearn: 0.4095700\ttotal: 5.83s\tremaining: 1m 26s\n",
      "63:\tlearn: 0.4095346\ttotal: 6.04s\tremaining: 1m 28s\n",
      "64:\tlearn: 0.4095346\ttotal: 6.09s\tremaining: 1m 27s\n",
      "65:\tlearn: 0.4095009\ttotal: 6.26s\tremaining: 1m 28s\n",
      "66:\tlearn: 0.4093762\ttotal: 6.42s\tremaining: 1m 29s\n",
      "67:\tlearn: 0.4093212\ttotal: 6.55s\tremaining: 1m 29s\n",
      "68:\tlearn: 0.4092820\ttotal: 6.7s\tremaining: 1m 30s\n",
      "69:\tlearn: 0.4091291\ttotal: 6.88s\tremaining: 1m 31s\n",
      "70:\tlearn: 0.4088034\ttotal: 7.06s\tremaining: 1m 32s\n",
      "71:\tlearn: 0.4087132\ttotal: 7.25s\tremaining: 1m 33s\n",
      "72:\tlearn: 0.4086553\ttotal: 7.44s\tremaining: 1m 34s\n",
      "73:\tlearn: 0.4085503\ttotal: 7.58s\tremaining: 1m 34s\n",
      "74:\tlearn: 0.4085135\ttotal: 7.67s\tremaining: 1m 34s\n",
      "75:\tlearn: 0.4085011\ttotal: 7.74s\tremaining: 1m 34s\n",
      "76:\tlearn: 0.4084113\ttotal: 7.86s\tremaining: 1m 34s\n",
      "77:\tlearn: 0.4083769\ttotal: 7.94s\tremaining: 1m 33s\n",
      "78:\tlearn: 0.4083756\ttotal: 8s\tremaining: 1m 33s\n",
      "79:\tlearn: 0.4083381\ttotal: 8.1s\tremaining: 1m 33s\n",
      "80:\tlearn: 0.4083197\ttotal: 8.17s\tremaining: 1m 32s\n",
      "81:\tlearn: 0.4082851\ttotal: 8.22s\tremaining: 1m 32s\n",
      "82:\tlearn: 0.4082381\ttotal: 8.3s\tremaining: 1m 31s\n",
      "83:\tlearn: 0.4081671\ttotal: 8.37s\tremaining: 1m 31s\n",
      "84:\tlearn: 0.4081550\ttotal: 8.46s\tremaining: 1m 31s\n",
      "85:\tlearn: 0.4081460\ttotal: 8.51s\tremaining: 1m 30s\n",
      "86:\tlearn: 0.4081127\ttotal: 8.62s\tremaining: 1m 30s\n",
      "87:\tlearn: 0.4080578\ttotal: 8.71s\tremaining: 1m 30s\n",
      "88:\tlearn: 0.4080268\ttotal: 8.83s\tremaining: 1m 30s\n",
      "89:\tlearn: 0.4080215\ttotal: 8.91s\tremaining: 1m 30s\n",
      "90:\tlearn: 0.4080069\ttotal: 8.97s\tremaining: 1m 29s\n",
      "91:\tlearn: 0.4079893\ttotal: 9.02s\tremaining: 1m 29s\n",
      "92:\tlearn: 0.4079578\ttotal: 9.09s\tremaining: 1m 28s\n",
      "93:\tlearn: 0.4079513\ttotal: 9.16s\tremaining: 1m 28s\n",
      "94:\tlearn: 0.4079405\ttotal: 9.23s\tremaining: 1m 27s\n",
      "95:\tlearn: 0.4079200\ttotal: 9.3s\tremaining: 1m 27s\n",
      "96:\tlearn: 0.4078959\ttotal: 9.39s\tremaining: 1m 27s\n",
      "97:\tlearn: 0.4078328\ttotal: 9.46s\tremaining: 1m 27s\n",
      "98:\tlearn: 0.4078001\ttotal: 9.52s\tremaining: 1m 26s\n",
      "99:\tlearn: 0.4077600\ttotal: 9.61s\tremaining: 1m 26s\n",
      "100:\tlearn: 0.4076761\ttotal: 9.68s\tremaining: 1m 26s\n",
      "101:\tlearn: 0.4076665\ttotal: 9.74s\tremaining: 1m 25s\n",
      "102:\tlearn: 0.4076235\ttotal: 9.8s\tremaining: 1m 25s\n",
      "103:\tlearn: 0.4076115\ttotal: 9.85s\tremaining: 1m 24s\n",
      "104:\tlearn: 0.4075834\ttotal: 9.93s\tremaining: 1m 24s\n",
      "105:\tlearn: 0.4075077\ttotal: 9.98s\tremaining: 1m 24s\n",
      "106:\tlearn: 0.4075036\ttotal: 10s\tremaining: 1m 23s\n",
      "107:\tlearn: 0.4074865\ttotal: 10.1s\tremaining: 1m 23s\n",
      "108:\tlearn: 0.4074534\ttotal: 10.2s\tremaining: 1m 23s\n",
      "109:\tlearn: 0.4074093\ttotal: 10.3s\tremaining: 1m 22s\n",
      "110:\tlearn: 0.4073175\ttotal: 10.3s\tremaining: 1m 22s\n",
      "111:\tlearn: 0.4072779\ttotal: 10.4s\tremaining: 1m 22s\n",
      "112:\tlearn: 0.4072288\ttotal: 10.5s\tremaining: 1m 22s\n",
      "113:\tlearn: 0.4071909\ttotal: 10.5s\tremaining: 1m 21s\n",
      "114:\tlearn: 0.4071057\ttotal: 10.6s\tremaining: 1m 21s\n",
      "115:\tlearn: 0.4070678\ttotal: 10.7s\tremaining: 1m 21s\n",
      "116:\tlearn: 0.4070449\ttotal: 10.7s\tremaining: 1m 21s\n",
      "117:\tlearn: 0.4070164\ttotal: 10.8s\tremaining: 1m 20s\n",
      "118:\tlearn: 0.4069936\ttotal: 10.9s\tremaining: 1m 20s\n",
      "119:\tlearn: 0.4069591\ttotal: 10.9s\tremaining: 1m 20s\n",
      "120:\tlearn: 0.4069225\ttotal: 11s\tremaining: 1m 19s\n",
      "121:\tlearn: 0.4068567\ttotal: 11.1s\tremaining: 1m 19s\n",
      "122:\tlearn: 0.4068197\ttotal: 11.1s\tremaining: 1m 19s\n",
      "123:\tlearn: 0.4067835\ttotal: 11.2s\tremaining: 1m 18s\n",
      "124:\tlearn: 0.4067749\ttotal: 11.2s\tremaining: 1m 18s\n",
      "125:\tlearn: 0.4067121\ttotal: 11.3s\tremaining: 1m 18s\n",
      "126:\tlearn: 0.4066846\ttotal: 11.4s\tremaining: 1m 18s\n",
      "127:\tlearn: 0.4066645\ttotal: 11.5s\tremaining: 1m 18s\n",
      "128:\tlearn: 0.4066203\ttotal: 11.5s\tremaining: 1m 17s\n",
      "129:\tlearn: 0.4065692\ttotal: 11.6s\tremaining: 1m 17s\n",
      "130:\tlearn: 0.4065477\ttotal: 11.6s\tremaining: 1m 17s\n",
      "131:\tlearn: 0.4065222\ttotal: 11.7s\tremaining: 1m 16s\n",
      "132:\tlearn: 0.4064771\ttotal: 11.8s\tremaining: 1m 16s\n",
      "133:\tlearn: 0.4064533\ttotal: 11.8s\tremaining: 1m 16s\n",
      "134:\tlearn: 0.4064399\ttotal: 11.9s\tremaining: 1m 16s\n",
      "135:\tlearn: 0.4063798\ttotal: 11.9s\tremaining: 1m 15s\n",
      "136:\tlearn: 0.4063440\ttotal: 12s\tremaining: 1m 15s\n",
      "137:\tlearn: 0.4062771\ttotal: 12.1s\tremaining: 1m 15s\n",
      "138:\tlearn: 0.4062647\ttotal: 12.1s\tremaining: 1m 15s\n",
      "139:\tlearn: 0.4062596\ttotal: 12.2s\tremaining: 1m 14s\n",
      "140:\tlearn: 0.4062400\ttotal: 12.2s\tremaining: 1m 14s\n",
      "141:\tlearn: 0.4062051\ttotal: 12.3s\tremaining: 1m 14s\n",
      "142:\tlearn: 0.4061929\ttotal: 12.3s\tremaining: 1m 13s\n",
      "143:\tlearn: 0.4061848\ttotal: 12.4s\tremaining: 1m 13s\n",
      "144:\tlearn: 0.4061474\ttotal: 12.4s\tremaining: 1m 13s\n",
      "145:\tlearn: 0.4061142\ttotal: 12.5s\tremaining: 1m 13s\n",
      "146:\tlearn: 0.4061081\ttotal: 12.5s\tremaining: 1m 12s\n",
      "147:\tlearn: 0.4060882\ttotal: 12.6s\tremaining: 1m 12s\n",
      "148:\tlearn: 0.4060446\ttotal: 12.6s\tremaining: 1m 12s\n",
      "149:\tlearn: 0.4060177\ttotal: 12.7s\tremaining: 1m 12s\n",
      "150:\tlearn: 0.4060115\ttotal: 12.8s\tremaining: 1m 11s\n",
      "151:\tlearn: 0.4059649\ttotal: 12.8s\tremaining: 1m 11s\n",
      "152:\tlearn: 0.4059568\ttotal: 12.9s\tremaining: 1m 11s\n",
      "153:\tlearn: 0.4059428\ttotal: 12.9s\tremaining: 1m 10s\n",
      "154:\tlearn: 0.4059157\ttotal: 12.9s\tremaining: 1m 10s\n",
      "155:\tlearn: 0.4058796\ttotal: 13s\tremaining: 1m 10s\n",
      "156:\tlearn: 0.4058310\ttotal: 13s\tremaining: 1m 10s\n",
      "157:\tlearn: 0.4058231\ttotal: 13.1s\tremaining: 1m 9s\n",
      "158:\tlearn: 0.4058024\ttotal: 13.1s\tremaining: 1m 9s\n",
      "159:\tlearn: 0.4057866\ttotal: 13.2s\tremaining: 1m 9s\n",
      "160:\tlearn: 0.4057554\ttotal: 13.2s\tremaining: 1m 9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161:\tlearn: 0.4057390\ttotal: 13.3s\tremaining: 1m 8s\n",
      "162:\tlearn: 0.4056988\ttotal: 13.4s\tremaining: 1m 8s\n",
      "163:\tlearn: 0.4056853\ttotal: 13.4s\tremaining: 1m 8s\n",
      "164:\tlearn: 0.4056760\ttotal: 13.4s\tremaining: 1m 8s\n",
      "165:\tlearn: 0.4056583\ttotal: 13.5s\tremaining: 1m 7s\n",
      "166:\tlearn: 0.4056133\ttotal: 13.5s\tremaining: 1m 7s\n",
      "167:\tlearn: 0.4055993\ttotal: 13.6s\tremaining: 1m 7s\n",
      "168:\tlearn: 0.4055774\ttotal: 13.6s\tremaining: 1m 7s\n",
      "169:\tlearn: 0.4055563\ttotal: 13.7s\tremaining: 1m 6s\n",
      "170:\tlearn: 0.4055460\ttotal: 13.7s\tremaining: 1m 6s\n",
      "171:\tlearn: 0.4055233\ttotal: 13.8s\tremaining: 1m 6s\n",
      "172:\tlearn: 0.4055165\ttotal: 13.8s\tremaining: 1m 6s\n",
      "173:\tlearn: 0.4055012\ttotal: 13.9s\tremaining: 1m 5s\n",
      "174:\tlearn: 0.4054941\ttotal: 13.9s\tremaining: 1m 5s\n",
      "175:\tlearn: 0.4054487\ttotal: 14s\tremaining: 1m 5s\n",
      "176:\tlearn: 0.4054157\ttotal: 14s\tremaining: 1m 5s\n",
      "177:\tlearn: 0.4054015\ttotal: 14.1s\tremaining: 1m 4s\n",
      "178:\tlearn: 0.4053727\ttotal: 14.1s\tremaining: 1m 4s\n",
      "179:\tlearn: 0.4053459\ttotal: 14.2s\tremaining: 1m 4s\n",
      "180:\tlearn: 0.4053073\ttotal: 14.2s\tremaining: 1m 4s\n",
      "181:\tlearn: 0.4052927\ttotal: 14.3s\tremaining: 1m 4s\n",
      "182:\tlearn: 0.4052868\ttotal: 14.3s\tremaining: 1m 3s\n",
      "183:\tlearn: 0.4052559\ttotal: 14.4s\tremaining: 1m 3s\n",
      "184:\tlearn: 0.4052074\ttotal: 14.5s\tremaining: 1m 3s\n",
      "185:\tlearn: 0.4051907\ttotal: 14.5s\tremaining: 1m 3s\n",
      "186:\tlearn: 0.4051770\ttotal: 14.5s\tremaining: 1m 3s\n",
      "187:\tlearn: 0.4051647\ttotal: 14.6s\tremaining: 1m 3s\n",
      "188:\tlearn: 0.4051447\ttotal: 14.7s\tremaining: 1m 2s\n",
      "189:\tlearn: 0.4051236\ttotal: 14.7s\tremaining: 1m 2s\n",
      "190:\tlearn: 0.4051063\ttotal: 14.8s\tremaining: 1m 2s\n",
      "191:\tlearn: 0.4050891\ttotal: 14.8s\tremaining: 1m 2s\n",
      "192:\tlearn: 0.4050687\ttotal: 14.9s\tremaining: 1m 2s\n",
      "193:\tlearn: 0.4050245\ttotal: 14.9s\tremaining: 1m 1s\n",
      "194:\tlearn: 0.4050181\ttotal: 15s\tremaining: 1m 1s\n",
      "195:\tlearn: 0.4049768\ttotal: 15s\tremaining: 1m 1s\n",
      "196:\tlearn: 0.4049534\ttotal: 15.1s\tremaining: 1m 1s\n",
      "197:\tlearn: 0.4049513\ttotal: 15.1s\tremaining: 1m 1s\n",
      "198:\tlearn: 0.4049231\ttotal: 15.2s\tremaining: 1m 1s\n",
      "199:\tlearn: 0.4048855\ttotal: 15.2s\tremaining: 1m\n",
      "200:\tlearn: 0.4048581\ttotal: 15.3s\tremaining: 1m\n",
      "201:\tlearn: 0.4048498\ttotal: 15.3s\tremaining: 1m\n",
      "202:\tlearn: 0.4048159\ttotal: 15.4s\tremaining: 1m\n",
      "203:\tlearn: 0.4048077\ttotal: 15.4s\tremaining: 1m\n",
      "204:\tlearn: 0.4047646\ttotal: 15.5s\tremaining: 1m\n",
      "205:\tlearn: 0.4047524\ttotal: 15.5s\tremaining: 59.8s\n",
      "206:\tlearn: 0.4047288\ttotal: 15.6s\tremaining: 59.7s\n",
      "207:\tlearn: 0.4047252\ttotal: 15.6s\tremaining: 59.5s\n",
      "208:\tlearn: 0.4047035\ttotal: 15.7s\tremaining: 59.3s\n",
      "209:\tlearn: 0.4046978\ttotal: 15.7s\tremaining: 59.1s\n",
      "210:\tlearn: 0.4046874\ttotal: 15.7s\tremaining: 58.9s\n",
      "211:\tlearn: 0.4046773\ttotal: 15.8s\tremaining: 58.7s\n",
      "212:\tlearn: 0.4046526\ttotal: 15.8s\tremaining: 58.5s\n",
      "213:\tlearn: 0.4046043\ttotal: 15.9s\tremaining: 58.4s\n",
      "214:\tlearn: 0.4045895\ttotal: 15.9s\tremaining: 58.2s\n",
      "215:\tlearn: 0.4045603\ttotal: 16s\tremaining: 58.1s\n",
      "216:\tlearn: 0.4045340\ttotal: 16s\tremaining: 57.9s\n",
      "217:\tlearn: 0.4044911\ttotal: 16.1s\tremaining: 57.7s\n",
      "218:\tlearn: 0.4044738\ttotal: 16.1s\tremaining: 57.6s\n",
      "219:\tlearn: 0.4044630\ttotal: 16.2s\tremaining: 57.4s\n",
      "220:\tlearn: 0.4044389\ttotal: 16.2s\tremaining: 57.3s\n",
      "221:\tlearn: 0.4044353\ttotal: 16.3s\tremaining: 57.1s\n",
      "222:\tlearn: 0.4044196\ttotal: 16.3s\tremaining: 56.9s\n",
      "223:\tlearn: 0.4044065\ttotal: 16.4s\tremaining: 56.8s\n",
      "224:\tlearn: 0.4043819\ttotal: 16.4s\tremaining: 56.6s\n",
      "225:\tlearn: 0.4043575\ttotal: 16.5s\tremaining: 56.5s\n",
      "226:\tlearn: 0.4043502\ttotal: 16.5s\tremaining: 56.3s\n",
      "227:\tlearn: 0.4043277\ttotal: 16.6s\tremaining: 56.2s\n",
      "228:\tlearn: 0.4043214\ttotal: 16.6s\tremaining: 56s\n",
      "229:\tlearn: 0.4043112\ttotal: 16.7s\tremaining: 55.8s\n",
      "230:\tlearn: 0.4042936\ttotal: 16.7s\tremaining: 55.6s\n",
      "231:\tlearn: 0.4042870\ttotal: 16.8s\tremaining: 55.5s\n",
      "232:\tlearn: 0.4042729\ttotal: 16.8s\tremaining: 55.4s\n",
      "233:\tlearn: 0.4042590\ttotal: 16.9s\tremaining: 55.2s\n",
      "234:\tlearn: 0.4041230\ttotal: 16.9s\tremaining: 55.1s\n",
      "235:\tlearn: 0.4040999\ttotal: 17s\tremaining: 55s\n",
      "236:\tlearn: 0.4040915\ttotal: 17s\tremaining: 54.8s\n",
      "237:\tlearn: 0.4040760\ttotal: 17.1s\tremaining: 54.7s\n",
      "238:\tlearn: 0.4040457\ttotal: 17.1s\tremaining: 54.5s\n",
      "239:\tlearn: 0.4040224\ttotal: 17.2s\tremaining: 54.4s\n",
      "240:\tlearn: 0.4040149\ttotal: 17.2s\tremaining: 54.2s\n",
      "241:\tlearn: 0.4039923\ttotal: 17.3s\tremaining: 54.1s\n",
      "242:\tlearn: 0.4039873\ttotal: 17.3s\tremaining: 53.9s\n",
      "243:\tlearn: 0.4039856\ttotal: 17.4s\tremaining: 53.8s\n",
      "244:\tlearn: 0.4039734\ttotal: 17.4s\tremaining: 53.7s\n",
      "245:\tlearn: 0.4039513\ttotal: 17.5s\tremaining: 53.6s\n",
      "246:\tlearn: 0.4039151\ttotal: 17.5s\tremaining: 53.4s\n",
      "247:\tlearn: 0.4038881\ttotal: 17.6s\tremaining: 53.3s\n",
      "248:\tlearn: 0.4038738\ttotal: 17.6s\tremaining: 53.2s\n",
      "249:\tlearn: 0.4038336\ttotal: 17.7s\tremaining: 53s\n",
      "250:\tlearn: 0.4038219\ttotal: 17.7s\tremaining: 52.9s\n",
      "251:\tlearn: 0.4037986\ttotal: 17.8s\tremaining: 52.8s\n",
      "252:\tlearn: 0.4037795\ttotal: 17.8s\tremaining: 52.6s\n",
      "253:\tlearn: 0.4037536\ttotal: 17.9s\tremaining: 52.5s\n",
      "254:\tlearn: 0.4037458\ttotal: 17.9s\tremaining: 52.3s\n",
      "255:\tlearn: 0.4037289\ttotal: 17.9s\tremaining: 52.2s\n",
      "256:\tlearn: 0.4037221\ttotal: 18s\tremaining: 52s\n",
      "257:\tlearn: 0.4037124\ttotal: 18s\tremaining: 51.8s\n",
      "258:\tlearn: 0.4037082\ttotal: 18.1s\tremaining: 51.7s\n",
      "259:\tlearn: 0.4036673\ttotal: 18.1s\tremaining: 51.6s\n",
      "260:\tlearn: 0.4036574\ttotal: 18.2s\tremaining: 51.4s\n",
      "261:\tlearn: 0.4036437\ttotal: 18.2s\tremaining: 51.3s\n",
      "262:\tlearn: 0.4036407\ttotal: 18.3s\tremaining: 51.2s\n",
      "263:\tlearn: 0.4036261\ttotal: 18.3s\tremaining: 51.1s\n",
      "264:\tlearn: 0.4036258\ttotal: 18.3s\tremaining: 50.9s\n",
      "265:\tlearn: 0.4035993\ttotal: 18.4s\tremaining: 50.7s\n",
      "266:\tlearn: 0.4035737\ttotal: 18.4s\tremaining: 50.6s\n",
      "267:\tlearn: 0.4035491\ttotal: 18.5s\tremaining: 50.5s\n",
      "268:\tlearn: 0.4035423\ttotal: 18.5s\tremaining: 50.3s\n",
      "269:\tlearn: 0.4035137\ttotal: 18.6s\tremaining: 50.2s\n",
      "270:\tlearn: 0.4035100\ttotal: 18.6s\tremaining: 50.1s\n",
      "271:\tlearn: 0.4034815\ttotal: 18.7s\tremaining: 50s\n",
      "272:\tlearn: 0.4034728\ttotal: 18.7s\tremaining: 49.9s\n",
      "273:\tlearn: 0.4034396\ttotal: 18.8s\tremaining: 49.7s\n",
      "274:\tlearn: 0.4034196\ttotal: 18.8s\tremaining: 49.6s\n",
      "275:\tlearn: 0.4034077\ttotal: 18.9s\tremaining: 49.5s\n",
      "276:\tlearn: 0.4034066\ttotal: 18.9s\tremaining: 49.4s\n",
      "277:\tlearn: 0.4033813\ttotal: 19s\tremaining: 49.3s\n",
      "278:\tlearn: 0.4033624\ttotal: 19s\tremaining: 49.2s\n",
      "279:\tlearn: 0.4033516\ttotal: 19.1s\tremaining: 49s\n",
      "280:\tlearn: 0.4033354\ttotal: 19.1s\tremaining: 48.9s\n",
      "281:\tlearn: 0.4033122\ttotal: 19.2s\tremaining: 48.8s\n",
      "282:\tlearn: 0.4032977\ttotal: 19.2s\tremaining: 48.7s\n",
      "283:\tlearn: 0.4032669\ttotal: 19.3s\tremaining: 48.6s\n",
      "284:\tlearn: 0.4032624\ttotal: 19.3s\tremaining: 48.4s\n",
      "285:\tlearn: 0.4032599\ttotal: 19.3s\tremaining: 48.3s\n",
      "286:\tlearn: 0.4032412\ttotal: 19.4s\tremaining: 48.2s\n",
      "287:\tlearn: 0.4032218\ttotal: 19.4s\tremaining: 48.1s\n",
      "288:\tlearn: 0.4032017\ttotal: 19.5s\tremaining: 47.9s\n",
      "289:\tlearn: 0.4031897\ttotal: 19.5s\tremaining: 47.8s\n",
      "290:\tlearn: 0.4031830\ttotal: 19.6s\tremaining: 47.7s\n",
      "291:\tlearn: 0.4031653\ttotal: 19.6s\tremaining: 47.6s\n",
      "292:\tlearn: 0.4031513\ttotal: 19.7s\tremaining: 47.5s\n",
      "293:\tlearn: 0.4031334\ttotal: 19.7s\tremaining: 47.4s\n",
      "294:\tlearn: 0.4031074\ttotal: 19.8s\tremaining: 47.3s\n",
      "295:\tlearn: 0.4030784\ttotal: 19.8s\tremaining: 47.2s\n",
      "296:\tlearn: 0.4030618\ttotal: 19.9s\tremaining: 47s\n",
      "297:\tlearn: 0.4030475\ttotal: 19.9s\tremaining: 46.9s\n",
      "298:\tlearn: 0.4030329\ttotal: 20s\tremaining: 46.8s\n",
      "299:\tlearn: 0.4030189\ttotal: 20s\tremaining: 46.7s\n",
      "300:\tlearn: 0.4030144\ttotal: 20.1s\tremaining: 46.6s\n",
      "301:\tlearn: 0.4030104\ttotal: 20.1s\tremaining: 46.5s\n",
      "302:\tlearn: 0.4029726\ttotal: 20.1s\tremaining: 46.3s\n",
      "303:\tlearn: 0.4029396\ttotal: 20.2s\tremaining: 46.3s\n",
      "304:\tlearn: 0.4029336\ttotal: 20.2s\tremaining: 46.1s\n",
      "305:\tlearn: 0.4029145\ttotal: 20.3s\tremaining: 46s\n",
      "306:\tlearn: 0.4029021\ttotal: 20.3s\tremaining: 45.9s\n",
      "307:\tlearn: 0.4028842\ttotal: 20.4s\tremaining: 45.8s\n",
      "308:\tlearn: 0.4028789\ttotal: 20.4s\tremaining: 45.6s\n",
      "309:\tlearn: 0.4028677\ttotal: 20.5s\tremaining: 45.5s\n",
      "310:\tlearn: 0.4028587\ttotal: 20.5s\tremaining: 45.4s\n",
      "311:\tlearn: 0.4028516\ttotal: 20.6s\tremaining: 45.3s\n",
      "312:\tlearn: 0.4028291\ttotal: 20.6s\tremaining: 45.2s\n",
      "313:\tlearn: 0.4027981\ttotal: 20.6s\tremaining: 45.1s\n",
      "314:\tlearn: 0.4027935\ttotal: 20.7s\tremaining: 45s\n",
      "315:\tlearn: 0.4027802\ttotal: 20.7s\tremaining: 44.9s\n",
      "316:\tlearn: 0.4027676\ttotal: 20.8s\tremaining: 44.8s\n",
      "317:\tlearn: 0.4027609\ttotal: 20.8s\tremaining: 44.6s\n",
      "318:\tlearn: 0.4027459\ttotal: 20.9s\tremaining: 44.5s\n",
      "319:\tlearn: 0.4027417\ttotal: 20.9s\tremaining: 44.4s\n",
      "320:\tlearn: 0.4027296\ttotal: 21s\tremaining: 44.3s\n",
      "321:\tlearn: 0.4027144\ttotal: 21s\tremaining: 44.2s\n",
      "322:\tlearn: 0.4027058\ttotal: 21s\tremaining: 44.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323:\tlearn: 0.4026987\ttotal: 21.1s\tremaining: 44s\n",
      "324:\tlearn: 0.4026838\ttotal: 21.1s\tremaining: 43.9s\n",
      "325:\tlearn: 0.4026774\ttotal: 21.2s\tremaining: 43.8s\n",
      "326:\tlearn: 0.4026709\ttotal: 21.2s\tremaining: 43.7s\n",
      "327:\tlearn: 0.4026532\ttotal: 21.3s\tremaining: 43.6s\n",
      "328:\tlearn: 0.4026317\ttotal: 21.3s\tremaining: 43.5s\n",
      "329:\tlearn: 0.4026159\ttotal: 21.4s\tremaining: 43.4s\n",
      "330:\tlearn: 0.4026120\ttotal: 21.4s\tremaining: 43.3s\n",
      "331:\tlearn: 0.4025904\ttotal: 21.5s\tremaining: 43.2s\n",
      "332:\tlearn: 0.4025839\ttotal: 21.5s\tremaining: 43.1s\n",
      "333:\tlearn: 0.4025646\ttotal: 21.6s\tremaining: 43s\n",
      "334:\tlearn: 0.4025529\ttotal: 21.6s\tremaining: 42.9s\n",
      "335:\tlearn: 0.4025291\ttotal: 21.7s\tremaining: 42.8s\n",
      "336:\tlearn: 0.4025184\ttotal: 21.7s\tremaining: 42.7s\n",
      "337:\tlearn: 0.4025002\ttotal: 21.8s\tremaining: 42.6s\n",
      "338:\tlearn: 0.4024951\ttotal: 21.8s\tremaining: 42.5s\n",
      "339:\tlearn: 0.4024851\ttotal: 21.9s\tremaining: 42.5s\n",
      "340:\tlearn: 0.4024703\ttotal: 21.9s\tremaining: 42.4s\n",
      "341:\tlearn: 0.4024453\ttotal: 22s\tremaining: 42.2s\n",
      "342:\tlearn: 0.4024391\ttotal: 22s\tremaining: 42.1s\n",
      "343:\tlearn: 0.4024253\ttotal: 22s\tremaining: 42s\n",
      "344:\tlearn: 0.4024207\ttotal: 22.1s\tremaining: 41.9s\n",
      "345:\tlearn: 0.4024181\ttotal: 22.1s\tremaining: 41.8s\n",
      "346:\tlearn: 0.4023963\ttotal: 22.2s\tremaining: 41.7s\n",
      "347:\tlearn: 0.4023873\ttotal: 22.2s\tremaining: 41.6s\n",
      "348:\tlearn: 0.4023834\ttotal: 22.2s\tremaining: 41.5s\n",
      "349:\tlearn: 0.4023779\ttotal: 22.3s\tremaining: 41.4s\n",
      "350:\tlearn: 0.4023589\ttotal: 22.3s\tremaining: 41.3s\n",
      "351:\tlearn: 0.4023368\ttotal: 22.4s\tremaining: 41.2s\n",
      "352:\tlearn: 0.4023327\ttotal: 22.4s\tremaining: 41.1s\n",
      "353:\tlearn: 0.4023152\ttotal: 22.5s\tremaining: 41s\n",
      "354:\tlearn: 0.4022977\ttotal: 22.5s\tremaining: 40.9s\n",
      "355:\tlearn: 0.4022707\ttotal: 22.6s\tremaining: 40.8s\n",
      "356:\tlearn: 0.4022452\ttotal: 22.6s\tremaining: 40.8s\n",
      "357:\tlearn: 0.4022170\ttotal: 22.7s\tremaining: 40.7s\n",
      "358:\tlearn: 0.4022078\ttotal: 22.7s\tremaining: 40.6s\n",
      "359:\tlearn: 0.4021834\ttotal: 22.8s\tremaining: 40.5s\n",
      "360:\tlearn: 0.4021640\ttotal: 22.8s\tremaining: 40.4s\n",
      "361:\tlearn: 0.4021400\ttotal: 22.9s\tremaining: 40.4s\n",
      "362:\tlearn: 0.4021340\ttotal: 22.9s\tremaining: 40.3s\n",
      "363:\tlearn: 0.4021133\ttotal: 23s\tremaining: 40.2s\n",
      "364:\tlearn: 0.4021050\ttotal: 23s\tremaining: 40.1s\n",
      "365:\tlearn: 0.4020990\ttotal: 23.1s\tremaining: 40s\n",
      "366:\tlearn: 0.4020771\ttotal: 23.1s\tremaining: 39.9s\n",
      "367:\tlearn: 0.4020592\ttotal: 23.2s\tremaining: 39.8s\n",
      "368:\tlearn: 0.4020516\ttotal: 23.2s\tremaining: 39.7s\n",
      "369:\tlearn: 0.4020215\ttotal: 23.3s\tremaining: 39.6s\n",
      "370:\tlearn: 0.4020204\ttotal: 23.3s\tremaining: 39.5s\n",
      "371:\tlearn: 0.4020079\ttotal: 23.3s\tremaining: 39.4s\n",
      "372:\tlearn: 0.4020050\ttotal: 23.4s\tremaining: 39.3s\n",
      "373:\tlearn: 0.4019911\ttotal: 23.4s\tremaining: 39.2s\n",
      "374:\tlearn: 0.4019851\ttotal: 23.5s\tremaining: 39.1s\n",
      "375:\tlearn: 0.4019784\ttotal: 23.5s\tremaining: 39s\n",
      "376:\tlearn: 0.4019679\ttotal: 23.6s\tremaining: 38.9s\n",
      "377:\tlearn: 0.4019499\ttotal: 23.6s\tremaining: 38.8s\n",
      "378:\tlearn: 0.4019348\ttotal: 23.6s\tremaining: 38.7s\n",
      "379:\tlearn: 0.4019105\ttotal: 23.7s\tremaining: 38.6s\n",
      "380:\tlearn: 0.4018994\ttotal: 23.7s\tremaining: 38.6s\n",
      "381:\tlearn: 0.4018843\ttotal: 23.8s\tremaining: 38.5s\n",
      "382:\tlearn: 0.4018677\ttotal: 23.8s\tremaining: 38.4s\n",
      "383:\tlearn: 0.4018532\ttotal: 23.9s\tremaining: 38.3s\n",
      "384:\tlearn: 0.4018409\ttotal: 23.9s\tremaining: 38.2s\n",
      "385:\tlearn: 0.4018270\ttotal: 24s\tremaining: 38.1s\n",
      "386:\tlearn: 0.4018082\ttotal: 24s\tremaining: 38.1s\n",
      "387:\tlearn: 0.4018010\ttotal: 24.1s\tremaining: 38s\n",
      "388:\tlearn: 0.4017839\ttotal: 24.1s\tremaining: 37.9s\n",
      "389:\tlearn: 0.4017756\ttotal: 24.2s\tremaining: 37.8s\n",
      "390:\tlearn: 0.4017538\ttotal: 24.2s\tremaining: 37.7s\n",
      "391:\tlearn: 0.4017334\ttotal: 24.2s\tremaining: 37.6s\n",
      "392:\tlearn: 0.4017293\ttotal: 24.3s\tremaining: 37.5s\n",
      "393:\tlearn: 0.4017247\ttotal: 24.3s\tremaining: 37.4s\n",
      "394:\tlearn: 0.4017159\ttotal: 24.4s\tremaining: 37.4s\n",
      "395:\tlearn: 0.4017004\ttotal: 24.4s\tremaining: 37.3s\n",
      "396:\tlearn: 0.4016798\ttotal: 24.5s\tremaining: 37.2s\n",
      "397:\tlearn: 0.4016632\ttotal: 24.5s\tremaining: 37.1s\n",
      "398:\tlearn: 0.4016511\ttotal: 24.6s\tremaining: 37.1s\n",
      "399:\tlearn: 0.4016503\ttotal: 24.7s\tremaining: 37s\n",
      "400:\tlearn: 0.4016359\ttotal: 24.7s\tremaining: 36.9s\n",
      "401:\tlearn: 0.4016234\ttotal: 24.7s\tremaining: 36.8s\n",
      "402:\tlearn: 0.4016216\ttotal: 24.8s\tremaining: 36.7s\n",
      "403:\tlearn: 0.4016070\ttotal: 24.8s\tremaining: 36.6s\n",
      "404:\tlearn: 0.4015978\ttotal: 24.9s\tremaining: 36.5s\n",
      "405:\tlearn: 0.4015686\ttotal: 24.9s\tremaining: 36.5s\n",
      "406:\tlearn: 0.4015660\ttotal: 25s\tremaining: 36.4s\n",
      "407:\tlearn: 0.4015533\ttotal: 25s\tremaining: 36.3s\n",
      "408:\tlearn: 0.4015505\ttotal: 25.1s\tremaining: 36.2s\n",
      "409:\tlearn: 0.4015383\ttotal: 25.1s\tremaining: 36.1s\n",
      "410:\tlearn: 0.4015200\ttotal: 25.1s\tremaining: 36s\n",
      "411:\tlearn: 0.4015089\ttotal: 25.2s\tremaining: 35.9s\n",
      "412:\tlearn: 0.4015056\ttotal: 25.2s\tremaining: 35.9s\n",
      "413:\tlearn: 0.4014977\ttotal: 25.3s\tremaining: 35.8s\n",
      "414:\tlearn: 0.4014675\ttotal: 25.3s\tremaining: 35.7s\n",
      "415:\tlearn: 0.4014632\ttotal: 25.4s\tremaining: 35.6s\n",
      "416:\tlearn: 0.4014483\ttotal: 25.4s\tremaining: 35.5s\n",
      "417:\tlearn: 0.4014302\ttotal: 25.4s\tremaining: 35.4s\n",
      "418:\tlearn: 0.4014176\ttotal: 25.5s\tremaining: 35.4s\n",
      "419:\tlearn: 0.4014021\ttotal: 25.5s\tremaining: 35.3s\n",
      "420:\tlearn: 0.4013945\ttotal: 25.6s\tremaining: 35.2s\n",
      "421:\tlearn: 0.4013823\ttotal: 25.6s\tremaining: 35.1s\n",
      "422:\tlearn: 0.4013724\ttotal: 25.7s\tremaining: 35s\n",
      "423:\tlearn: 0.4013614\ttotal: 25.7s\tremaining: 34.9s\n",
      "424:\tlearn: 0.4013436\ttotal: 25.8s\tremaining: 34.9s\n",
      "425:\tlearn: 0.4013417\ttotal: 25.8s\tremaining: 34.8s\n",
      "426:\tlearn: 0.4013213\ttotal: 25.9s\tremaining: 34.7s\n",
      "427:\tlearn: 0.4013125\ttotal: 25.9s\tremaining: 34.6s\n",
      "428:\tlearn: 0.4013035\ttotal: 26s\tremaining: 34.5s\n",
      "429:\tlearn: 0.4012890\ttotal: 26s\tremaining: 34.5s\n",
      "430:\tlearn: 0.4012847\ttotal: 26s\tremaining: 34.4s\n",
      "431:\tlearn: 0.4012708\ttotal: 26.1s\tremaining: 34.3s\n",
      "432:\tlearn: 0.4012606\ttotal: 26.1s\tremaining: 34.2s\n",
      "433:\tlearn: 0.4012554\ttotal: 26.2s\tremaining: 34.1s\n",
      "434:\tlearn: 0.4012395\ttotal: 26.2s\tremaining: 34s\n",
      "435:\tlearn: 0.4012194\ttotal: 26.3s\tremaining: 34s\n",
      "436:\tlearn: 0.4012179\ttotal: 26.3s\tremaining: 33.9s\n",
      "437:\tlearn: 0.4012142\ttotal: 26.3s\tremaining: 33.8s\n",
      "438:\tlearn: 0.4011982\ttotal: 26.4s\tremaining: 33.7s\n",
      "439:\tlearn: 0.4011831\ttotal: 26.4s\tremaining: 33.6s\n",
      "440:\tlearn: 0.4011757\ttotal: 26.5s\tremaining: 33.6s\n",
      "441:\tlearn: 0.4011711\ttotal: 26.5s\tremaining: 33.5s\n",
      "442:\tlearn: 0.4011637\ttotal: 26.6s\tremaining: 33.4s\n",
      "443:\tlearn: 0.4011607\ttotal: 26.6s\tremaining: 33.3s\n",
      "444:\tlearn: 0.4011595\ttotal: 26.7s\tremaining: 33.2s\n",
      "445:\tlearn: 0.4011386\ttotal: 26.7s\tremaining: 33.2s\n",
      "446:\tlearn: 0.4011229\ttotal: 26.7s\tremaining: 33.1s\n",
      "447:\tlearn: 0.4011110\ttotal: 26.8s\tremaining: 33s\n",
      "448:\tlearn: 0.4010964\ttotal: 26.8s\tremaining: 32.9s\n",
      "449:\tlearn: 0.4010893\ttotal: 26.9s\tremaining: 32.9s\n",
      "450:\tlearn: 0.4010798\ttotal: 26.9s\tremaining: 32.8s\n",
      "451:\tlearn: 0.4010748\ttotal: 27s\tremaining: 32.7s\n",
      "452:\tlearn: 0.4010712\ttotal: 27s\tremaining: 32.6s\n",
      "453:\tlearn: 0.4010629\ttotal: 27s\tremaining: 32.5s\n",
      "454:\tlearn: 0.4010594\ttotal: 27.1s\tremaining: 32.4s\n",
      "455:\tlearn: 0.4010434\ttotal: 27.1s\tremaining: 32.4s\n",
      "456:\tlearn: 0.4010300\ttotal: 27.2s\tremaining: 32.3s\n",
      "457:\tlearn: 0.4010270\ttotal: 27.2s\tremaining: 32.2s\n",
      "458:\tlearn: 0.4010220\ttotal: 27.3s\tremaining: 32.1s\n",
      "459:\tlearn: 0.4010089\ttotal: 27.3s\tremaining: 32s\n",
      "460:\tlearn: 0.4010007\ttotal: 27.3s\tremaining: 32s\n",
      "461:\tlearn: 0.4009914\ttotal: 27.4s\tremaining: 31.9s\n",
      "462:\tlearn: 0.4009744\ttotal: 27.5s\tremaining: 31.8s\n",
      "463:\tlearn: 0.4009603\ttotal: 27.5s\tremaining: 31.8s\n",
      "464:\tlearn: 0.4009419\ttotal: 27.5s\tremaining: 31.7s\n",
      "465:\tlearn: 0.4009212\ttotal: 27.6s\tremaining: 31.6s\n",
      "466:\tlearn: 0.4008982\ttotal: 27.6s\tremaining: 31.5s\n",
      "467:\tlearn: 0.4008799\ttotal: 27.7s\tremaining: 31.5s\n",
      "468:\tlearn: 0.4008678\ttotal: 27.7s\tremaining: 31.4s\n",
      "469:\tlearn: 0.4008665\ttotal: 27.8s\tremaining: 31.3s\n",
      "470:\tlearn: 0.4008602\ttotal: 27.9s\tremaining: 31.3s\n",
      "471:\tlearn: 0.4008443\ttotal: 27.9s\tremaining: 31.2s\n",
      "472:\tlearn: 0.4008387\ttotal: 28s\tremaining: 31.1s\n",
      "473:\tlearn: 0.4008323\ttotal: 28s\tremaining: 31.1s\n",
      "474:\tlearn: 0.4008197\ttotal: 28.1s\tremaining: 31s\n",
      "475:\tlearn: 0.4008180\ttotal: 28.1s\tremaining: 31s\n",
      "476:\tlearn: 0.4008069\ttotal: 28.2s\tremaining: 30.9s\n",
      "477:\tlearn: 0.4008018\ttotal: 28.2s\tremaining: 30.8s\n",
      "478:\tlearn: 0.4007985\ttotal: 28.3s\tremaining: 30.8s\n",
      "479:\tlearn: 0.4007917\ttotal: 28.3s\tremaining: 30.7s\n",
      "480:\tlearn: 0.4007774\ttotal: 28.4s\tremaining: 30.6s\n",
      "481:\tlearn: 0.4007743\ttotal: 28.4s\tremaining: 30.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482:\tlearn: 0.4007723\ttotal: 28.5s\tremaining: 30.5s\n",
      "483:\tlearn: 0.4007539\ttotal: 28.5s\tremaining: 30.4s\n",
      "484:\tlearn: 0.4007484\ttotal: 28.5s\tremaining: 30.3s\n",
      "485:\tlearn: 0.4007447\ttotal: 28.6s\tremaining: 30.2s\n",
      "486:\tlearn: 0.4007260\ttotal: 28.6s\tremaining: 30.2s\n",
      "487:\tlearn: 0.4007208\ttotal: 28.7s\tremaining: 30.1s\n",
      "488:\tlearn: 0.4007131\ttotal: 28.7s\tremaining: 30s\n",
      "489:\tlearn: 0.4006925\ttotal: 28.8s\tremaining: 29.9s\n",
      "490:\tlearn: 0.4006740\ttotal: 28.8s\tremaining: 29.9s\n",
      "491:\tlearn: 0.4006670\ttotal: 28.8s\tremaining: 29.8s\n",
      "492:\tlearn: 0.4006595\ttotal: 28.9s\tremaining: 29.7s\n",
      "493:\tlearn: 0.4006490\ttotal: 28.9s\tremaining: 29.7s\n",
      "494:\tlearn: 0.4006344\ttotal: 29s\tremaining: 29.6s\n",
      "495:\tlearn: 0.4006270\ttotal: 29s\tremaining: 29.5s\n",
      "496:\tlearn: 0.4006267\ttotal: 29.1s\tremaining: 29.4s\n",
      "497:\tlearn: 0.4006129\ttotal: 29.1s\tremaining: 29.3s\n",
      "498:\tlearn: 0.4006085\ttotal: 29.1s\tremaining: 29.3s\n",
      "499:\tlearn: 0.4005925\ttotal: 29.2s\tremaining: 29.2s\n",
      "500:\tlearn: 0.4005841\ttotal: 29.2s\tremaining: 29.1s\n",
      "501:\tlearn: 0.4005724\ttotal: 29.3s\tremaining: 29.1s\n",
      "502:\tlearn: 0.4005492\ttotal: 29.3s\tremaining: 29s\n",
      "503:\tlearn: 0.4005386\ttotal: 29.4s\tremaining: 28.9s\n",
      "504:\tlearn: 0.4005335\ttotal: 29.4s\tremaining: 28.8s\n",
      "505:\tlearn: 0.4005219\ttotal: 29.5s\tremaining: 28.8s\n",
      "506:\tlearn: 0.4005129\ttotal: 29.5s\tremaining: 28.7s\n",
      "507:\tlearn: 0.4005023\ttotal: 29.6s\tremaining: 28.6s\n",
      "508:\tlearn: 0.4005014\ttotal: 29.6s\tremaining: 28.6s\n",
      "509:\tlearn: 0.4004909\ttotal: 29.7s\tremaining: 28.5s\n",
      "510:\tlearn: 0.4004712\ttotal: 29.7s\tremaining: 28.4s\n",
      "511:\tlearn: 0.4004624\ttotal: 29.8s\tremaining: 28.4s\n",
      "512:\tlearn: 0.4004404\ttotal: 29.8s\tremaining: 28.3s\n",
      "513:\tlearn: 0.4004344\ttotal: 29.9s\tremaining: 28.2s\n",
      "514:\tlearn: 0.4004273\ttotal: 29.9s\tremaining: 28.2s\n",
      "515:\tlearn: 0.4004217\ttotal: 30s\tremaining: 28.1s\n",
      "516:\tlearn: 0.4004095\ttotal: 30s\tremaining: 28s\n",
      "517:\tlearn: 0.4003973\ttotal: 30.1s\tremaining: 28s\n",
      "518:\tlearn: 0.4003883\ttotal: 30.1s\tremaining: 27.9s\n",
      "519:\tlearn: 0.4003685\ttotal: 30.1s\tremaining: 27.8s\n",
      "520:\tlearn: 0.4003633\ttotal: 30.2s\tremaining: 27.8s\n",
      "521:\tlearn: 0.4003606\ttotal: 30.2s\tremaining: 27.7s\n",
      "522:\tlearn: 0.4003564\ttotal: 30.3s\tremaining: 27.6s\n",
      "523:\tlearn: 0.4003445\ttotal: 30.3s\tremaining: 27.6s\n",
      "524:\tlearn: 0.4003326\ttotal: 30.4s\tremaining: 27.5s\n",
      "525:\tlearn: 0.4003301\ttotal: 30.4s\tremaining: 27.4s\n",
      "526:\tlearn: 0.4003234\ttotal: 30.5s\tremaining: 27.4s\n",
      "527:\tlearn: 0.4003067\ttotal: 30.5s\tremaining: 27.3s\n",
      "528:\tlearn: 0.4003029\ttotal: 30.6s\tremaining: 27.2s\n",
      "529:\tlearn: 0.4002396\ttotal: 30.6s\tremaining: 27.2s\n",
      "530:\tlearn: 0.4002187\ttotal: 30.7s\tremaining: 27.1s\n",
      "531:\tlearn: 0.4002146\ttotal: 30.7s\tremaining: 27s\n",
      "532:\tlearn: 0.4002099\ttotal: 30.7s\tremaining: 26.9s\n",
      "533:\tlearn: 0.4001884\ttotal: 30.8s\tremaining: 26.9s\n",
      "534:\tlearn: 0.4001805\ttotal: 30.8s\tremaining: 26.8s\n",
      "535:\tlearn: 0.4001698\ttotal: 30.9s\tremaining: 26.7s\n",
      "536:\tlearn: 0.4001636\ttotal: 30.9s\tremaining: 26.7s\n",
      "537:\tlearn: 0.4001464\ttotal: 31s\tremaining: 26.6s\n",
      "538:\tlearn: 0.4001409\ttotal: 31s\tremaining: 26.5s\n",
      "539:\tlearn: 0.4001290\ttotal: 31.1s\tremaining: 26.5s\n",
      "540:\tlearn: 0.4001244\ttotal: 31.1s\tremaining: 26.4s\n",
      "541:\tlearn: 0.4001145\ttotal: 31.2s\tremaining: 26.3s\n",
      "542:\tlearn: 0.4000921\ttotal: 31.2s\tremaining: 26.3s\n",
      "543:\tlearn: 0.4000839\ttotal: 31.3s\tremaining: 26.2s\n",
      "544:\tlearn: 0.4000698\ttotal: 31.3s\tremaining: 26.1s\n",
      "545:\tlearn: 0.4000665\ttotal: 31.3s\tremaining: 26.1s\n",
      "546:\tlearn: 0.4000627\ttotal: 31.4s\tremaining: 26s\n",
      "547:\tlearn: 0.4000353\ttotal: 31.4s\tremaining: 25.9s\n",
      "548:\tlearn: 0.4000277\ttotal: 31.5s\tremaining: 25.9s\n",
      "549:\tlearn: 0.4000048\ttotal: 31.5s\tremaining: 25.8s\n",
      "550:\tlearn: 0.3999939\ttotal: 31.6s\tremaining: 25.7s\n",
      "551:\tlearn: 0.3999743\ttotal: 31.6s\tremaining: 25.7s\n",
      "552:\tlearn: 0.3999579\ttotal: 31.7s\tremaining: 25.6s\n",
      "553:\tlearn: 0.3999493\ttotal: 31.7s\tremaining: 25.5s\n",
      "554:\tlearn: 0.3999369\ttotal: 31.8s\tremaining: 25.5s\n",
      "555:\tlearn: 0.3999230\ttotal: 31.8s\tremaining: 25.4s\n",
      "556:\tlearn: 0.3999071\ttotal: 31.9s\tremaining: 25.3s\n",
      "557:\tlearn: 0.3998887\ttotal: 31.9s\tremaining: 25.3s\n",
      "558:\tlearn: 0.3998827\ttotal: 31.9s\tremaining: 25.2s\n",
      "559:\tlearn: 0.3998724\ttotal: 32s\tremaining: 25.1s\n",
      "560:\tlearn: 0.3998518\ttotal: 32s\tremaining: 25.1s\n",
      "561:\tlearn: 0.3998395\ttotal: 32.1s\tremaining: 25s\n",
      "562:\tlearn: 0.3998333\ttotal: 32.1s\tremaining: 24.9s\n",
      "563:\tlearn: 0.3998312\ttotal: 32.2s\tremaining: 24.9s\n",
      "564:\tlearn: 0.3998178\ttotal: 32.2s\tremaining: 24.8s\n",
      "565:\tlearn: 0.3998043\ttotal: 32.3s\tremaining: 24.7s\n",
      "566:\tlearn: 0.3997834\ttotal: 32.3s\tremaining: 24.7s\n",
      "567:\tlearn: 0.3997685\ttotal: 32.4s\tremaining: 24.6s\n",
      "568:\tlearn: 0.3997479\ttotal: 32.4s\tremaining: 24.6s\n",
      "569:\tlearn: 0.3997352\ttotal: 32.5s\tremaining: 24.5s\n",
      "570:\tlearn: 0.3997210\ttotal: 32.5s\tremaining: 24.4s\n",
      "571:\tlearn: 0.3997127\ttotal: 32.6s\tremaining: 24.4s\n",
      "572:\tlearn: 0.3997073\ttotal: 32.6s\tremaining: 24.3s\n",
      "573:\tlearn: 0.3997012\ttotal: 32.7s\tremaining: 24.2s\n",
      "574:\tlearn: 0.3996948\ttotal: 32.7s\tremaining: 24.2s\n",
      "575:\tlearn: 0.3996832\ttotal: 32.8s\tremaining: 24.1s\n",
      "576:\tlearn: 0.3996794\ttotal: 32.8s\tremaining: 24.1s\n",
      "577:\tlearn: 0.3996700\ttotal: 32.9s\tremaining: 24s\n",
      "578:\tlearn: 0.3996658\ttotal: 32.9s\tremaining: 23.9s\n",
      "579:\tlearn: 0.3996609\ttotal: 33s\tremaining: 23.9s\n",
      "580:\tlearn: 0.3996522\ttotal: 33s\tremaining: 23.8s\n",
      "581:\tlearn: 0.3996433\ttotal: 33.1s\tremaining: 23.8s\n",
      "582:\tlearn: 0.3996294\ttotal: 33.1s\tremaining: 23.7s\n",
      "583:\tlearn: 0.3996204\ttotal: 33.2s\tremaining: 23.6s\n",
      "584:\tlearn: 0.3996134\ttotal: 33.2s\tremaining: 23.6s\n",
      "585:\tlearn: 0.3995997\ttotal: 33.3s\tremaining: 23.5s\n",
      "586:\tlearn: 0.3995923\ttotal: 33.3s\tremaining: 23.4s\n",
      "587:\tlearn: 0.3995836\ttotal: 33.4s\tremaining: 23.4s\n",
      "588:\tlearn: 0.3995786\ttotal: 33.4s\tremaining: 23.3s\n",
      "589:\tlearn: 0.3995716\ttotal: 33.5s\tremaining: 23.3s\n",
      "590:\tlearn: 0.3995706\ttotal: 33.5s\tremaining: 23.2s\n",
      "591:\tlearn: 0.3995689\ttotal: 33.5s\tremaining: 23.1s\n",
      "592:\tlearn: 0.3995514\ttotal: 33.6s\tremaining: 23s\n",
      "593:\tlearn: 0.3995430\ttotal: 33.6s\tremaining: 23s\n",
      "594:\tlearn: 0.3995343\ttotal: 33.7s\tremaining: 22.9s\n",
      "595:\tlearn: 0.3995278\ttotal: 33.7s\tremaining: 22.9s\n",
      "596:\tlearn: 0.3995177\ttotal: 33.8s\tremaining: 22.8s\n",
      "597:\tlearn: 0.3995054\ttotal: 33.8s\tremaining: 22.7s\n",
      "598:\tlearn: 0.3994943\ttotal: 33.9s\tremaining: 22.7s\n",
      "599:\tlearn: 0.3994831\ttotal: 33.9s\tremaining: 22.6s\n",
      "600:\tlearn: 0.3994688\ttotal: 34s\tremaining: 22.6s\n",
      "601:\tlearn: 0.3994519\ttotal: 34s\tremaining: 22.5s\n",
      "602:\tlearn: 0.3994459\ttotal: 34.1s\tremaining: 22.4s\n",
      "603:\tlearn: 0.3994323\ttotal: 34.1s\tremaining: 22.4s\n",
      "604:\tlearn: 0.3994200\ttotal: 34.2s\tremaining: 22.3s\n",
      "605:\tlearn: 0.3994075\ttotal: 34.2s\tremaining: 22.2s\n",
      "606:\tlearn: 0.3993947\ttotal: 34.2s\tremaining: 22.2s\n",
      "607:\tlearn: 0.3993822\ttotal: 34.3s\tremaining: 22.1s\n",
      "608:\tlearn: 0.3993694\ttotal: 34.3s\tremaining: 22s\n",
      "609:\tlearn: 0.3993593\ttotal: 34.4s\tremaining: 22s\n",
      "610:\tlearn: 0.3993507\ttotal: 34.4s\tremaining: 21.9s\n",
      "611:\tlearn: 0.3993492\ttotal: 34.5s\tremaining: 21.9s\n",
      "612:\tlearn: 0.3993413\ttotal: 34.5s\tremaining: 21.8s\n",
      "613:\tlearn: 0.3993231\ttotal: 34.6s\tremaining: 21.7s\n",
      "614:\tlearn: 0.3993184\ttotal: 34.6s\tremaining: 21.7s\n",
      "615:\tlearn: 0.3993012\ttotal: 34.7s\tremaining: 21.6s\n",
      "616:\tlearn: 0.3992884\ttotal: 34.7s\tremaining: 21.6s\n",
      "617:\tlearn: 0.3992838\ttotal: 34.8s\tremaining: 21.5s\n",
      "618:\tlearn: 0.3992791\ttotal: 34.8s\tremaining: 21.4s\n",
      "619:\tlearn: 0.3992754\ttotal: 34.9s\tremaining: 21.4s\n",
      "620:\tlearn: 0.3992605\ttotal: 34.9s\tremaining: 21.3s\n",
      "621:\tlearn: 0.3992460\ttotal: 35s\tremaining: 21.2s\n",
      "622:\tlearn: 0.3992349\ttotal: 35s\tremaining: 21.2s\n",
      "623:\tlearn: 0.3992148\ttotal: 35s\tremaining: 21.1s\n",
      "624:\tlearn: 0.3992104\ttotal: 35.1s\tremaining: 21.1s\n",
      "625:\tlearn: 0.3992042\ttotal: 35.1s\tremaining: 21s\n",
      "626:\tlearn: 0.3991998\ttotal: 35.2s\tremaining: 20.9s\n",
      "627:\tlearn: 0.3991815\ttotal: 35.2s\tremaining: 20.9s\n",
      "628:\tlearn: 0.3991717\ttotal: 35.3s\tremaining: 20.8s\n",
      "629:\tlearn: 0.3991638\ttotal: 35.3s\tremaining: 20.7s\n",
      "630:\tlearn: 0.3991627\ttotal: 35.4s\tremaining: 20.7s\n",
      "631:\tlearn: 0.3991551\ttotal: 35.4s\tremaining: 20.6s\n",
      "632:\tlearn: 0.3991440\ttotal: 35.5s\tremaining: 20.6s\n",
      "633:\tlearn: 0.3991401\ttotal: 35.5s\tremaining: 20.5s\n",
      "634:\tlearn: 0.3991346\ttotal: 35.6s\tremaining: 20.4s\n",
      "635:\tlearn: 0.3991195\ttotal: 35.6s\tremaining: 20.4s\n",
      "636:\tlearn: 0.3991045\ttotal: 35.7s\tremaining: 20.3s\n",
      "637:\tlearn: 0.3991012\ttotal: 35.7s\tremaining: 20.3s\n",
      "638:\tlearn: 0.3990892\ttotal: 35.8s\tremaining: 20.2s\n",
      "639:\tlearn: 0.3990832\ttotal: 35.8s\tremaining: 20.2s\n",
      "640:\tlearn: 0.3990751\ttotal: 35.9s\tremaining: 20.1s\n",
      "641:\tlearn: 0.3990729\ttotal: 35.9s\tremaining: 20s\n",
      "642:\tlearn: 0.3990609\ttotal: 36s\tremaining: 20s\n",
      "643:\tlearn: 0.3990429\ttotal: 36s\tremaining: 19.9s\n",
      "644:\tlearn: 0.3990336\ttotal: 36s\tremaining: 19.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645:\tlearn: 0.3990254\ttotal: 36.1s\tremaining: 19.8s\n",
      "646:\tlearn: 0.3990098\ttotal: 36.1s\tremaining: 19.7s\n",
      "647:\tlearn: 0.3989956\ttotal: 36.2s\tremaining: 19.7s\n",
      "648:\tlearn: 0.3989901\ttotal: 36.2s\tremaining: 19.6s\n",
      "649:\tlearn: 0.3989808\ttotal: 36.3s\tremaining: 19.5s\n",
      "650:\tlearn: 0.3989791\ttotal: 36.3s\tremaining: 19.5s\n",
      "651:\tlearn: 0.3989583\ttotal: 36.4s\tremaining: 19.4s\n",
      "652:\tlearn: 0.3989508\ttotal: 36.4s\tremaining: 19.4s\n",
      "653:\tlearn: 0.3989452\ttotal: 36.5s\tremaining: 19.3s\n",
      "654:\tlearn: 0.3989279\ttotal: 36.5s\tremaining: 19.2s\n",
      "655:\tlearn: 0.3989267\ttotal: 36.6s\tremaining: 19.2s\n",
      "656:\tlearn: 0.3989161\ttotal: 36.6s\tremaining: 19.1s\n",
      "657:\tlearn: 0.3989006\ttotal: 36.6s\tremaining: 19s\n",
      "658:\tlearn: 0.3988966\ttotal: 36.7s\tremaining: 19s\n",
      "659:\tlearn: 0.3988828\ttotal: 36.7s\tremaining: 18.9s\n",
      "660:\tlearn: 0.3988733\ttotal: 36.8s\tremaining: 18.9s\n",
      "661:\tlearn: 0.3988628\ttotal: 36.8s\tremaining: 18.8s\n",
      "662:\tlearn: 0.3988451\ttotal: 36.9s\tremaining: 18.7s\n",
      "663:\tlearn: 0.3988297\ttotal: 36.9s\tremaining: 18.7s\n",
      "664:\tlearn: 0.3988190\ttotal: 36.9s\tremaining: 18.6s\n",
      "665:\tlearn: 0.3988046\ttotal: 37s\tremaining: 18.5s\n",
      "666:\tlearn: 0.3987970\ttotal: 37s\tremaining: 18.5s\n",
      "667:\tlearn: 0.3987926\ttotal: 37.1s\tremaining: 18.4s\n",
      "668:\tlearn: 0.3987873\ttotal: 37.1s\tremaining: 18.4s\n",
      "669:\tlearn: 0.3987816\ttotal: 37.2s\tremaining: 18.3s\n",
      "670:\tlearn: 0.3987669\ttotal: 37.2s\tremaining: 18.3s\n",
      "671:\tlearn: 0.3987531\ttotal: 37.3s\tremaining: 18.2s\n",
      "672:\tlearn: 0.3987492\ttotal: 37.3s\tremaining: 18.1s\n",
      "673:\tlearn: 0.3987377\ttotal: 37.4s\tremaining: 18.1s\n",
      "674:\tlearn: 0.3987307\ttotal: 37.4s\tremaining: 18s\n",
      "675:\tlearn: 0.3987134\ttotal: 37.5s\tremaining: 18s\n",
      "676:\tlearn: 0.3987035\ttotal: 37.5s\tremaining: 17.9s\n",
      "677:\tlearn: 0.3986986\ttotal: 37.5s\tremaining: 17.8s\n",
      "678:\tlearn: 0.3986964\ttotal: 37.6s\tremaining: 17.8s\n",
      "679:\tlearn: 0.3986844\ttotal: 37.6s\tremaining: 17.7s\n",
      "680:\tlearn: 0.3986695\ttotal: 37.7s\tremaining: 17.6s\n",
      "681:\tlearn: 0.3986621\ttotal: 37.7s\tremaining: 17.6s\n",
      "682:\tlearn: 0.3986515\ttotal: 37.8s\tremaining: 17.5s\n",
      "683:\tlearn: 0.3986474\ttotal: 37.8s\tremaining: 17.5s\n",
      "684:\tlearn: 0.3986450\ttotal: 37.9s\tremaining: 17.4s\n",
      "685:\tlearn: 0.3986423\ttotal: 37.9s\tremaining: 17.4s\n",
      "686:\tlearn: 0.3986385\ttotal: 37.9s\tremaining: 17.3s\n",
      "687:\tlearn: 0.3986321\ttotal: 38s\tremaining: 17.2s\n",
      "688:\tlearn: 0.3986242\ttotal: 38s\tremaining: 17.2s\n",
      "689:\tlearn: 0.3986085\ttotal: 38.1s\tremaining: 17.1s\n",
      "690:\tlearn: 0.3985978\ttotal: 38.1s\tremaining: 17.1s\n",
      "691:\tlearn: 0.3985828\ttotal: 38.2s\tremaining: 17s\n",
      "692:\tlearn: 0.3985680\ttotal: 38.2s\tremaining: 16.9s\n",
      "693:\tlearn: 0.3985613\ttotal: 38.3s\tremaining: 16.9s\n",
      "694:\tlearn: 0.3985458\ttotal: 38.3s\tremaining: 16.8s\n",
      "695:\tlearn: 0.3985403\ttotal: 38.4s\tremaining: 16.8s\n",
      "696:\tlearn: 0.3985314\ttotal: 38.4s\tremaining: 16.7s\n",
      "697:\tlearn: 0.3985270\ttotal: 38.5s\tremaining: 16.7s\n",
      "698:\tlearn: 0.3985224\ttotal: 38.5s\tremaining: 16.6s\n",
      "699:\tlearn: 0.3985059\ttotal: 38.6s\tremaining: 16.5s\n",
      "700:\tlearn: 0.3985053\ttotal: 38.6s\tremaining: 16.5s\n",
      "701:\tlearn: 0.3984998\ttotal: 38.7s\tremaining: 16.4s\n",
      "702:\tlearn: 0.3984849\ttotal: 38.7s\tremaining: 16.4s\n",
      "703:\tlearn: 0.3984702\ttotal: 38.7s\tremaining: 16.3s\n",
      "704:\tlearn: 0.3984670\ttotal: 38.8s\tremaining: 16.2s\n",
      "705:\tlearn: 0.3984654\ttotal: 38.8s\tremaining: 16.2s\n",
      "706:\tlearn: 0.3984538\ttotal: 38.9s\tremaining: 16.1s\n",
      "707:\tlearn: 0.3984398\ttotal: 38.9s\tremaining: 16s\n",
      "708:\tlearn: 0.3984336\ttotal: 39s\tremaining: 16s\n",
      "709:\tlearn: 0.3984287\ttotal: 39s\tremaining: 15.9s\n",
      "710:\tlearn: 0.3984210\ttotal: 39s\tremaining: 15.9s\n",
      "711:\tlearn: 0.3984071\ttotal: 39.1s\tremaining: 15.8s\n",
      "712:\tlearn: 0.3983952\ttotal: 39.1s\tremaining: 15.8s\n",
      "713:\tlearn: 0.3983944\ttotal: 39.2s\tremaining: 15.7s\n",
      "714:\tlearn: 0.3983881\ttotal: 39.2s\tremaining: 15.6s\n",
      "715:\tlearn: 0.3983749\ttotal: 39.3s\tremaining: 15.6s\n",
      "716:\tlearn: 0.3983720\ttotal: 39.3s\tremaining: 15.5s\n",
      "717:\tlearn: 0.3983657\ttotal: 39.3s\tremaining: 15.5s\n",
      "718:\tlearn: 0.3983635\ttotal: 39.4s\tremaining: 15.4s\n",
      "719:\tlearn: 0.3983592\ttotal: 39.4s\tremaining: 15.3s\n",
      "720:\tlearn: 0.3983418\ttotal: 39.5s\tremaining: 15.3s\n",
      "721:\tlearn: 0.3983252\ttotal: 39.5s\tremaining: 15.2s\n",
      "722:\tlearn: 0.3983178\ttotal: 39.6s\tremaining: 15.2s\n",
      "723:\tlearn: 0.3983024\ttotal: 39.6s\tremaining: 15.1s\n",
      "724:\tlearn: 0.3982933\ttotal: 39.7s\tremaining: 15s\n",
      "725:\tlearn: 0.3982897\ttotal: 39.7s\tremaining: 15s\n",
      "726:\tlearn: 0.3982743\ttotal: 39.8s\tremaining: 14.9s\n",
      "727:\tlearn: 0.3982631\ttotal: 39.8s\tremaining: 14.9s\n",
      "728:\tlearn: 0.3982610\ttotal: 39.9s\tremaining: 14.8s\n",
      "729:\tlearn: 0.3982566\ttotal: 39.9s\tremaining: 14.8s\n",
      "730:\tlearn: 0.3982473\ttotal: 39.9s\tremaining: 14.7s\n",
      "731:\tlearn: 0.3982395\ttotal: 40s\tremaining: 14.6s\n",
      "732:\tlearn: 0.3982307\ttotal: 40s\tremaining: 14.6s\n",
      "733:\tlearn: 0.3982222\ttotal: 40.1s\tremaining: 14.5s\n",
      "734:\tlearn: 0.3982148\ttotal: 40.1s\tremaining: 14.5s\n",
      "735:\tlearn: 0.3982017\ttotal: 40.2s\tremaining: 14.4s\n",
      "736:\tlearn: 0.3981985\ttotal: 40.2s\tremaining: 14.4s\n",
      "737:\tlearn: 0.3981831\ttotal: 40.3s\tremaining: 14.3s\n",
      "738:\tlearn: 0.3981788\ttotal: 40.3s\tremaining: 14.2s\n",
      "739:\tlearn: 0.3981731\ttotal: 40.4s\tremaining: 14.2s\n",
      "740:\tlearn: 0.3981613\ttotal: 40.4s\tremaining: 14.1s\n",
      "741:\tlearn: 0.3981567\ttotal: 40.5s\tremaining: 14.1s\n",
      "742:\tlearn: 0.3981411\ttotal: 40.5s\tremaining: 14s\n",
      "743:\tlearn: 0.3981384\ttotal: 40.5s\tremaining: 13.9s\n",
      "744:\tlearn: 0.3981356\ttotal: 40.6s\tremaining: 13.9s\n",
      "745:\tlearn: 0.3981273\ttotal: 40.6s\tremaining: 13.8s\n",
      "746:\tlearn: 0.3981147\ttotal: 40.7s\tremaining: 13.8s\n",
      "747:\tlearn: 0.3981102\ttotal: 40.7s\tremaining: 13.7s\n",
      "748:\tlearn: 0.3980997\ttotal: 40.8s\tremaining: 13.7s\n",
      "749:\tlearn: 0.3980941\ttotal: 40.8s\tremaining: 13.6s\n",
      "750:\tlearn: 0.3980902\ttotal: 40.8s\tremaining: 13.5s\n",
      "751:\tlearn: 0.3980722\ttotal: 40.9s\tremaining: 13.5s\n",
      "752:\tlearn: 0.3980585\ttotal: 40.9s\tremaining: 13.4s\n",
      "753:\tlearn: 0.3980568\ttotal: 41s\tremaining: 13.4s\n",
      "754:\tlearn: 0.3980418\ttotal: 41s\tremaining: 13.3s\n",
      "755:\tlearn: 0.3980381\ttotal: 41.1s\tremaining: 13.3s\n",
      "756:\tlearn: 0.3980326\ttotal: 41.1s\tremaining: 13.2s\n",
      "757:\tlearn: 0.3980304\ttotal: 41.2s\tremaining: 13.1s\n",
      "758:\tlearn: 0.3980241\ttotal: 41.2s\tremaining: 13.1s\n",
      "759:\tlearn: 0.3980174\ttotal: 41.2s\tremaining: 13s\n",
      "760:\tlearn: 0.3980086\ttotal: 41.3s\tremaining: 13s\n",
      "761:\tlearn: 0.3980021\ttotal: 41.3s\tremaining: 12.9s\n",
      "762:\tlearn: 0.3979932\ttotal: 41.4s\tremaining: 12.8s\n",
      "763:\tlearn: 0.3979848\ttotal: 41.4s\tremaining: 12.8s\n",
      "764:\tlearn: 0.3979723\ttotal: 41.5s\tremaining: 12.7s\n",
      "765:\tlearn: 0.3979569\ttotal: 41.5s\tremaining: 12.7s\n",
      "766:\tlearn: 0.3979561\ttotal: 41.5s\tremaining: 12.6s\n",
      "767:\tlearn: 0.3979468\ttotal: 41.6s\tremaining: 12.6s\n",
      "768:\tlearn: 0.3979382\ttotal: 41.6s\tremaining: 12.5s\n",
      "769:\tlearn: 0.3979290\ttotal: 41.7s\tremaining: 12.4s\n",
      "770:\tlearn: 0.3979231\ttotal: 41.7s\tremaining: 12.4s\n",
      "771:\tlearn: 0.3979154\ttotal: 41.8s\tremaining: 12.3s\n",
      "772:\tlearn: 0.3979128\ttotal: 41.8s\tremaining: 12.3s\n",
      "773:\tlearn: 0.3979110\ttotal: 41.8s\tremaining: 12.2s\n",
      "774:\tlearn: 0.3979027\ttotal: 41.9s\tremaining: 12.2s\n",
      "775:\tlearn: 0.3978999\ttotal: 41.9s\tremaining: 12.1s\n",
      "776:\tlearn: 0.3978876\ttotal: 42s\tremaining: 12.1s\n",
      "777:\tlearn: 0.3978809\ttotal: 42s\tremaining: 12s\n",
      "778:\tlearn: 0.3978732\ttotal: 42.1s\tremaining: 11.9s\n",
      "779:\tlearn: 0.3978665\ttotal: 42.1s\tremaining: 11.9s\n",
      "780:\tlearn: 0.3978594\ttotal: 42.2s\tremaining: 11.8s\n",
      "781:\tlearn: 0.3978450\ttotal: 42.2s\tremaining: 11.8s\n",
      "782:\tlearn: 0.3978397\ttotal: 42.3s\tremaining: 11.7s\n",
      "783:\tlearn: 0.3978314\ttotal: 42.3s\tremaining: 11.7s\n",
      "784:\tlearn: 0.3978190\ttotal: 42.4s\tremaining: 11.6s\n",
      "785:\tlearn: 0.3978111\ttotal: 42.4s\tremaining: 11.5s\n",
      "786:\tlearn: 0.3978021\ttotal: 42.5s\tremaining: 11.5s\n",
      "787:\tlearn: 0.3977933\ttotal: 42.5s\tremaining: 11.4s\n",
      "788:\tlearn: 0.3977876\ttotal: 42.6s\tremaining: 11.4s\n",
      "789:\tlearn: 0.3977818\ttotal: 42.6s\tremaining: 11.3s\n",
      "790:\tlearn: 0.3977742\ttotal: 42.7s\tremaining: 11.3s\n",
      "791:\tlearn: 0.3977573\ttotal: 42.7s\tremaining: 11.2s\n",
      "792:\tlearn: 0.3977539\ttotal: 42.8s\tremaining: 11.2s\n",
      "793:\tlearn: 0.3977475\ttotal: 42.8s\tremaining: 11.1s\n",
      "794:\tlearn: 0.3977445\ttotal: 42.9s\tremaining: 11.1s\n",
      "795:\tlearn: 0.3977381\ttotal: 42.9s\tremaining: 11s\n",
      "796:\tlearn: 0.3977358\ttotal: 43s\tremaining: 10.9s\n",
      "797:\tlearn: 0.3977337\ttotal: 43s\tremaining: 10.9s\n",
      "798:\tlearn: 0.3977287\ttotal: 43.1s\tremaining: 10.8s\n",
      "799:\tlearn: 0.3977256\ttotal: 43.1s\tremaining: 10.8s\n",
      "800:\tlearn: 0.3977179\ttotal: 43.2s\tremaining: 10.7s\n",
      "801:\tlearn: 0.3977140\ttotal: 43.2s\tremaining: 10.7s\n",
      "802:\tlearn: 0.3977108\ttotal: 43.2s\tremaining: 10.6s\n",
      "803:\tlearn: 0.3977058\ttotal: 43.3s\tremaining: 10.6s\n",
      "804:\tlearn: 0.3977029\ttotal: 43.3s\tremaining: 10.5s\n",
      "805:\tlearn: 0.3976931\ttotal: 43.4s\tremaining: 10.4s\n",
      "806:\tlearn: 0.3976879\ttotal: 43.4s\tremaining: 10.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807:\tlearn: 0.3976862\ttotal: 43.5s\tremaining: 10.3s\n",
      "808:\tlearn: 0.3976827\ttotal: 43.5s\tremaining: 10.3s\n",
      "809:\tlearn: 0.3976679\ttotal: 43.6s\tremaining: 10.2s\n",
      "810:\tlearn: 0.3976612\ttotal: 43.6s\tremaining: 10.2s\n",
      "811:\tlearn: 0.3976569\ttotal: 43.7s\tremaining: 10.1s\n",
      "812:\tlearn: 0.3976481\ttotal: 43.7s\tremaining: 10.1s\n",
      "813:\tlearn: 0.3976463\ttotal: 43.8s\tremaining: 10s\n",
      "814:\tlearn: 0.3976409\ttotal: 43.8s\tremaining: 9.94s\n",
      "815:\tlearn: 0.3976375\ttotal: 43.9s\tremaining: 9.89s\n",
      "816:\tlearn: 0.3976330\ttotal: 43.9s\tremaining: 9.83s\n",
      "817:\tlearn: 0.3976227\ttotal: 43.9s\tremaining: 9.78s\n",
      "818:\tlearn: 0.3976155\ttotal: 44s\tremaining: 9.72s\n",
      "819:\tlearn: 0.3976090\ttotal: 44s\tremaining: 9.67s\n",
      "820:\tlearn: 0.3975984\ttotal: 44.1s\tremaining: 9.61s\n",
      "821:\tlearn: 0.3975922\ttotal: 44.1s\tremaining: 9.55s\n",
      "822:\tlearn: 0.3975868\ttotal: 44.2s\tremaining: 9.5s\n",
      "823:\tlearn: 0.3975786\ttotal: 44.2s\tremaining: 9.45s\n",
      "824:\tlearn: 0.3975701\ttotal: 44.3s\tremaining: 9.39s\n",
      "825:\tlearn: 0.3975543\ttotal: 44.3s\tremaining: 9.33s\n",
      "826:\tlearn: 0.3975502\ttotal: 44.4s\tremaining: 9.28s\n",
      "827:\tlearn: 0.3975485\ttotal: 44.4s\tremaining: 9.22s\n",
      "828:\tlearn: 0.3975411\ttotal: 44.4s\tremaining: 9.17s\n",
      "829:\tlearn: 0.3975330\ttotal: 44.5s\tremaining: 9.11s\n",
      "830:\tlearn: 0.3975204\ttotal: 44.5s\tremaining: 9.05s\n",
      "831:\tlearn: 0.3975180\ttotal: 44.6s\tremaining: 8.99s\n",
      "832:\tlearn: 0.3975093\ttotal: 44.6s\tremaining: 8.94s\n",
      "833:\tlearn: 0.3975000\ttotal: 44.7s\tremaining: 8.89s\n",
      "834:\tlearn: 0.3974970\ttotal: 44.7s\tremaining: 8.83s\n",
      "835:\tlearn: 0.3974945\ttotal: 44.7s\tremaining: 8.78s\n",
      "836:\tlearn: 0.3974873\ttotal: 44.8s\tremaining: 8.72s\n",
      "837:\tlearn: 0.3974845\ttotal: 44.8s\tremaining: 8.67s\n",
      "838:\tlearn: 0.3974719\ttotal: 44.9s\tremaining: 8.61s\n",
      "839:\tlearn: 0.3974605\ttotal: 44.9s\tremaining: 8.56s\n",
      "840:\tlearn: 0.3974561\ttotal: 45s\tremaining: 8.5s\n",
      "841:\tlearn: 0.3974554\ttotal: 45s\tremaining: 8.45s\n",
      "842:\tlearn: 0.3974521\ttotal: 45.1s\tremaining: 8.39s\n",
      "843:\tlearn: 0.3974484\ttotal: 45.1s\tremaining: 8.34s\n",
      "844:\tlearn: 0.3974369\ttotal: 45.2s\tremaining: 8.28s\n",
      "845:\tlearn: 0.3974214\ttotal: 45.2s\tremaining: 8.23s\n",
      "846:\tlearn: 0.3974159\ttotal: 45.3s\tremaining: 8.17s\n",
      "847:\tlearn: 0.3974152\ttotal: 45.3s\tremaining: 8.12s\n",
      "848:\tlearn: 0.3974010\ttotal: 45.3s\tremaining: 8.06s\n",
      "849:\tlearn: 0.3973849\ttotal: 45.4s\tremaining: 8.01s\n",
      "850:\tlearn: 0.3973794\ttotal: 45.4s\tremaining: 7.95s\n",
      "851:\tlearn: 0.3973757\ttotal: 45.5s\tremaining: 7.89s\n",
      "852:\tlearn: 0.3973665\ttotal: 45.5s\tremaining: 7.84s\n",
      "853:\tlearn: 0.3973601\ttotal: 45.5s\tremaining: 7.79s\n",
      "854:\tlearn: 0.3973516\ttotal: 45.6s\tremaining: 7.73s\n",
      "855:\tlearn: 0.3973388\ttotal: 45.6s\tremaining: 7.68s\n",
      "856:\tlearn: 0.3973342\ttotal: 45.7s\tremaining: 7.62s\n",
      "857:\tlearn: 0.3973231\ttotal: 45.7s\tremaining: 7.56s\n",
      "858:\tlearn: 0.3973172\ttotal: 45.7s\tremaining: 7.51s\n",
      "859:\tlearn: 0.3973083\ttotal: 45.8s\tremaining: 7.45s\n",
      "860:\tlearn: 0.3973032\ttotal: 45.8s\tremaining: 7.4s\n",
      "861:\tlearn: 0.3972923\ttotal: 45.9s\tremaining: 7.35s\n",
      "862:\tlearn: 0.3972857\ttotal: 45.9s\tremaining: 7.29s\n",
      "863:\tlearn: 0.3972760\ttotal: 46s\tremaining: 7.24s\n",
      "864:\tlearn: 0.3972683\ttotal: 46s\tremaining: 7.18s\n",
      "865:\tlearn: 0.3972536\ttotal: 46.1s\tremaining: 7.13s\n",
      "866:\tlearn: 0.3972479\ttotal: 46.1s\tremaining: 7.08s\n",
      "867:\tlearn: 0.3972343\ttotal: 46.2s\tremaining: 7.02s\n",
      "868:\tlearn: 0.3972281\ttotal: 46.2s\tremaining: 6.97s\n",
      "869:\tlearn: 0.3972178\ttotal: 46.3s\tremaining: 6.91s\n",
      "870:\tlearn: 0.3972098\ttotal: 46.3s\tremaining: 6.86s\n",
      "871:\tlearn: 0.3972005\ttotal: 46.4s\tremaining: 6.81s\n",
      "872:\tlearn: 0.3971870\ttotal: 46.4s\tremaining: 6.75s\n",
      "873:\tlearn: 0.3971779\ttotal: 46.5s\tremaining: 6.7s\n",
      "874:\tlearn: 0.3971730\ttotal: 46.5s\tremaining: 6.65s\n",
      "875:\tlearn: 0.3971693\ttotal: 46.6s\tremaining: 6.59s\n",
      "876:\tlearn: 0.3971649\ttotal: 46.6s\tremaining: 6.53s\n",
      "877:\tlearn: 0.3971550\ttotal: 46.6s\tremaining: 6.48s\n",
      "878:\tlearn: 0.3971421\ttotal: 46.7s\tremaining: 6.42s\n",
      "879:\tlearn: 0.3971393\ttotal: 46.7s\tremaining: 6.37s\n",
      "880:\tlearn: 0.3971304\ttotal: 46.8s\tremaining: 6.32s\n",
      "881:\tlearn: 0.3971271\ttotal: 46.8s\tremaining: 6.26s\n",
      "882:\tlearn: 0.3971256\ttotal: 46.9s\tremaining: 6.21s\n",
      "883:\tlearn: 0.3971195\ttotal: 46.9s\tremaining: 6.15s\n",
      "884:\tlearn: 0.3971101\ttotal: 46.9s\tremaining: 6.1s\n",
      "885:\tlearn: 0.3971026\ttotal: 47s\tremaining: 6.04s\n",
      "886:\tlearn: 0.3970961\ttotal: 47s\tremaining: 5.99s\n",
      "887:\tlearn: 0.3970915\ttotal: 47.1s\tremaining: 5.94s\n",
      "888:\tlearn: 0.3970808\ttotal: 47.1s\tremaining: 5.88s\n",
      "889:\tlearn: 0.3970792\ttotal: 47.1s\tremaining: 5.83s\n",
      "890:\tlearn: 0.3970741\ttotal: 47.2s\tremaining: 5.77s\n",
      "891:\tlearn: 0.3970693\ttotal: 47.2s\tremaining: 5.72s\n",
      "892:\tlearn: 0.3970648\ttotal: 47.3s\tremaining: 5.66s\n",
      "893:\tlearn: 0.3970524\ttotal: 47.3s\tremaining: 5.61s\n",
      "894:\tlearn: 0.3970451\ttotal: 47.4s\tremaining: 5.56s\n",
      "895:\tlearn: 0.3970439\ttotal: 47.4s\tremaining: 5.5s\n",
      "896:\tlearn: 0.3970261\ttotal: 47.5s\tremaining: 5.45s\n",
      "897:\tlearn: 0.3970181\ttotal: 47.5s\tremaining: 5.4s\n",
      "898:\tlearn: 0.3970055\ttotal: 47.6s\tremaining: 5.34s\n",
      "899:\tlearn: 0.3969857\ttotal: 47.6s\tremaining: 5.29s\n",
      "900:\tlearn: 0.3969720\ttotal: 47.7s\tremaining: 5.24s\n",
      "901:\tlearn: 0.3969578\ttotal: 47.7s\tremaining: 5.18s\n",
      "902:\tlearn: 0.3969532\ttotal: 47.8s\tremaining: 5.13s\n",
      "903:\tlearn: 0.3969500\ttotal: 47.8s\tremaining: 5.08s\n",
      "904:\tlearn: 0.3969419\ttotal: 47.9s\tremaining: 5.02s\n",
      "905:\tlearn: 0.3969377\ttotal: 47.9s\tremaining: 4.97s\n",
      "906:\tlearn: 0.3969291\ttotal: 48s\tremaining: 4.92s\n",
      "907:\tlearn: 0.3969288\ttotal: 48s\tremaining: 4.86s\n",
      "908:\tlearn: 0.3969180\ttotal: 48s\tremaining: 4.81s\n",
      "909:\tlearn: 0.3969139\ttotal: 48.1s\tremaining: 4.75s\n",
      "910:\tlearn: 0.3969113\ttotal: 48.1s\tremaining: 4.7s\n",
      "911:\tlearn: 0.3969030\ttotal: 48.2s\tremaining: 4.65s\n",
      "912:\tlearn: 0.3969021\ttotal: 48.2s\tremaining: 4.59s\n",
      "913:\tlearn: 0.3968954\ttotal: 48.3s\tremaining: 4.54s\n",
      "914:\tlearn: 0.3968929\ttotal: 48.3s\tremaining: 4.49s\n",
      "915:\tlearn: 0.3968826\ttotal: 48.4s\tremaining: 4.43s\n",
      "916:\tlearn: 0.3968738\ttotal: 48.4s\tremaining: 4.38s\n",
      "917:\tlearn: 0.3968696\ttotal: 48.5s\tremaining: 4.33s\n",
      "918:\tlearn: 0.3968662\ttotal: 48.5s\tremaining: 4.27s\n",
      "919:\tlearn: 0.3968639\ttotal: 48.5s\tremaining: 4.22s\n",
      "920:\tlearn: 0.3968455\ttotal: 48.6s\tremaining: 4.17s\n",
      "921:\tlearn: 0.3968390\ttotal: 48.6s\tremaining: 4.11s\n",
      "922:\tlearn: 0.3968244\ttotal: 48.7s\tremaining: 4.06s\n",
      "923:\tlearn: 0.3968160\ttotal: 48.7s\tremaining: 4s\n",
      "924:\tlearn: 0.3968068\ttotal: 48.7s\tremaining: 3.95s\n",
      "925:\tlearn: 0.3967928\ttotal: 48.8s\tremaining: 3.9s\n",
      "926:\tlearn: 0.3967891\ttotal: 48.8s\tremaining: 3.85s\n",
      "927:\tlearn: 0.3967853\ttotal: 48.9s\tremaining: 3.79s\n",
      "928:\tlearn: 0.3967745\ttotal: 48.9s\tremaining: 3.74s\n",
      "929:\tlearn: 0.3967722\ttotal: 49s\tremaining: 3.68s\n",
      "930:\tlearn: 0.3967671\ttotal: 49s\tremaining: 3.63s\n",
      "931:\tlearn: 0.3967586\ttotal: 49s\tremaining: 3.58s\n",
      "932:\tlearn: 0.3967559\ttotal: 49.1s\tremaining: 3.52s\n",
      "933:\tlearn: 0.3967497\ttotal: 49.1s\tremaining: 3.47s\n",
      "934:\tlearn: 0.3967396\ttotal: 49.2s\tremaining: 3.42s\n",
      "935:\tlearn: 0.3967341\ttotal: 49.2s\tremaining: 3.37s\n",
      "936:\tlearn: 0.3967335\ttotal: 49.3s\tremaining: 3.31s\n",
      "937:\tlearn: 0.3967312\ttotal: 49.3s\tremaining: 3.26s\n",
      "938:\tlearn: 0.3967252\ttotal: 49.4s\tremaining: 3.21s\n",
      "939:\tlearn: 0.3967127\ttotal: 49.4s\tremaining: 3.15s\n",
      "940:\tlearn: 0.3967074\ttotal: 49.4s\tremaining: 3.1s\n",
      "941:\tlearn: 0.3966860\ttotal: 49.5s\tremaining: 3.05s\n",
      "942:\tlearn: 0.3966698\ttotal: 49.5s\tremaining: 2.99s\n",
      "943:\tlearn: 0.3966672\ttotal: 49.6s\tremaining: 2.94s\n",
      "944:\tlearn: 0.3966652\ttotal: 49.6s\tremaining: 2.89s\n",
      "945:\tlearn: 0.3966489\ttotal: 49.7s\tremaining: 2.83s\n",
      "946:\tlearn: 0.3966483\ttotal: 49.7s\tremaining: 2.78s\n",
      "947:\tlearn: 0.3966412\ttotal: 49.8s\tremaining: 2.73s\n",
      "948:\tlearn: 0.3966378\ttotal: 49.8s\tremaining: 2.68s\n",
      "949:\tlearn: 0.3966337\ttotal: 49.9s\tremaining: 2.62s\n",
      "950:\tlearn: 0.3966287\ttotal: 49.9s\tremaining: 2.57s\n",
      "951:\tlearn: 0.3966278\ttotal: 49.9s\tremaining: 2.52s\n",
      "952:\tlearn: 0.3966230\ttotal: 50s\tremaining: 2.46s\n",
      "953:\tlearn: 0.3966067\ttotal: 50s\tremaining: 2.41s\n",
      "954:\tlearn: 0.3966049\ttotal: 50.1s\tremaining: 2.36s\n",
      "955:\tlearn: 0.3965997\ttotal: 50.1s\tremaining: 2.31s\n",
      "956:\tlearn: 0.3965966\ttotal: 50.2s\tremaining: 2.25s\n",
      "957:\tlearn: 0.3965895\ttotal: 50.2s\tremaining: 2.2s\n",
      "958:\tlearn: 0.3965844\ttotal: 50.3s\tremaining: 2.15s\n",
      "959:\tlearn: 0.3965786\ttotal: 50.3s\tremaining: 2.1s\n",
      "960:\tlearn: 0.3965699\ttotal: 50.3s\tremaining: 2.04s\n",
      "961:\tlearn: 0.3965587\ttotal: 50.4s\tremaining: 1.99s\n",
      "962:\tlearn: 0.3965499\ttotal: 50.4s\tremaining: 1.94s\n",
      "963:\tlearn: 0.3965470\ttotal: 50.5s\tremaining: 1.89s\n",
      "964:\tlearn: 0.3965420\ttotal: 50.6s\tremaining: 1.83s\n",
      "965:\tlearn: 0.3965366\ttotal: 50.6s\tremaining: 1.78s\n",
      "966:\tlearn: 0.3965364\ttotal: 50.6s\tremaining: 1.73s\n",
      "967:\tlearn: 0.3965266\ttotal: 50.7s\tremaining: 1.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968:\tlearn: 0.3965205\ttotal: 50.7s\tremaining: 1.62s\n",
      "969:\tlearn: 0.3965049\ttotal: 50.8s\tremaining: 1.57s\n",
      "970:\tlearn: 0.3964911\ttotal: 50.8s\tremaining: 1.52s\n",
      "971:\tlearn: 0.3964858\ttotal: 50.9s\tremaining: 1.46s\n",
      "972:\tlearn: 0.3964768\ttotal: 50.9s\tremaining: 1.41s\n",
      "973:\tlearn: 0.3964749\ttotal: 50.9s\tremaining: 1.36s\n",
      "974:\tlearn: 0.3964694\ttotal: 51s\tremaining: 1.31s\n",
      "975:\tlearn: 0.3964517\ttotal: 51.1s\tremaining: 1.25s\n",
      "976:\tlearn: 0.3964385\ttotal: 51.1s\tremaining: 1.2s\n",
      "977:\tlearn: 0.3964366\ttotal: 51.1s\tremaining: 1.15s\n",
      "978:\tlearn: 0.3964354\ttotal: 51.2s\tremaining: 1.1s\n",
      "979:\tlearn: 0.3964272\ttotal: 51.2s\tremaining: 1.04s\n",
      "980:\tlearn: 0.3964202\ttotal: 51.3s\tremaining: 993ms\n",
      "981:\tlearn: 0.3964062\ttotal: 51.3s\tremaining: 941ms\n",
      "982:\tlearn: 0.3963947\ttotal: 51.4s\tremaining: 888ms\n",
      "983:\tlearn: 0.3963897\ttotal: 51.4s\tremaining: 836ms\n",
      "984:\tlearn: 0.3963789\ttotal: 51.5s\tremaining: 784ms\n",
      "985:\tlearn: 0.3963774\ttotal: 51.5s\tremaining: 731ms\n",
      "986:\tlearn: 0.3963670\ttotal: 51.5s\tremaining: 679ms\n",
      "987:\tlearn: 0.3963584\ttotal: 51.6s\tremaining: 627ms\n",
      "988:\tlearn: 0.3963500\ttotal: 51.6s\tremaining: 574ms\n",
      "989:\tlearn: 0.3963408\ttotal: 51.7s\tremaining: 522ms\n",
      "990:\tlearn: 0.3963255\ttotal: 51.7s\tremaining: 470ms\n",
      "991:\tlearn: 0.3963161\ttotal: 51.8s\tremaining: 418ms\n",
      "992:\tlearn: 0.3963099\ttotal: 51.8s\tremaining: 365ms\n",
      "993:\tlearn: 0.3962992\ttotal: 51.9s\tremaining: 313ms\n",
      "994:\tlearn: 0.3962920\ttotal: 51.9s\tremaining: 261ms\n",
      "995:\tlearn: 0.3962784\ttotal: 52s\tremaining: 209ms\n",
      "996:\tlearn: 0.3962728\ttotal: 52s\tremaining: 157ms\n",
      "997:\tlearn: 0.3962699\ttotal: 52.1s\tremaining: 104ms\n",
      "998:\tlearn: 0.3962676\ttotal: 52.1s\tremaining: 52.2ms\n",
      "999:\tlearn: 0.3962513\ttotal: 52.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.rerank.TwoStageModel at 0x7f15e45f9cd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_stage.fit(dataset, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = two_stage.recommend(\n",
    "                    users=dataset.user_id_map.external_ids, \n",
    "                    dataset=dataset,\n",
    "                    k=10,\n",
    "                    filter_viewed=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11088450</th>\n",
       "      <td>1097557</td>\n",
       "      <td>10440</td>\n",
       "      <td>0.565327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088451</th>\n",
       "      <td>1097557</td>\n",
       "      <td>9728</td>\n",
       "      <td>0.493843</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088452</th>\n",
       "      <td>1097557</td>\n",
       "      <td>13865</td>\n",
       "      <td>0.463521</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088479</th>\n",
       "      <td>1097557</td>\n",
       "      <td>16228</td>\n",
       "      <td>0.396493</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088453</th>\n",
       "      <td>1097557</td>\n",
       "      <td>3734</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15152</th>\n",
       "      <td>0</td>\n",
       "      <td>4151</td>\n",
       "      <td>0.279995</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>0</td>\n",
       "      <td>7829</td>\n",
       "      <td>0.239109</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15156</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0.217433</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>0</td>\n",
       "      <td>14703</td>\n",
       "      <td>0.215547</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15160</th>\n",
       "      <td>0</td>\n",
       "      <td>7571</td>\n",
       "      <td>0.199354</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442880 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id     score  rank\n",
       "11088450  1097557    10440  0.565327     1\n",
       "11088451  1097557     9728  0.493843     2\n",
       "11088452  1097557    13865  0.463521     3\n",
       "11088479  1097557    16228  0.396493     4\n",
       "11088453  1097557     3734  0.369894     5\n",
       "...           ...      ...       ...   ...\n",
       "15152           0     4151  0.279995     6\n",
       "15168           0     7829  0.239109     7\n",
       "15156           0      142  0.217433     8\n",
       "15174           0    14703  0.215547     9\n",
       "15160           0     7571  0.199354    10\n",
       "\n",
       "[7442880 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CrossValidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostRanker guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To successfully launch CatBoostClassifier at the ranking stage, it is necessary to **process categorical features**: fill in empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we specify our custom feature collector for TwoStageModel\n",
    "# To transfer CatBoostRanker we use CatBoostRerankerWrapper (for faster work with large amounts of data)\n",
    "\n",
    "two_stage = TwoStageModel(first_stage,\n",
    "                          splitter,\n",
    "                          CatBoostRerankerWrapper(), # CatBoostRanker is initialized by default\n",
    "                          feature_collector=CustomFeatureCollectorCatBoost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['age', 'income', 'sex']\n",
    "\n",
    "# example parameters for running model training \n",
    "# more valid parameters here https://catboost.ai/en/docs/concepts/python-reference_pool\n",
    "fit_params = {\n",
    "    'cat_features': cat_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\ttotal: 163ms\tremaining: 2m 43s\n",
      "1:\ttotal: 266ms\tremaining: 2m 12s\n",
      "2:\ttotal: 364ms\tremaining: 2m 1s\n",
      "3:\ttotal: 463ms\tremaining: 1m 55s\n",
      "4:\ttotal: 564ms\tremaining: 1m 52s\n",
      "5:\ttotal: 663ms\tremaining: 1m 49s\n",
      "6:\ttotal: 760ms\tremaining: 1m 47s\n",
      "7:\ttotal: 858ms\tremaining: 1m 46s\n",
      "8:\ttotal: 955ms\tremaining: 1m 45s\n",
      "9:\ttotal: 1.05s\tremaining: 1m 44s\n",
      "10:\ttotal: 1.15s\tremaining: 1m 43s\n",
      "11:\ttotal: 1.25s\tremaining: 1m 42s\n",
      "12:\ttotal: 1.34s\tremaining: 1m 41s\n",
      "13:\ttotal: 1.44s\tremaining: 1m 41s\n",
      "14:\ttotal: 1.53s\tremaining: 1m 40s\n",
      "15:\ttotal: 1.65s\tremaining: 1m 41s\n",
      "16:\ttotal: 1.75s\tremaining: 1m 40s\n",
      "17:\ttotal: 1.85s\tremaining: 1m 40s\n",
      "18:\ttotal: 1.95s\tremaining: 1m 40s\n",
      "19:\ttotal: 2.04s\tremaining: 1m 40s\n",
      "20:\ttotal: 2.15s\tremaining: 1m 40s\n",
      "21:\ttotal: 2.24s\tremaining: 1m 39s\n",
      "22:\ttotal: 2.34s\tremaining: 1m 39s\n",
      "23:\ttotal: 2.44s\tremaining: 1m 39s\n",
      "24:\ttotal: 2.53s\tremaining: 1m 38s\n",
      "25:\ttotal: 2.63s\tremaining: 1m 38s\n",
      "26:\ttotal: 2.73s\tremaining: 1m 38s\n",
      "27:\ttotal: 2.82s\tremaining: 1m 37s\n",
      "28:\ttotal: 2.94s\tremaining: 1m 38s\n",
      "29:\ttotal: 3.04s\tremaining: 1m 38s\n",
      "30:\ttotal: 3.13s\tremaining: 1m 37s\n",
      "31:\ttotal: 3.23s\tremaining: 1m 37s\n",
      "32:\ttotal: 3.33s\tremaining: 1m 37s\n",
      "33:\ttotal: 3.42s\tremaining: 1m 37s\n",
      "34:\ttotal: 3.52s\tremaining: 1m 36s\n",
      "35:\ttotal: 3.61s\tremaining: 1m 36s\n",
      "36:\ttotal: 3.71s\tremaining: 1m 36s\n",
      "37:\ttotal: 3.81s\tremaining: 1m 36s\n",
      "38:\ttotal: 3.9s\tremaining: 1m 36s\n",
      "39:\ttotal: 4s\tremaining: 1m 35s\n",
      "40:\ttotal: 4.09s\tremaining: 1m 35s\n",
      "41:\ttotal: 4.19s\tremaining: 1m 35s\n",
      "42:\ttotal: 4.29s\tremaining: 1m 35s\n",
      "43:\ttotal: 4.38s\tremaining: 1m 35s\n",
      "44:\ttotal: 4.47s\tremaining: 1m 34s\n",
      "45:\ttotal: 4.57s\tremaining: 1m 34s\n",
      "46:\ttotal: 4.67s\tremaining: 1m 34s\n",
      "47:\ttotal: 4.76s\tremaining: 1m 34s\n",
      "48:\ttotal: 4.86s\tremaining: 1m 34s\n",
      "49:\ttotal: 4.96s\tremaining: 1m 34s\n",
      "50:\ttotal: 5.06s\tremaining: 1m 34s\n",
      "51:\ttotal: 5.15s\tremaining: 1m 33s\n",
      "52:\ttotal: 5.25s\tremaining: 1m 33s\n",
      "53:\ttotal: 5.34s\tremaining: 1m 33s\n",
      "54:\ttotal: 5.43s\tremaining: 1m 33s\n",
      "55:\ttotal: 5.53s\tremaining: 1m 33s\n",
      "56:\ttotal: 5.62s\tremaining: 1m 33s\n",
      "57:\ttotal: 5.72s\tremaining: 1m 32s\n",
      "58:\ttotal: 5.82s\tremaining: 1m 32s\n",
      "59:\ttotal: 5.91s\tremaining: 1m 32s\n",
      "60:\ttotal: 6.01s\tremaining: 1m 32s\n",
      "61:\ttotal: 6.1s\tremaining: 1m 32s\n",
      "62:\ttotal: 6.2s\tremaining: 1m 32s\n",
      "63:\ttotal: 6.3s\tremaining: 1m 32s\n",
      "64:\ttotal: 6.39s\tremaining: 1m 31s\n",
      "65:\ttotal: 6.49s\tremaining: 1m 31s\n",
      "66:\ttotal: 6.58s\tremaining: 1m 31s\n",
      "67:\ttotal: 6.68s\tremaining: 1m 31s\n",
      "68:\ttotal: 6.78s\tremaining: 1m 31s\n",
      "69:\ttotal: 6.87s\tremaining: 1m 31s\n",
      "70:\ttotal: 7.09s\tremaining: 1m 32s\n",
      "71:\ttotal: 7.27s\tremaining: 1m 33s\n",
      "72:\ttotal: 7.37s\tremaining: 1m 33s\n",
      "73:\ttotal: 7.47s\tremaining: 1m 33s\n",
      "74:\ttotal: 7.58s\tremaining: 1m 33s\n",
      "75:\ttotal: 7.68s\tremaining: 1m 33s\n",
      "76:\ttotal: 7.78s\tremaining: 1m 33s\n",
      "77:\ttotal: 7.88s\tremaining: 1m 33s\n",
      "78:\ttotal: 7.98s\tremaining: 1m 32s\n",
      "79:\ttotal: 8.07s\tremaining: 1m 32s\n",
      "80:\ttotal: 8.17s\tremaining: 1m 32s\n",
      "81:\ttotal: 8.27s\tremaining: 1m 32s\n",
      "82:\ttotal: 8.37s\tremaining: 1m 32s\n",
      "83:\ttotal: 8.46s\tremaining: 1m 32s\n",
      "84:\ttotal: 8.56s\tremaining: 1m 32s\n",
      "85:\ttotal: 8.66s\tremaining: 1m 32s\n",
      "86:\ttotal: 8.76s\tremaining: 1m 31s\n",
      "87:\ttotal: 8.85s\tremaining: 1m 31s\n",
      "88:\ttotal: 8.95s\tremaining: 1m 31s\n",
      "89:\ttotal: 9.05s\tremaining: 1m 31s\n",
      "90:\ttotal: 9.15s\tremaining: 1m 31s\n",
      "91:\ttotal: 9.25s\tremaining: 1m 31s\n",
      "92:\ttotal: 9.36s\tremaining: 1m 31s\n",
      "93:\ttotal: 9.46s\tremaining: 1m 31s\n",
      "94:\ttotal: 9.56s\tremaining: 1m 31s\n",
      "95:\ttotal: 9.66s\tremaining: 1m 30s\n",
      "96:\ttotal: 9.75s\tremaining: 1m 30s\n",
      "97:\ttotal: 9.85s\tremaining: 1m 30s\n",
      "98:\ttotal: 9.94s\tremaining: 1m 30s\n",
      "99:\ttotal: 10s\tremaining: 1m 30s\n",
      "100:\ttotal: 10.1s\tremaining: 1m 30s\n",
      "101:\ttotal: 10.2s\tremaining: 1m 30s\n",
      "102:\ttotal: 10.3s\tremaining: 1m 29s\n",
      "103:\ttotal: 10.4s\tremaining: 1m 29s\n",
      "104:\ttotal: 10.5s\tremaining: 1m 29s\n",
      "105:\ttotal: 10.6s\tremaining: 1m 29s\n",
      "106:\ttotal: 10.7s\tremaining: 1m 29s\n",
      "107:\ttotal: 10.8s\tremaining: 1m 29s\n",
      "108:\ttotal: 10.9s\tremaining: 1m 29s\n",
      "109:\ttotal: 11s\tremaining: 1m 29s\n",
      "110:\ttotal: 11.1s\tremaining: 1m 29s\n",
      "111:\ttotal: 11.2s\tremaining: 1m 28s\n",
      "112:\ttotal: 11.3s\tremaining: 1m 28s\n",
      "113:\ttotal: 11.4s\tremaining: 1m 28s\n",
      "114:\ttotal: 11.5s\tremaining: 1m 28s\n",
      "115:\ttotal: 11.6s\tremaining: 1m 28s\n",
      "116:\ttotal: 11.7s\tremaining: 1m 28s\n",
      "117:\ttotal: 11.8s\tremaining: 1m 28s\n",
      "118:\ttotal: 11.9s\tremaining: 1m 28s\n",
      "119:\ttotal: 12s\tremaining: 1m 27s\n",
      "120:\ttotal: 12.1s\tremaining: 1m 27s\n",
      "121:\ttotal: 12.2s\tremaining: 1m 27s\n",
      "122:\ttotal: 12.3s\tremaining: 1m 27s\n",
      "123:\ttotal: 12.4s\tremaining: 1m 27s\n",
      "124:\ttotal: 12.5s\tremaining: 1m 27s\n",
      "125:\ttotal: 12.6s\tremaining: 1m 27s\n",
      "126:\ttotal: 12.7s\tremaining: 1m 27s\n",
      "127:\ttotal: 12.8s\tremaining: 1m 27s\n",
      "128:\ttotal: 12.9s\tremaining: 1m 26s\n",
      "129:\ttotal: 13s\tremaining: 1m 26s\n",
      "130:\ttotal: 13.1s\tremaining: 1m 26s\n",
      "131:\ttotal: 13.2s\tremaining: 1m 26s\n",
      "132:\ttotal: 13.3s\tremaining: 1m 26s\n",
      "133:\ttotal: 13.4s\tremaining: 1m 26s\n",
      "134:\ttotal: 13.5s\tremaining: 1m 26s\n",
      "135:\ttotal: 13.5s\tremaining: 1m 26s\n",
      "136:\ttotal: 13.6s\tremaining: 1m 25s\n",
      "137:\ttotal: 13.7s\tremaining: 1m 25s\n",
      "138:\ttotal: 13.8s\tremaining: 1m 25s\n",
      "139:\ttotal: 13.9s\tremaining: 1m 25s\n",
      "140:\ttotal: 14s\tremaining: 1m 25s\n",
      "141:\ttotal: 14.1s\tremaining: 1m 25s\n",
      "142:\ttotal: 14.2s\tremaining: 1m 25s\n",
      "143:\ttotal: 14.3s\tremaining: 1m 25s\n",
      "144:\ttotal: 14.4s\tremaining: 1m 25s\n",
      "145:\ttotal: 14.5s\tremaining: 1m 24s\n",
      "146:\ttotal: 14.6s\tremaining: 1m 24s\n",
      "147:\ttotal: 14.7s\tremaining: 1m 24s\n",
      "148:\ttotal: 14.8s\tremaining: 1m 24s\n",
      "149:\ttotal: 14.9s\tremaining: 1m 24s\n",
      "150:\ttotal: 15s\tremaining: 1m 24s\n",
      "151:\ttotal: 15.1s\tremaining: 1m 24s\n",
      "152:\ttotal: 15.2s\tremaining: 1m 24s\n",
      "153:\ttotal: 15.3s\tremaining: 1m 24s\n",
      "154:\ttotal: 15.4s\tremaining: 1m 24s\n",
      "155:\ttotal: 15.5s\tremaining: 1m 23s\n",
      "156:\ttotal: 15.6s\tremaining: 1m 23s\n",
      "157:\ttotal: 15.7s\tremaining: 1m 23s\n",
      "158:\ttotal: 15.8s\tremaining: 1m 23s\n",
      "159:\ttotal: 15.9s\tremaining: 1m 23s\n",
      "160:\ttotal: 16s\tremaining: 1m 23s\n",
      "161:\ttotal: 16.1s\tremaining: 1m 23s\n",
      "162:\ttotal: 16.2s\tremaining: 1m 23s\n",
      "163:\ttotal: 16.3s\tremaining: 1m 23s\n",
      "164:\ttotal: 16.4s\tremaining: 1m 22s\n",
      "165:\ttotal: 16.5s\tremaining: 1m 22s\n",
      "166:\ttotal: 16.6s\tremaining: 1m 22s\n",
      "167:\ttotal: 16.7s\tremaining: 1m 22s\n",
      "168:\ttotal: 16.8s\tremaining: 1m 22s\n",
      "169:\ttotal: 16.9s\tremaining: 1m 22s\n",
      "170:\ttotal: 17s\tremaining: 1m 22s\n",
      "171:\ttotal: 17.1s\tremaining: 1m 22s\n",
      "172:\ttotal: 17.2s\tremaining: 1m 22s\n",
      "173:\ttotal: 17.3s\tremaining: 1m 22s\n",
      "174:\ttotal: 17.4s\tremaining: 1m 21s\n",
      "175:\ttotal: 17.5s\tremaining: 1m 21s\n",
      "176:\ttotal: 17.6s\tremaining: 1m 21s\n",
      "177:\ttotal: 17.7s\tremaining: 1m 21s\n",
      "178:\ttotal: 17.8s\tremaining: 1m 21s\n",
      "179:\ttotal: 17.9s\tremaining: 1m 21s\n",
      "180:\ttotal: 18s\tremaining: 1m 21s\n",
      "181:\ttotal: 18.1s\tremaining: 1m 21s\n",
      "182:\ttotal: 18.2s\tremaining: 1m 21s\n",
      "183:\ttotal: 18.3s\tremaining: 1m 21s\n",
      "184:\ttotal: 18.4s\tremaining: 1m 20s\n",
      "185:\ttotal: 18.5s\tremaining: 1m 20s\n",
      "186:\ttotal: 18.6s\tremaining: 1m 20s\n",
      "187:\ttotal: 18.7s\tremaining: 1m 20s\n",
      "188:\ttotal: 18.8s\tremaining: 1m 20s\n",
      "189:\ttotal: 18.8s\tremaining: 1m 20s\n",
      "190:\ttotal: 18.9s\tremaining: 1m 20s\n",
      "191:\ttotal: 19s\tremaining: 1m 20s\n",
      "192:\ttotal: 19.1s\tremaining: 1m 20s\n",
      "193:\ttotal: 19.2s\tremaining: 1m 19s\n",
      "194:\ttotal: 19.3s\tremaining: 1m 19s\n",
      "195:\ttotal: 19.4s\tremaining: 1m 19s\n",
      "196:\ttotal: 19.5s\tremaining: 1m 19s\n",
      "197:\ttotal: 19.6s\tremaining: 1m 19s\n",
      "198:\ttotal: 19.7s\tremaining: 1m 19s\n",
      "199:\ttotal: 19.8s\tremaining: 1m 19s\n",
      "200:\ttotal: 19.9s\tremaining: 1m 19s\n",
      "201:\ttotal: 20s\tremaining: 1m 19s\n",
      "202:\ttotal: 20.1s\tremaining: 1m 18s\n",
      "203:\ttotal: 20.2s\tremaining: 1m 18s\n",
      "204:\ttotal: 20.3s\tremaining: 1m 18s\n",
      "205:\ttotal: 20.4s\tremaining: 1m 18s\n",
      "206:\ttotal: 20.5s\tremaining: 1m 18s\n",
      "207:\ttotal: 20.6s\tremaining: 1m 18s\n",
      "208:\ttotal: 20.7s\tremaining: 1m 18s\n",
      "209:\ttotal: 20.8s\tremaining: 1m 18s\n",
      "210:\ttotal: 20.9s\tremaining: 1m 18s\n",
      "211:\ttotal: 21s\tremaining: 1m 17s\n",
      "212:\ttotal: 21.1s\tremaining: 1m 17s\n",
      "213:\ttotal: 21.2s\tremaining: 1m 17s\n",
      "214:\ttotal: 21.3s\tremaining: 1m 17s\n",
      "215:\ttotal: 21.4s\tremaining: 1m 17s\n",
      "216:\ttotal: 21.5s\tremaining: 1m 17s\n",
      "217:\ttotal: 21.6s\tremaining: 1m 17s\n",
      "218:\ttotal: 21.7s\tremaining: 1m 17s\n",
      "219:\ttotal: 21.8s\tremaining: 1m 17s\n",
      "220:\ttotal: 21.9s\tremaining: 1m 17s\n",
      "221:\ttotal: 22s\tremaining: 1m 16s\n",
      "222:\ttotal: 22s\tremaining: 1m 16s\n",
      "223:\ttotal: 22.1s\tremaining: 1m 16s\n",
      "224:\ttotal: 22.3s\tremaining: 1m 16s\n",
      "225:\ttotal: 22.4s\tremaining: 1m 16s\n",
      "226:\ttotal: 22.5s\tremaining: 1m 16s\n",
      "227:\ttotal: 22.6s\tremaining: 1m 16s\n",
      "228:\ttotal: 22.7s\tremaining: 1m 16s\n",
      "229:\ttotal: 22.8s\tremaining: 1m 16s\n",
      "230:\ttotal: 22.9s\tremaining: 1m 16s\n",
      "231:\ttotal: 23s\tremaining: 1m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232:\ttotal: 23.1s\tremaining: 1m 15s\n",
      "233:\ttotal: 23.2s\tremaining: 1m 15s\n",
      "234:\ttotal: 23.3s\tremaining: 1m 15s\n",
      "235:\ttotal: 23.4s\tremaining: 1m 15s\n",
      "236:\ttotal: 23.5s\tremaining: 1m 15s\n",
      "237:\ttotal: 23.6s\tremaining: 1m 15s\n",
      "238:\ttotal: 23.7s\tremaining: 1m 15s\n",
      "239:\ttotal: 23.8s\tremaining: 1m 15s\n",
      "240:\ttotal: 23.9s\tremaining: 1m 15s\n",
      "241:\ttotal: 24s\tremaining: 1m 15s\n",
      "242:\ttotal: 24.1s\tremaining: 1m 14s\n",
      "243:\ttotal: 24.2s\tremaining: 1m 14s\n",
      "244:\ttotal: 24.3s\tremaining: 1m 14s\n",
      "245:\ttotal: 24.4s\tremaining: 1m 14s\n",
      "246:\ttotal: 24.5s\tremaining: 1m 14s\n",
      "247:\ttotal: 24.6s\tremaining: 1m 14s\n",
      "248:\ttotal: 24.7s\tremaining: 1m 14s\n",
      "249:\ttotal: 24.8s\tremaining: 1m 14s\n",
      "250:\ttotal: 24.9s\tremaining: 1m 14s\n",
      "251:\ttotal: 25s\tremaining: 1m 14s\n",
      "252:\ttotal: 25.1s\tremaining: 1m 13s\n",
      "253:\ttotal: 25.2s\tremaining: 1m 13s\n",
      "254:\ttotal: 25.3s\tremaining: 1m 13s\n",
      "255:\ttotal: 25.3s\tremaining: 1m 13s\n",
      "256:\ttotal: 25.4s\tremaining: 1m 13s\n",
      "257:\ttotal: 25.5s\tremaining: 1m 13s\n",
      "258:\ttotal: 25.6s\tremaining: 1m 13s\n",
      "259:\ttotal: 25.7s\tremaining: 1m 13s\n",
      "260:\ttotal: 25.8s\tremaining: 1m 13s\n",
      "261:\ttotal: 25.9s\tremaining: 1m 13s\n",
      "262:\ttotal: 26s\tremaining: 1m 12s\n",
      "263:\ttotal: 26.1s\tremaining: 1m 12s\n",
      "264:\ttotal: 26.2s\tremaining: 1m 12s\n",
      "265:\ttotal: 26.3s\tremaining: 1m 12s\n",
      "266:\ttotal: 26.4s\tremaining: 1m 12s\n",
      "267:\ttotal: 26.5s\tremaining: 1m 12s\n",
      "268:\ttotal: 26.6s\tremaining: 1m 12s\n",
      "269:\ttotal: 26.7s\tremaining: 1m 12s\n",
      "270:\ttotal: 26.8s\tremaining: 1m 12s\n",
      "271:\ttotal: 26.9s\tremaining: 1m 12s\n",
      "272:\ttotal: 27s\tremaining: 1m 11s\n",
      "273:\ttotal: 27.1s\tremaining: 1m 11s\n",
      "274:\ttotal: 27.2s\tremaining: 1m 11s\n",
      "275:\ttotal: 27.3s\tremaining: 1m 11s\n",
      "276:\ttotal: 27.4s\tremaining: 1m 11s\n",
      "277:\ttotal: 27.5s\tremaining: 1m 11s\n",
      "278:\ttotal: 27.6s\tremaining: 1m 11s\n",
      "279:\ttotal: 27.7s\tremaining: 1m 11s\n",
      "280:\ttotal: 27.8s\tremaining: 1m 11s\n",
      "281:\ttotal: 27.9s\tremaining: 1m 11s\n",
      "282:\ttotal: 28s\tremaining: 1m 10s\n",
      "283:\ttotal: 28.1s\tremaining: 1m 10s\n",
      "284:\ttotal: 28.2s\tremaining: 1m 10s\n",
      "285:\ttotal: 28.3s\tremaining: 1m 10s\n",
      "286:\ttotal: 28.4s\tremaining: 1m 10s\n",
      "287:\ttotal: 28.5s\tremaining: 1m 10s\n",
      "288:\ttotal: 28.6s\tremaining: 1m 10s\n",
      "289:\ttotal: 28.7s\tremaining: 1m 10s\n",
      "290:\ttotal: 28.8s\tremaining: 1m 10s\n",
      "291:\ttotal: 28.9s\tremaining: 1m 10s\n",
      "292:\ttotal: 29.1s\tremaining: 1m 10s\n",
      "293:\ttotal: 29.2s\tremaining: 1m 10s\n",
      "294:\ttotal: 29.3s\tremaining: 1m 9s\n",
      "295:\ttotal: 29.4s\tremaining: 1m 9s\n",
      "296:\ttotal: 29.5s\tremaining: 1m 9s\n",
      "297:\ttotal: 29.6s\tremaining: 1m 9s\n",
      "298:\ttotal: 29.7s\tremaining: 1m 9s\n",
      "299:\ttotal: 29.8s\tremaining: 1m 9s\n",
      "300:\ttotal: 29.9s\tremaining: 1m 9s\n",
      "301:\ttotal: 30s\tremaining: 1m 9s\n",
      "302:\ttotal: 30.1s\tremaining: 1m 9s\n",
      "303:\ttotal: 30.2s\tremaining: 1m 9s\n",
      "304:\ttotal: 30.3s\tremaining: 1m 9s\n",
      "305:\ttotal: 30.5s\tremaining: 1m 9s\n",
      "306:\ttotal: 30.6s\tremaining: 1m 8s\n",
      "307:\ttotal: 30.7s\tremaining: 1m 8s\n",
      "308:\ttotal: 30.8s\tremaining: 1m 8s\n",
      "309:\ttotal: 30.9s\tremaining: 1m 8s\n",
      "310:\ttotal: 31s\tremaining: 1m 8s\n",
      "311:\ttotal: 31.1s\tremaining: 1m 8s\n",
      "312:\ttotal: 31.2s\tremaining: 1m 8s\n",
      "313:\ttotal: 31.3s\tremaining: 1m 8s\n",
      "314:\ttotal: 31.4s\tremaining: 1m 8s\n",
      "315:\ttotal: 31.5s\tremaining: 1m 8s\n",
      "316:\ttotal: 31.6s\tremaining: 1m 8s\n",
      "317:\ttotal: 31.7s\tremaining: 1m 8s\n",
      "318:\ttotal: 31.9s\tremaining: 1m 7s\n",
      "319:\ttotal: 32s\tremaining: 1m 7s\n",
      "320:\ttotal: 32.1s\tremaining: 1m 7s\n",
      "321:\ttotal: 32.2s\tremaining: 1m 7s\n",
      "322:\ttotal: 32.3s\tremaining: 1m 7s\n",
      "323:\ttotal: 32.4s\tremaining: 1m 7s\n",
      "324:\ttotal: 32.5s\tremaining: 1m 7s\n",
      "325:\ttotal: 32.6s\tremaining: 1m 7s\n",
      "326:\ttotal: 32.7s\tremaining: 1m 7s\n",
      "327:\ttotal: 32.8s\tremaining: 1m 7s\n",
      "328:\ttotal: 32.9s\tremaining: 1m 7s\n",
      "329:\ttotal: 33s\tremaining: 1m 7s\n",
      "330:\ttotal: 33.1s\tremaining: 1m 6s\n",
      "331:\ttotal: 33.2s\tremaining: 1m 6s\n",
      "332:\ttotal: 33.3s\tremaining: 1m 6s\n",
      "333:\ttotal: 33.4s\tremaining: 1m 6s\n",
      "334:\ttotal: 33.5s\tremaining: 1m 6s\n",
      "335:\ttotal: 33.7s\tremaining: 1m 6s\n",
      "336:\ttotal: 33.8s\tremaining: 1m 6s\n",
      "337:\ttotal: 33.9s\tremaining: 1m 6s\n",
      "338:\ttotal: 34s\tremaining: 1m 6s\n",
      "339:\ttotal: 34.1s\tremaining: 1m 6s\n",
      "340:\ttotal: 34.2s\tremaining: 1m 6s\n",
      "341:\ttotal: 34.3s\tremaining: 1m 5s\n",
      "342:\ttotal: 34.4s\tremaining: 1m 5s\n",
      "343:\ttotal: 34.5s\tremaining: 1m 5s\n",
      "344:\ttotal: 34.6s\tremaining: 1m 5s\n",
      "345:\ttotal: 34.7s\tremaining: 1m 5s\n",
      "346:\ttotal: 34.8s\tremaining: 1m 5s\n",
      "347:\ttotal: 34.9s\tremaining: 1m 5s\n",
      "348:\ttotal: 35s\tremaining: 1m 5s\n",
      "349:\ttotal: 35.1s\tremaining: 1m 5s\n",
      "350:\ttotal: 35.2s\tremaining: 1m 5s\n",
      "351:\ttotal: 35.3s\tremaining: 1m 4s\n",
      "352:\ttotal: 35.4s\tremaining: 1m 4s\n",
      "353:\ttotal: 35.5s\tremaining: 1m 4s\n",
      "354:\ttotal: 35.6s\tremaining: 1m 4s\n",
      "355:\ttotal: 35.7s\tremaining: 1m 4s\n",
      "356:\ttotal: 35.8s\tremaining: 1m 4s\n",
      "357:\ttotal: 35.9s\tremaining: 1m 4s\n",
      "358:\ttotal: 36s\tremaining: 1m 4s\n",
      "359:\ttotal: 36.1s\tremaining: 1m 4s\n",
      "360:\ttotal: 36.2s\tremaining: 1m 4s\n",
      "361:\ttotal: 36.3s\tremaining: 1m 4s\n",
      "362:\ttotal: 36.4s\tremaining: 1m 3s\n",
      "363:\ttotal: 36.5s\tremaining: 1m 3s\n",
      "364:\ttotal: 36.6s\tremaining: 1m 3s\n",
      "365:\ttotal: 36.7s\tremaining: 1m 3s\n",
      "366:\ttotal: 36.8s\tremaining: 1m 3s\n",
      "367:\ttotal: 36.9s\tremaining: 1m 3s\n",
      "368:\ttotal: 37s\tremaining: 1m 3s\n",
      "369:\ttotal: 37.1s\tremaining: 1m 3s\n",
      "370:\ttotal: 37.2s\tremaining: 1m 3s\n",
      "371:\ttotal: 37.3s\tremaining: 1m 3s\n",
      "372:\ttotal: 37.4s\tremaining: 1m 2s\n",
      "373:\ttotal: 37.6s\tremaining: 1m 2s\n",
      "374:\ttotal: 37.7s\tremaining: 1m 2s\n",
      "375:\ttotal: 37.8s\tremaining: 1m 2s\n",
      "376:\ttotal: 37.9s\tremaining: 1m 2s\n",
      "377:\ttotal: 38s\tremaining: 1m 2s\n",
      "378:\ttotal: 38.1s\tremaining: 1m 2s\n",
      "379:\ttotal: 38.2s\tremaining: 1m 2s\n",
      "380:\ttotal: 38.3s\tremaining: 1m 2s\n",
      "381:\ttotal: 38.4s\tremaining: 1m 2s\n",
      "382:\ttotal: 38.5s\tremaining: 1m 1s\n",
      "383:\ttotal: 38.6s\tremaining: 1m 1s\n",
      "384:\ttotal: 38.7s\tremaining: 1m 1s\n",
      "385:\ttotal: 38.8s\tremaining: 1m 1s\n",
      "386:\ttotal: 38.9s\tremaining: 1m 1s\n",
      "387:\ttotal: 39s\tremaining: 1m 1s\n",
      "388:\ttotal: 39.1s\tremaining: 1m 1s\n",
      "389:\ttotal: 39.2s\tremaining: 1m 1s\n",
      "390:\ttotal: 39.3s\tremaining: 1m 1s\n",
      "391:\ttotal: 39.4s\tremaining: 1m 1s\n",
      "392:\ttotal: 39.5s\tremaining: 1m 1s\n",
      "393:\ttotal: 39.6s\tremaining: 1m\n",
      "394:\ttotal: 39.7s\tremaining: 1m\n",
      "395:\ttotal: 39.8s\tremaining: 1m\n",
      "396:\ttotal: 39.9s\tremaining: 1m\n",
      "397:\ttotal: 40s\tremaining: 1m\n",
      "398:\ttotal: 40.1s\tremaining: 1m\n",
      "399:\ttotal: 40.2s\tremaining: 1m\n",
      "400:\ttotal: 40.4s\tremaining: 1m\n",
      "401:\ttotal: 40.5s\tremaining: 1m\n",
      "402:\ttotal: 40.6s\tremaining: 1m\n",
      "403:\ttotal: 40.7s\tremaining: 60s\n",
      "404:\ttotal: 40.8s\tremaining: 59.9s\n",
      "405:\ttotal: 40.9s\tremaining: 59.8s\n",
      "406:\ttotal: 41s\tremaining: 59.7s\n",
      "407:\ttotal: 41.1s\tremaining: 59.6s\n",
      "408:\ttotal: 41.2s\tremaining: 59.5s\n",
      "409:\ttotal: 41.3s\tremaining: 59.4s\n",
      "410:\ttotal: 41.4s\tremaining: 59.3s\n",
      "411:\ttotal: 41.5s\tremaining: 59.2s\n",
      "412:\ttotal: 41.6s\tremaining: 59.1s\n",
      "413:\ttotal: 41.7s\tremaining: 59s\n",
      "414:\ttotal: 41.8s\tremaining: 58.9s\n",
      "415:\ttotal: 41.9s\tremaining: 58.8s\n",
      "416:\ttotal: 42s\tremaining: 58.7s\n",
      "417:\ttotal: 42.1s\tremaining: 58.6s\n",
      "418:\ttotal: 42.2s\tremaining: 58.5s\n",
      "419:\ttotal: 42.3s\tremaining: 58.4s\n",
      "420:\ttotal: 42.4s\tremaining: 58.3s\n",
      "421:\ttotal: 42.5s\tremaining: 58.2s\n",
      "422:\ttotal: 42.6s\tremaining: 58.1s\n",
      "423:\ttotal: 42.7s\tremaining: 58s\n",
      "424:\ttotal: 42.8s\tremaining: 57.9s\n",
      "425:\ttotal: 42.9s\tremaining: 57.8s\n",
      "426:\ttotal: 43s\tremaining: 57.7s\n",
      "427:\ttotal: 43.1s\tremaining: 57.6s\n",
      "428:\ttotal: 43.2s\tremaining: 57.5s\n",
      "429:\ttotal: 43.3s\tremaining: 57.4s\n",
      "430:\ttotal: 43.4s\tremaining: 57.3s\n",
      "431:\ttotal: 43.5s\tremaining: 57.2s\n",
      "432:\ttotal: 43.6s\tremaining: 57.1s\n",
      "433:\ttotal: 43.7s\tremaining: 57s\n",
      "434:\ttotal: 43.8s\tremaining: 56.9s\n",
      "435:\ttotal: 43.9s\tremaining: 56.8s\n",
      "436:\ttotal: 44.1s\tremaining: 56.8s\n",
      "437:\ttotal: 44.2s\tremaining: 56.7s\n",
      "438:\ttotal: 44.3s\tremaining: 56.6s\n",
      "439:\ttotal: 44.4s\tremaining: 56.5s\n",
      "440:\ttotal: 44.5s\tremaining: 56.4s\n",
      "441:\ttotal: 44.6s\tremaining: 56.3s\n",
      "442:\ttotal: 44.7s\tremaining: 56.2s\n",
      "443:\ttotal: 44.8s\tremaining: 56.1s\n",
      "444:\ttotal: 44.9s\tremaining: 56s\n",
      "445:\ttotal: 45s\tremaining: 55.9s\n",
      "446:\ttotal: 45.1s\tremaining: 55.8s\n",
      "447:\ttotal: 45.2s\tremaining: 55.7s\n",
      "448:\ttotal: 45.3s\tremaining: 55.6s\n",
      "449:\ttotal: 45.4s\tremaining: 55.5s\n",
      "450:\ttotal: 45.5s\tremaining: 55.4s\n",
      "451:\ttotal: 45.6s\tremaining: 55.3s\n",
      "452:\ttotal: 45.7s\tremaining: 55.2s\n",
      "453:\ttotal: 45.8s\tremaining: 55.1s\n",
      "454:\ttotal: 45.9s\tremaining: 55s\n",
      "455:\ttotal: 46s\tremaining: 54.9s\n",
      "456:\ttotal: 46.1s\tremaining: 54.8s\n",
      "457:\ttotal: 46.2s\tremaining: 54.7s\n",
      "458:\ttotal: 46.3s\tremaining: 54.6s\n",
      "459:\ttotal: 46.4s\tremaining: 54.5s\n",
      "460:\ttotal: 46.5s\tremaining: 54.4s\n",
      "461:\ttotal: 46.6s\tremaining: 54.3s\n",
      "462:\ttotal: 46.7s\tremaining: 54.2s\n",
      "463:\ttotal: 46.8s\tremaining: 54.1s\n",
      "464:\ttotal: 46.9s\tremaining: 54s\n",
      "465:\ttotal: 47s\tremaining: 53.9s\n",
      "466:\ttotal: 47.1s\tremaining: 53.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467:\ttotal: 47.2s\tremaining: 53.7s\n",
      "468:\ttotal: 47.3s\tremaining: 53.6s\n",
      "469:\ttotal: 47.4s\tremaining: 53.5s\n",
      "470:\ttotal: 47.5s\tremaining: 53.4s\n",
      "471:\ttotal: 47.6s\tremaining: 53.3s\n",
      "472:\ttotal: 47.7s\tremaining: 53.2s\n",
      "473:\ttotal: 47.8s\tremaining: 53.1s\n",
      "474:\ttotal: 47.9s\tremaining: 53s\n",
      "475:\ttotal: 48.1s\tremaining: 52.9s\n",
      "476:\ttotal: 48.2s\tremaining: 52.8s\n",
      "477:\ttotal: 48.3s\tremaining: 52.7s\n",
      "478:\ttotal: 48.4s\tremaining: 52.6s\n",
      "479:\ttotal: 48.5s\tremaining: 52.5s\n",
      "480:\ttotal: 48.6s\tremaining: 52.4s\n",
      "481:\ttotal: 48.7s\tremaining: 52.3s\n",
      "482:\ttotal: 48.8s\tremaining: 52.2s\n",
      "483:\ttotal: 48.9s\tremaining: 52.1s\n",
      "484:\ttotal: 49s\tremaining: 52s\n",
      "485:\ttotal: 49.1s\tremaining: 51.9s\n",
      "486:\ttotal: 49.2s\tremaining: 51.8s\n",
      "487:\ttotal: 49.3s\tremaining: 51.7s\n",
      "488:\ttotal: 49.4s\tremaining: 51.6s\n",
      "489:\ttotal: 49.5s\tremaining: 51.5s\n",
      "490:\ttotal: 49.6s\tremaining: 51.4s\n",
      "491:\ttotal: 49.7s\tremaining: 51.3s\n",
      "492:\ttotal: 49.8s\tremaining: 51.2s\n",
      "493:\ttotal: 49.9s\tremaining: 51.1s\n",
      "494:\ttotal: 50s\tremaining: 51s\n",
      "495:\ttotal: 50.1s\tremaining: 50.9s\n",
      "496:\ttotal: 50.2s\tremaining: 50.8s\n",
      "497:\ttotal: 50.3s\tremaining: 50.7s\n",
      "498:\ttotal: 50.4s\tremaining: 50.6s\n",
      "499:\ttotal: 50.5s\tremaining: 50.5s\n",
      "500:\ttotal: 50.6s\tremaining: 50.4s\n",
      "501:\ttotal: 50.7s\tremaining: 50.3s\n",
      "502:\ttotal: 50.8s\tremaining: 50.2s\n",
      "503:\ttotal: 50.9s\tremaining: 50.1s\n",
      "504:\ttotal: 51s\tremaining: 50s\n",
      "505:\ttotal: 51.1s\tremaining: 49.9s\n",
      "506:\ttotal: 51.2s\tremaining: 49.8s\n",
      "507:\ttotal: 51.3s\tremaining: 49.7s\n",
      "508:\ttotal: 51.4s\tremaining: 49.6s\n",
      "509:\ttotal: 51.6s\tremaining: 49.5s\n",
      "510:\ttotal: 51.7s\tremaining: 49.4s\n",
      "511:\ttotal: 51.8s\tremaining: 49.3s\n",
      "512:\ttotal: 51.9s\tremaining: 49.2s\n",
      "513:\ttotal: 52s\tremaining: 49.1s\n",
      "514:\ttotal: 52.1s\tremaining: 49s\n",
      "515:\ttotal: 52.2s\tremaining: 48.9s\n",
      "516:\ttotal: 52.3s\tremaining: 48.8s\n",
      "517:\ttotal: 52.4s\tremaining: 48.7s\n",
      "518:\ttotal: 52.5s\tremaining: 48.6s\n",
      "519:\ttotal: 52.6s\tremaining: 48.5s\n",
      "520:\ttotal: 52.7s\tremaining: 48.4s\n",
      "521:\ttotal: 52.8s\tremaining: 48.3s\n",
      "522:\ttotal: 52.9s\tremaining: 48.2s\n",
      "523:\ttotal: 53s\tremaining: 48.1s\n",
      "524:\ttotal: 53.1s\tremaining: 48s\n",
      "525:\ttotal: 53.2s\tremaining: 47.9s\n",
      "526:\ttotal: 53.3s\tremaining: 47.8s\n",
      "527:\ttotal: 53.4s\tremaining: 47.7s\n",
      "528:\ttotal: 53.5s\tremaining: 47.6s\n",
      "529:\ttotal: 53.6s\tremaining: 47.5s\n",
      "530:\ttotal: 53.7s\tremaining: 47.4s\n",
      "531:\ttotal: 53.8s\tremaining: 47.3s\n",
      "532:\ttotal: 53.9s\tremaining: 47.2s\n",
      "533:\ttotal: 54s\tremaining: 47.1s\n",
      "534:\ttotal: 54.1s\tremaining: 47s\n",
      "535:\ttotal: 54.2s\tremaining: 46.9s\n",
      "536:\ttotal: 54.3s\tremaining: 46.8s\n",
      "537:\ttotal: 54.4s\tremaining: 46.7s\n",
      "538:\ttotal: 54.5s\tremaining: 46.6s\n",
      "539:\ttotal: 54.6s\tremaining: 46.5s\n",
      "540:\ttotal: 54.7s\tremaining: 46.4s\n",
      "541:\ttotal: 54.8s\tremaining: 46.3s\n",
      "542:\ttotal: 54.9s\tremaining: 46.2s\n",
      "543:\ttotal: 55s\tremaining: 46.1s\n",
      "544:\ttotal: 55.1s\tremaining: 46s\n",
      "545:\ttotal: 55.2s\tremaining: 45.9s\n",
      "546:\ttotal: 55.3s\tremaining: 45.8s\n",
      "547:\ttotal: 55.4s\tremaining: 45.7s\n",
      "548:\ttotal: 55.5s\tremaining: 45.6s\n",
      "549:\ttotal: 55.6s\tremaining: 45.5s\n",
      "550:\ttotal: 55.7s\tremaining: 45.4s\n",
      "551:\ttotal: 55.8s\tremaining: 45.3s\n",
      "552:\ttotal: 55.9s\tremaining: 45.2s\n",
      "553:\ttotal: 56s\tremaining: 45.1s\n",
      "554:\ttotal: 56.1s\tremaining: 45s\n",
      "555:\ttotal: 56.2s\tremaining: 44.9s\n",
      "556:\ttotal: 56.4s\tremaining: 44.8s\n",
      "557:\ttotal: 56.5s\tremaining: 44.7s\n",
      "558:\ttotal: 56.6s\tremaining: 44.6s\n",
      "559:\ttotal: 56.7s\tremaining: 44.5s\n",
      "560:\ttotal: 56.8s\tremaining: 44.5s\n",
      "561:\ttotal: 56.9s\tremaining: 44.4s\n",
      "562:\ttotal: 57s\tremaining: 44.3s\n",
      "563:\ttotal: 57.1s\tremaining: 44.2s\n",
      "564:\ttotal: 57.2s\tremaining: 44.1s\n",
      "565:\ttotal: 57.4s\tremaining: 44s\n",
      "566:\ttotal: 57.5s\tremaining: 43.9s\n",
      "567:\ttotal: 57.6s\tremaining: 43.8s\n",
      "568:\ttotal: 57.7s\tremaining: 43.7s\n",
      "569:\ttotal: 57.8s\tremaining: 43.6s\n",
      "570:\ttotal: 57.9s\tremaining: 43.5s\n",
      "571:\ttotal: 58s\tremaining: 43.4s\n",
      "572:\ttotal: 58.1s\tremaining: 43.3s\n",
      "573:\ttotal: 58.2s\tremaining: 43.2s\n",
      "574:\ttotal: 58.4s\tremaining: 43.1s\n",
      "575:\ttotal: 58.5s\tremaining: 43s\n",
      "576:\ttotal: 58.6s\tremaining: 42.9s\n",
      "577:\ttotal: 58.7s\tremaining: 42.8s\n",
      "578:\ttotal: 58.8s\tremaining: 42.8s\n",
      "579:\ttotal: 58.9s\tremaining: 42.7s\n",
      "580:\ttotal: 59s\tremaining: 42.6s\n",
      "581:\ttotal: 59.1s\tremaining: 42.5s\n",
      "582:\ttotal: 59.2s\tremaining: 42.4s\n",
      "583:\ttotal: 59.4s\tremaining: 42.3s\n",
      "584:\ttotal: 59.5s\tremaining: 42.2s\n",
      "585:\ttotal: 59.6s\tremaining: 42.1s\n",
      "586:\ttotal: 59.7s\tremaining: 42s\n",
      "587:\ttotal: 59.8s\tremaining: 41.9s\n",
      "588:\ttotal: 59.9s\tremaining: 41.8s\n",
      "589:\ttotal: 1m\tremaining: 41.7s\n",
      "590:\ttotal: 1m\tremaining: 41.6s\n",
      "591:\ttotal: 1m\tremaining: 41.5s\n",
      "592:\ttotal: 1m\tremaining: 41.4s\n",
      "593:\ttotal: 1m\tremaining: 41.3s\n",
      "594:\ttotal: 1m\tremaining: 41.2s\n",
      "595:\ttotal: 1m\tremaining: 41.2s\n",
      "596:\ttotal: 1m\tremaining: 41.1s\n",
      "597:\ttotal: 1m\tremaining: 41s\n",
      "598:\ttotal: 1m 1s\tremaining: 40.9s\n",
      "599:\ttotal: 1m 1s\tremaining: 40.8s\n",
      "600:\ttotal: 1m 1s\tremaining: 40.7s\n",
      "601:\ttotal: 1m 1s\tremaining: 40.6s\n",
      "602:\ttotal: 1m 1s\tremaining: 40.5s\n",
      "603:\ttotal: 1m 1s\tremaining: 40.4s\n",
      "604:\ttotal: 1m 1s\tremaining: 40.3s\n",
      "605:\ttotal: 1m 1s\tremaining: 40.2s\n",
      "606:\ttotal: 1m 1s\tremaining: 40.1s\n",
      "607:\ttotal: 1m 2s\tremaining: 40s\n",
      "608:\ttotal: 1m 2s\tremaining: 39.9s\n",
      "609:\ttotal: 1m 2s\tremaining: 39.8s\n",
      "610:\ttotal: 1m 2s\tremaining: 39.7s\n",
      "611:\ttotal: 1m 2s\tremaining: 39.6s\n",
      "612:\ttotal: 1m 2s\tremaining: 39.5s\n",
      "613:\ttotal: 1m 2s\tremaining: 39.4s\n",
      "614:\ttotal: 1m 2s\tremaining: 39.3s\n",
      "615:\ttotal: 1m 2s\tremaining: 39.2s\n",
      "616:\ttotal: 1m 3s\tremaining: 39.1s\n",
      "617:\ttotal: 1m 3s\tremaining: 39s\n",
      "618:\ttotal: 1m 3s\tremaining: 38.9s\n",
      "619:\ttotal: 1m 3s\tremaining: 38.9s\n",
      "620:\ttotal: 1m 3s\tremaining: 38.8s\n",
      "621:\ttotal: 1m 3s\tremaining: 38.7s\n",
      "622:\ttotal: 1m 3s\tremaining: 38.6s\n",
      "623:\ttotal: 1m 3s\tremaining: 38.5s\n",
      "624:\ttotal: 1m 3s\tremaining: 38.4s\n",
      "625:\ttotal: 1m 4s\tremaining: 38.3s\n",
      "626:\ttotal: 1m 4s\tremaining: 38.2s\n",
      "627:\ttotal: 1m 4s\tremaining: 38.1s\n",
      "628:\ttotal: 1m 4s\tremaining: 38s\n",
      "629:\ttotal: 1m 4s\tremaining: 37.9s\n",
      "630:\ttotal: 1m 4s\tremaining: 37.8s\n",
      "631:\ttotal: 1m 4s\tremaining: 37.7s\n",
      "632:\ttotal: 1m 4s\tremaining: 37.6s\n",
      "633:\ttotal: 1m 4s\tremaining: 37.5s\n",
      "634:\ttotal: 1m 5s\tremaining: 37.4s\n",
      "635:\ttotal: 1m 5s\tremaining: 37.3s\n",
      "636:\ttotal: 1m 5s\tremaining: 37.2s\n",
      "637:\ttotal: 1m 5s\tremaining: 37.1s\n",
      "638:\ttotal: 1m 5s\tremaining: 37s\n",
      "639:\ttotal: 1m 5s\tremaining: 36.9s\n",
      "640:\ttotal: 1m 5s\tremaining: 36.8s\n",
      "641:\ttotal: 1m 5s\tremaining: 36.7s\n",
      "642:\ttotal: 1m 5s\tremaining: 36.6s\n",
      "643:\ttotal: 1m 6s\tremaining: 36.5s\n",
      "644:\ttotal: 1m 6s\tremaining: 36.4s\n",
      "645:\ttotal: 1m 6s\tremaining: 36.3s\n",
      "646:\ttotal: 1m 6s\tremaining: 36.2s\n",
      "647:\ttotal: 1m 6s\tremaining: 36.1s\n",
      "648:\ttotal: 1m 6s\tremaining: 36s\n",
      "649:\ttotal: 1m 6s\tremaining: 35.9s\n",
      "650:\ttotal: 1m 6s\tremaining: 35.8s\n",
      "651:\ttotal: 1m 6s\tremaining: 35.7s\n",
      "652:\ttotal: 1m 7s\tremaining: 35.7s\n",
      "653:\ttotal: 1m 7s\tremaining: 35.6s\n",
      "654:\ttotal: 1m 7s\tremaining: 35.5s\n",
      "655:\ttotal: 1m 7s\tremaining: 35.4s\n",
      "656:\ttotal: 1m 7s\tremaining: 35.3s\n",
      "657:\ttotal: 1m 7s\tremaining: 35.2s\n",
      "658:\ttotal: 1m 7s\tremaining: 35.1s\n",
      "659:\ttotal: 1m 7s\tremaining: 35s\n",
      "660:\ttotal: 1m 7s\tremaining: 34.9s\n",
      "661:\ttotal: 1m 8s\tremaining: 34.8s\n",
      "662:\ttotal: 1m 8s\tremaining: 34.7s\n",
      "663:\ttotal: 1m 8s\tremaining: 34.6s\n",
      "664:\ttotal: 1m 8s\tremaining: 34.5s\n",
      "665:\ttotal: 1m 8s\tremaining: 34.4s\n",
      "666:\ttotal: 1m 8s\tremaining: 34.3s\n",
      "667:\ttotal: 1m 8s\tremaining: 34.2s\n",
      "668:\ttotal: 1m 8s\tremaining: 34.1s\n",
      "669:\ttotal: 1m 8s\tremaining: 34s\n",
      "670:\ttotal: 1m 9s\tremaining: 33.9s\n",
      "671:\ttotal: 1m 9s\tremaining: 33.8s\n",
      "672:\ttotal: 1m 9s\tremaining: 33.7s\n",
      "673:\ttotal: 1m 9s\tremaining: 33.6s\n",
      "674:\ttotal: 1m 9s\tremaining: 33.5s\n",
      "675:\ttotal: 1m 9s\tremaining: 33.4s\n",
      "676:\ttotal: 1m 9s\tremaining: 33.3s\n",
      "677:\ttotal: 1m 9s\tremaining: 33.2s\n",
      "678:\ttotal: 1m 10s\tremaining: 33.1s\n",
      "679:\ttotal: 1m 10s\tremaining: 33s\n",
      "680:\ttotal: 1m 10s\tremaining: 32.9s\n",
      "681:\ttotal: 1m 10s\tremaining: 32.8s\n",
      "682:\ttotal: 1m 10s\tremaining: 32.7s\n",
      "683:\ttotal: 1m 10s\tremaining: 32.6s\n",
      "684:\ttotal: 1m 10s\tremaining: 32.5s\n",
      "685:\ttotal: 1m 10s\tremaining: 32.4s\n",
      "686:\ttotal: 1m 10s\tremaining: 32.3s\n",
      "687:\ttotal: 1m 11s\tremaining: 32.2s\n",
      "688:\ttotal: 1m 11s\tremaining: 32.1s\n",
      "689:\ttotal: 1m 11s\tremaining: 32s\n",
      "690:\ttotal: 1m 11s\tremaining: 31.9s\n",
      "691:\ttotal: 1m 11s\tremaining: 31.8s\n",
      "692:\ttotal: 1m 11s\tremaining: 31.7s\n",
      "693:\ttotal: 1m 11s\tremaining: 31.6s\n",
      "694:\ttotal: 1m 11s\tremaining: 31.5s\n",
      "695:\ttotal: 1m 11s\tremaining: 31.4s\n",
      "696:\ttotal: 1m 11s\tremaining: 31.3s\n",
      "697:\ttotal: 1m 12s\tremaining: 31.2s\n",
      "698:\ttotal: 1m 12s\tremaining: 31.1s\n",
      "699:\ttotal: 1m 12s\tremaining: 31s\n",
      "700:\ttotal: 1m 12s\tremaining: 30.9s\n",
      "701:\ttotal: 1m 12s\tremaining: 30.8s\n",
      "702:\ttotal: 1m 12s\tremaining: 30.7s\n",
      "703:\ttotal: 1m 12s\tremaining: 30.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704:\ttotal: 1m 12s\tremaining: 30.5s\n",
      "705:\ttotal: 1m 13s\tremaining: 30.4s\n",
      "706:\ttotal: 1m 13s\tremaining: 30.3s\n",
      "707:\ttotal: 1m 13s\tremaining: 30.2s\n",
      "708:\ttotal: 1m 13s\tremaining: 30.1s\n",
      "709:\ttotal: 1m 13s\tremaining: 30s\n",
      "710:\ttotal: 1m 13s\tremaining: 29.9s\n",
      "711:\ttotal: 1m 13s\tremaining: 29.8s\n",
      "712:\ttotal: 1m 13s\tremaining: 29.7s\n",
      "713:\ttotal: 1m 13s\tremaining: 29.6s\n",
      "714:\ttotal: 1m 14s\tremaining: 29.5s\n",
      "715:\ttotal: 1m 14s\tremaining: 29.4s\n",
      "716:\ttotal: 1m 14s\tremaining: 29.3s\n",
      "717:\ttotal: 1m 14s\tremaining: 29.2s\n",
      "718:\ttotal: 1m 14s\tremaining: 29.1s\n",
      "719:\ttotal: 1m 14s\tremaining: 29s\n",
      "720:\ttotal: 1m 14s\tremaining: 28.9s\n",
      "721:\ttotal: 1m 14s\tremaining: 28.8s\n",
      "722:\ttotal: 1m 14s\tremaining: 28.7s\n",
      "723:\ttotal: 1m 15s\tremaining: 28.6s\n",
      "724:\ttotal: 1m 15s\tremaining: 28.5s\n",
      "725:\ttotal: 1m 15s\tremaining: 28.4s\n",
      "726:\ttotal: 1m 15s\tremaining: 28.3s\n",
      "727:\ttotal: 1m 15s\tremaining: 28.2s\n",
      "728:\ttotal: 1m 15s\tremaining: 28.1s\n",
      "729:\ttotal: 1m 15s\tremaining: 28s\n",
      "730:\ttotal: 1m 15s\tremaining: 27.9s\n",
      "731:\ttotal: 1m 15s\tremaining: 27.8s\n",
      "732:\ttotal: 1m 16s\tremaining: 27.7s\n",
      "733:\ttotal: 1m 16s\tremaining: 27.6s\n",
      "734:\ttotal: 1m 16s\tremaining: 27.5s\n",
      "735:\ttotal: 1m 16s\tremaining: 27.4s\n",
      "736:\ttotal: 1m 16s\tremaining: 27.3s\n",
      "737:\ttotal: 1m 16s\tremaining: 27.2s\n",
      "738:\ttotal: 1m 16s\tremaining: 27.1s\n",
      "739:\ttotal: 1m 16s\tremaining: 27s\n",
      "740:\ttotal: 1m 16s\tremaining: 26.9s\n",
      "741:\ttotal: 1m 17s\tremaining: 26.8s\n",
      "742:\ttotal: 1m 17s\tremaining: 26.7s\n",
      "743:\ttotal: 1m 17s\tremaining: 26.6s\n",
      "744:\ttotal: 1m 17s\tremaining: 26.5s\n",
      "745:\ttotal: 1m 17s\tremaining: 26.4s\n",
      "746:\ttotal: 1m 17s\tremaining: 26.3s\n",
      "747:\ttotal: 1m 17s\tremaining: 26.2s\n",
      "748:\ttotal: 1m 17s\tremaining: 26.1s\n",
      "749:\ttotal: 1m 17s\tremaining: 26s\n",
      "750:\ttotal: 1m 18s\tremaining: 25.9s\n",
      "751:\ttotal: 1m 18s\tremaining: 25.8s\n",
      "752:\ttotal: 1m 18s\tremaining: 25.7s\n",
      "753:\ttotal: 1m 18s\tremaining: 25.6s\n",
      "754:\ttotal: 1m 18s\tremaining: 25.5s\n",
      "755:\ttotal: 1m 18s\tremaining: 25.4s\n",
      "756:\ttotal: 1m 18s\tremaining: 25.3s\n",
      "757:\ttotal: 1m 18s\tremaining: 25.2s\n",
      "758:\ttotal: 1m 19s\tremaining: 25.1s\n",
      "759:\ttotal: 1m 19s\tremaining: 25s\n",
      "760:\ttotal: 1m 19s\tremaining: 24.9s\n",
      "761:\ttotal: 1m 19s\tremaining: 24.8s\n",
      "762:\ttotal: 1m 19s\tremaining: 24.7s\n",
      "763:\ttotal: 1m 19s\tremaining: 24.6s\n",
      "764:\ttotal: 1m 19s\tremaining: 24.5s\n",
      "765:\ttotal: 1m 19s\tremaining: 24.4s\n",
      "766:\ttotal: 1m 19s\tremaining: 24.3s\n",
      "767:\ttotal: 1m 20s\tremaining: 24.2s\n",
      "768:\ttotal: 1m 20s\tremaining: 24.1s\n",
      "769:\ttotal: 1m 20s\tremaining: 24s\n",
      "770:\ttotal: 1m 20s\tremaining: 23.9s\n",
      "771:\ttotal: 1m 20s\tremaining: 23.8s\n",
      "772:\ttotal: 1m 20s\tremaining: 23.7s\n",
      "773:\ttotal: 1m 20s\tremaining: 23.6s\n",
      "774:\ttotal: 1m 20s\tremaining: 23.5s\n",
      "775:\ttotal: 1m 20s\tremaining: 23.4s\n",
      "776:\ttotal: 1m 21s\tremaining: 23.3s\n",
      "777:\ttotal: 1m 21s\tremaining: 23.2s\n",
      "778:\ttotal: 1m 21s\tremaining: 23.1s\n",
      "779:\ttotal: 1m 21s\tremaining: 23s\n",
      "780:\ttotal: 1m 21s\tremaining: 22.9s\n",
      "781:\ttotal: 1m 21s\tremaining: 22.8s\n",
      "782:\ttotal: 1m 21s\tremaining: 22.7s\n",
      "783:\ttotal: 1m 21s\tremaining: 22.6s\n",
      "784:\ttotal: 1m 22s\tremaining: 22.5s\n",
      "785:\ttotal: 1m 22s\tremaining: 22.4s\n",
      "786:\ttotal: 1m 22s\tremaining: 22.3s\n",
      "787:\ttotal: 1m 22s\tremaining: 22.2s\n",
      "788:\ttotal: 1m 22s\tremaining: 22.1s\n",
      "789:\ttotal: 1m 22s\tremaining: 22s\n",
      "790:\ttotal: 1m 22s\tremaining: 21.9s\n",
      "791:\ttotal: 1m 22s\tremaining: 21.8s\n",
      "792:\ttotal: 1m 22s\tremaining: 21.6s\n",
      "793:\ttotal: 1m 23s\tremaining: 21.5s\n",
      "794:\ttotal: 1m 23s\tremaining: 21.4s\n",
      "795:\ttotal: 1m 23s\tremaining: 21.3s\n",
      "796:\ttotal: 1m 23s\tremaining: 21.2s\n",
      "797:\ttotal: 1m 23s\tremaining: 21.1s\n",
      "798:\ttotal: 1m 23s\tremaining: 21s\n",
      "799:\ttotal: 1m 23s\tremaining: 20.9s\n",
      "800:\ttotal: 1m 23s\tremaining: 20.8s\n",
      "801:\ttotal: 1m 23s\tremaining: 20.7s\n",
      "802:\ttotal: 1m 24s\tremaining: 20.6s\n",
      "803:\ttotal: 1m 24s\tremaining: 20.5s\n",
      "804:\ttotal: 1m 24s\tremaining: 20.4s\n",
      "805:\ttotal: 1m 24s\tremaining: 20.3s\n",
      "806:\ttotal: 1m 24s\tremaining: 20.2s\n",
      "807:\ttotal: 1m 24s\tremaining: 20.1s\n",
      "808:\ttotal: 1m 24s\tremaining: 20s\n",
      "809:\ttotal: 1m 24s\tremaining: 19.9s\n",
      "810:\ttotal: 1m 24s\tremaining: 19.8s\n",
      "811:\ttotal: 1m 25s\tremaining: 19.7s\n",
      "812:\ttotal: 1m 25s\tremaining: 19.6s\n",
      "813:\ttotal: 1m 25s\tremaining: 19.5s\n",
      "814:\ttotal: 1m 25s\tremaining: 19.4s\n",
      "815:\ttotal: 1m 25s\tremaining: 19.3s\n",
      "816:\ttotal: 1m 25s\tremaining: 19.2s\n",
      "817:\ttotal: 1m 25s\tremaining: 19.1s\n",
      "818:\ttotal: 1m 25s\tremaining: 19s\n",
      "819:\ttotal: 1m 25s\tremaining: 18.9s\n",
      "820:\ttotal: 1m 26s\tremaining: 18.8s\n",
      "821:\ttotal: 1m 26s\tremaining: 18.6s\n",
      "822:\ttotal: 1m 26s\tremaining: 18.5s\n",
      "823:\ttotal: 1m 26s\tremaining: 18.4s\n",
      "824:\ttotal: 1m 26s\tremaining: 18.3s\n",
      "825:\ttotal: 1m 26s\tremaining: 18.2s\n",
      "826:\ttotal: 1m 26s\tremaining: 18.1s\n",
      "827:\ttotal: 1m 26s\tremaining: 18s\n",
      "828:\ttotal: 1m 26s\tremaining: 17.9s\n",
      "829:\ttotal: 1m 26s\tremaining: 17.8s\n",
      "830:\ttotal: 1m 27s\tremaining: 17.7s\n",
      "831:\ttotal: 1m 27s\tremaining: 17.6s\n",
      "832:\ttotal: 1m 27s\tremaining: 17.5s\n",
      "833:\ttotal: 1m 27s\tremaining: 17.4s\n",
      "834:\ttotal: 1m 27s\tremaining: 17.3s\n",
      "835:\ttotal: 1m 27s\tremaining: 17.2s\n",
      "836:\ttotal: 1m 27s\tremaining: 17.1s\n",
      "837:\ttotal: 1m 27s\tremaining: 17s\n",
      "838:\ttotal: 1m 27s\tremaining: 16.9s\n",
      "839:\ttotal: 1m 28s\tremaining: 16.8s\n",
      "840:\ttotal: 1m 28s\tremaining: 16.7s\n",
      "841:\ttotal: 1m 28s\tremaining: 16.6s\n",
      "842:\ttotal: 1m 28s\tremaining: 16.5s\n",
      "843:\ttotal: 1m 28s\tremaining: 16.4s\n",
      "844:\ttotal: 1m 28s\tremaining: 16.3s\n",
      "845:\ttotal: 1m 28s\tremaining: 16.2s\n",
      "846:\ttotal: 1m 28s\tremaining: 16.1s\n",
      "847:\ttotal: 1m 28s\tremaining: 16s\n",
      "848:\ttotal: 1m 29s\tremaining: 15.8s\n",
      "849:\ttotal: 1m 29s\tremaining: 15.7s\n",
      "850:\ttotal: 1m 29s\tremaining: 15.6s\n",
      "851:\ttotal: 1m 29s\tremaining: 15.5s\n",
      "852:\ttotal: 1m 29s\tremaining: 15.4s\n",
      "853:\ttotal: 1m 29s\tremaining: 15.3s\n",
      "854:\ttotal: 1m 29s\tremaining: 15.2s\n",
      "855:\ttotal: 1m 29s\tremaining: 15.1s\n",
      "856:\ttotal: 1m 29s\tremaining: 15s\n",
      "857:\ttotal: 1m 30s\tremaining: 14.9s\n",
      "858:\ttotal: 1m 30s\tremaining: 14.8s\n",
      "859:\ttotal: 1m 30s\tremaining: 14.7s\n",
      "860:\ttotal: 1m 30s\tremaining: 14.6s\n",
      "861:\ttotal: 1m 30s\tremaining: 14.5s\n",
      "862:\ttotal: 1m 30s\tremaining: 14.4s\n",
      "863:\ttotal: 1m 30s\tremaining: 14.3s\n",
      "864:\ttotal: 1m 30s\tremaining: 14.2s\n",
      "865:\ttotal: 1m 30s\tremaining: 14.1s\n",
      "866:\ttotal: 1m 31s\tremaining: 14s\n",
      "867:\ttotal: 1m 31s\tremaining: 13.9s\n",
      "868:\ttotal: 1m 31s\tremaining: 13.8s\n",
      "869:\ttotal: 1m 31s\tremaining: 13.7s\n",
      "870:\ttotal: 1m 31s\tremaining: 13.6s\n",
      "871:\ttotal: 1m 31s\tremaining: 13.5s\n",
      "872:\ttotal: 1m 31s\tremaining: 13.4s\n",
      "873:\ttotal: 1m 31s\tremaining: 13.2s\n",
      "874:\ttotal: 1m 32s\tremaining: 13.1s\n",
      "875:\ttotal: 1m 32s\tremaining: 13s\n",
      "876:\ttotal: 1m 32s\tremaining: 12.9s\n",
      "877:\ttotal: 1m 32s\tremaining: 12.8s\n",
      "878:\ttotal: 1m 32s\tremaining: 12.7s\n",
      "879:\ttotal: 1m 32s\tremaining: 12.6s\n",
      "880:\ttotal: 1m 32s\tremaining: 12.5s\n",
      "881:\ttotal: 1m 32s\tremaining: 12.4s\n",
      "882:\ttotal: 1m 32s\tremaining: 12.3s\n",
      "883:\ttotal: 1m 33s\tremaining: 12.2s\n",
      "884:\ttotal: 1m 33s\tremaining: 12.1s\n",
      "885:\ttotal: 1m 33s\tremaining: 12s\n",
      "886:\ttotal: 1m 33s\tremaining: 11.9s\n",
      "887:\ttotal: 1m 33s\tremaining: 11.8s\n",
      "888:\ttotal: 1m 33s\tremaining: 11.7s\n",
      "889:\ttotal: 1m 33s\tremaining: 11.6s\n",
      "890:\ttotal: 1m 33s\tremaining: 11.5s\n",
      "891:\ttotal: 1m 33s\tremaining: 11.4s\n",
      "892:\ttotal: 1m 34s\tremaining: 11.3s\n",
      "893:\ttotal: 1m 34s\tremaining: 11.2s\n",
      "894:\ttotal: 1m 34s\tremaining: 11.1s\n",
      "895:\ttotal: 1m 34s\tremaining: 11s\n",
      "896:\ttotal: 1m 34s\tremaining: 10.9s\n",
      "897:\ttotal: 1m 34s\tremaining: 10.8s\n",
      "898:\ttotal: 1m 34s\tremaining: 10.6s\n",
      "899:\ttotal: 1m 34s\tremaining: 10.5s\n",
      "900:\ttotal: 1m 34s\tremaining: 10.4s\n",
      "901:\ttotal: 1m 35s\tremaining: 10.3s\n",
      "902:\ttotal: 1m 35s\tremaining: 10.2s\n",
      "903:\ttotal: 1m 35s\tremaining: 10.1s\n",
      "904:\ttotal: 1m 35s\tremaining: 10s\n",
      "905:\ttotal: 1m 35s\tremaining: 9.91s\n",
      "906:\ttotal: 1m 35s\tremaining: 9.81s\n",
      "907:\ttotal: 1m 35s\tremaining: 9.7s\n",
      "908:\ttotal: 1m 35s\tremaining: 9.6s\n",
      "909:\ttotal: 1m 35s\tremaining: 9.49s\n",
      "910:\ttotal: 1m 36s\tremaining: 9.39s\n",
      "911:\ttotal: 1m 36s\tremaining: 9.28s\n",
      "912:\ttotal: 1m 36s\tremaining: 9.18s\n",
      "913:\ttotal: 1m 36s\tremaining: 9.07s\n",
      "914:\ttotal: 1m 36s\tremaining: 8.97s\n",
      "915:\ttotal: 1m 36s\tremaining: 8.86s\n",
      "916:\ttotal: 1m 36s\tremaining: 8.76s\n",
      "917:\ttotal: 1m 36s\tremaining: 8.65s\n",
      "918:\ttotal: 1m 37s\tremaining: 8.55s\n",
      "919:\ttotal: 1m 37s\tremaining: 8.44s\n",
      "920:\ttotal: 1m 37s\tremaining: 8.34s\n",
      "921:\ttotal: 1m 37s\tremaining: 8.23s\n",
      "922:\ttotal: 1m 37s\tremaining: 8.13s\n",
      "923:\ttotal: 1m 37s\tremaining: 8.02s\n",
      "924:\ttotal: 1m 37s\tremaining: 7.92s\n",
      "925:\ttotal: 1m 37s\tremaining: 7.82s\n",
      "926:\ttotal: 1m 37s\tremaining: 7.71s\n",
      "927:\ttotal: 1m 38s\tremaining: 7.6s\n",
      "928:\ttotal: 1m 38s\tremaining: 7.5s\n",
      "929:\ttotal: 1m 38s\tremaining: 7.39s\n",
      "930:\ttotal: 1m 38s\tremaining: 7.29s\n",
      "931:\ttotal: 1m 38s\tremaining: 7.18s\n",
      "932:\ttotal: 1m 38s\tremaining: 7.08s\n",
      "933:\ttotal: 1m 38s\tremaining: 6.97s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934:\ttotal: 1m 38s\tremaining: 6.87s\n",
      "935:\ttotal: 1m 38s\tremaining: 6.76s\n",
      "936:\ttotal: 1m 39s\tremaining: 6.66s\n",
      "937:\ttotal: 1m 39s\tremaining: 6.55s\n",
      "938:\ttotal: 1m 39s\tremaining: 6.45s\n",
      "939:\ttotal: 1m 39s\tremaining: 6.34s\n",
      "940:\ttotal: 1m 39s\tremaining: 6.24s\n",
      "941:\ttotal: 1m 39s\tremaining: 6.13s\n",
      "942:\ttotal: 1m 39s\tremaining: 6.03s\n",
      "943:\ttotal: 1m 39s\tremaining: 5.92s\n",
      "944:\ttotal: 1m 39s\tremaining: 5.82s\n",
      "945:\ttotal: 1m 40s\tremaining: 5.71s\n",
      "946:\ttotal: 1m 40s\tremaining: 5.6s\n",
      "947:\ttotal: 1m 40s\tremaining: 5.5s\n",
      "948:\ttotal: 1m 40s\tremaining: 5.39s\n",
      "949:\ttotal: 1m 40s\tremaining: 5.29s\n",
      "950:\ttotal: 1m 40s\tremaining: 5.18s\n",
      "951:\ttotal: 1m 40s\tremaining: 5.08s\n",
      "952:\ttotal: 1m 40s\tremaining: 4.97s\n",
      "953:\ttotal: 1m 40s\tremaining: 4.87s\n",
      "954:\ttotal: 1m 41s\tremaining: 4.76s\n",
      "955:\ttotal: 1m 41s\tremaining: 4.66s\n",
      "956:\ttotal: 1m 41s\tremaining: 4.55s\n",
      "957:\ttotal: 1m 41s\tremaining: 4.44s\n",
      "958:\ttotal: 1m 41s\tremaining: 4.34s\n",
      "959:\ttotal: 1m 41s\tremaining: 4.23s\n",
      "960:\ttotal: 1m 41s\tremaining: 4.13s\n",
      "961:\ttotal: 1m 41s\tremaining: 4.02s\n",
      "962:\ttotal: 1m 41s\tremaining: 3.92s\n",
      "963:\ttotal: 1m 42s\tremaining: 3.81s\n",
      "964:\ttotal: 1m 42s\tremaining: 3.71s\n",
      "965:\ttotal: 1m 42s\tremaining: 3.6s\n",
      "966:\ttotal: 1m 42s\tremaining: 3.49s\n",
      "967:\ttotal: 1m 42s\tremaining: 3.39s\n",
      "968:\ttotal: 1m 42s\tremaining: 3.28s\n",
      "969:\ttotal: 1m 42s\tremaining: 3.18s\n",
      "970:\ttotal: 1m 42s\tremaining: 3.07s\n",
      "971:\ttotal: 1m 42s\tremaining: 2.96s\n",
      "972:\ttotal: 1m 43s\tremaining: 2.86s\n",
      "973:\ttotal: 1m 43s\tremaining: 2.75s\n",
      "974:\ttotal: 1m 43s\tremaining: 2.65s\n",
      "975:\ttotal: 1m 43s\tremaining: 2.54s\n",
      "976:\ttotal: 1m 43s\tremaining: 2.44s\n",
      "977:\ttotal: 1m 43s\tremaining: 2.33s\n",
      "978:\ttotal: 1m 43s\tremaining: 2.22s\n",
      "979:\ttotal: 1m 43s\tremaining: 2.12s\n",
      "980:\ttotal: 1m 43s\tremaining: 2.01s\n",
      "981:\ttotal: 1m 44s\tremaining: 1.91s\n",
      "982:\ttotal: 1m 44s\tremaining: 1.8s\n",
      "983:\ttotal: 1m 44s\tremaining: 1.7s\n",
      "984:\ttotal: 1m 44s\tremaining: 1.59s\n",
      "985:\ttotal: 1m 44s\tremaining: 1.48s\n",
      "986:\ttotal: 1m 44s\tremaining: 1.38s\n",
      "987:\ttotal: 1m 44s\tremaining: 1.27s\n",
      "988:\ttotal: 1m 44s\tremaining: 1.17s\n",
      "989:\ttotal: 1m 44s\tremaining: 1.06s\n",
      "990:\ttotal: 1m 45s\tremaining: 954ms\n",
      "991:\ttotal: 1m 45s\tremaining: 848ms\n",
      "992:\ttotal: 1m 45s\tremaining: 742ms\n",
      "993:\ttotal: 1m 45s\tremaining: 636ms\n",
      "994:\ttotal: 1m 45s\tremaining: 530ms\n",
      "995:\ttotal: 1m 45s\tremaining: 424ms\n",
      "996:\ttotal: 1m 45s\tremaining: 318ms\n",
      "997:\ttotal: 1m 45s\tremaining: 212ms\n",
      "998:\ttotal: 1m 45s\tremaining: 106ms\n",
      "999:\ttotal: 1m 46s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.rerank.TwoStageModel at 0x7f8aa0e3d730>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_stage.fit(dataset, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = two_stage.recommend(\n",
    "                    users=dataset.user_id_map.external_ids, \n",
    "                    dataset=dataset,\n",
    "                    k=10,\n",
    "                    filter_viewed=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11088450</th>\n",
       "      <td>1097557</td>\n",
       "      <td>10440</td>\n",
       "      <td>2.058919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088451</th>\n",
       "      <td>1097557</td>\n",
       "      <td>9728</td>\n",
       "      <td>1.749182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088452</th>\n",
       "      <td>1097557</td>\n",
       "      <td>13865</td>\n",
       "      <td>1.673442</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088453</th>\n",
       "      <td>1097557</td>\n",
       "      <td>3734</td>\n",
       "      <td>1.146710</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088479</th>\n",
       "      <td>1097557</td>\n",
       "      <td>16228</td>\n",
       "      <td>0.888368</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15169</th>\n",
       "      <td>0</td>\n",
       "      <td>4495</td>\n",
       "      <td>0.546036</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15159</th>\n",
       "      <td>0</td>\n",
       "      <td>9996</td>\n",
       "      <td>0.499036</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15160</th>\n",
       "      <td>0</td>\n",
       "      <td>7571</td>\n",
       "      <td>0.480380</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>0</td>\n",
       "      <td>7829</td>\n",
       "      <td>0.475391</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>0</td>\n",
       "      <td>7793</td>\n",
       "      <td>0.419560</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442880 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id     score  rank\n",
       "11088450  1097557    10440  2.058919     1\n",
       "11088451  1097557     9728  1.749182     2\n",
       "11088452  1097557    13865  1.673442     3\n",
       "11088453  1097557     3734  1.146710     4\n",
       "11088479  1097557    16228  0.888368     5\n",
       "...           ...      ...       ...   ...\n",
       "15169           0     4495  0.546036     6\n",
       "15159           0     9996  0.499036     7\n",
       "15160           0     7571  0.480380     8\n",
       "15168           0     7829  0.475391     9\n",
       "15170           0     7793  0.419560    10\n",
       "\n",
       "[7442880 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CrossValidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMClassifier guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier **cannot work with missing values**, so we must pre-process the data: \n",
    "1. Get rid of gaps in the data we want to work with (in the tutorial we want to use the feature description of users). \n",
    "2. Do not allow missing values to appear in the training sample for the second-stage model, obtained by adding the feature description. Therefore, to train the first-stage model, we will use user interactions with an available feature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "\n",
    "DATA_PATH = Path(\"data_original\")\n",
    "users = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "items = pd.read_csv(DATA_PATH / 'items.csv')\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": Columns.Datetime})\n",
    ")\n",
    "interactions[\"weight\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your any helper functions for working with loaded data\n",
    "def encode_and_clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_encode = encode_cat_cols(df)    \n",
    "    cols_with_nan = df_encode.columns[df_encode.isna().any()].tolist()\n",
    "    df_encode[cols_with_nan] = df_encode[cols_with_nan].fillna(df_encode[cols_with_nan].median())\n",
    "    return df_encode\n",
    "\n",
    "def encode_cat_cols(df: pd.DataFrame) -> pd.DataFrame:    \n",
    "    df_cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[df_cat_cols] = df[df_cat_cols].astype('category')\n",
    "    \n",
    "    for col in df_cat_cols:\n",
    "        cat_col = df[col].astype('category').cat\n",
    "        df[col] = cat_col.codes.astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding categorical data and handling missing values\n",
    "users = encode_and_clean_data(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962179, 840197)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check if all users who have interactions have a feature description (users)\n",
    "interactions[Columns.User].nunique(), users[Columns.User].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we leave only interactions where users have a characteristic description\n",
    "user_ids_with_feature = np.intersect1d(interactions[Columns.User].unique(), users[Columns.User].unique())\n",
    "interactions = interactions.query(f\"{Columns.User} in @user_ids_with_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.construct(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare first stage models\n",
    "first_stage = [\n",
    "    CandidateGenerator(\n",
    "        model=PopularModel(),\n",
    "        num_candidates=30,\n",
    "        keep_ranks=True,\n",
    "        keep_scores=True,\n",
    "        scores_fillna_value=1.01, # when working with the LGBMClassifier, you need to fill in the empty scores (e.g. max score)\n",
    "        ranks_fillna_value=31  # when working with the LGBMClassifier, you need to fill in the empty ranks (e.g. min rank)\n",
    "    ), \n",
    "    CandidateGenerator(\n",
    "        model=ImplicitItemKNNWrapperModel(CosineRecommender()),\n",
    "        num_candidates=30,\n",
    "        keep_ranks=True,\n",
    "        keep_scores=True,\n",
    "        scores_fillna_value=1,  # when working with the LGBMClassifier, you need to fill in the empty scores\n",
    "        ranks_fillna_value=31   # when working with the LGBMClassifier, you need to fill in the empty ranks\n",
    "    )\n",
    "]\n",
    "\n",
    "# Prepare splitter for selecting reranker train. Only one fold is expected!\n",
    "splitter = TimeRangeSplitter(\"7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write custome feature collecting funcs for users, items and user/item pairs\n",
    "class CustomFeatureCollectorLGBM(CandidatesFeatureCollectorBase):\n",
    "    def _get_user_features(\n",
    "        self, users: AnyIds, dataset: Dataset, fold_info: tp.Optional[tp.Dict[str, tp.Any]], external_ids: bool\n",
    "    ) -> pd.DataFrame:\n",
    "        user_features = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "        user_features = encode_and_clean_data(user_features) # make sure descriptive description does not have empty values \n",
    "        \n",
    "        return user_features[user_features[Columns.User].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all users who have interactions\n",
    "users = dataset.user_id_map.external_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we specify our custom feature collector for TwoStageModel\n",
    "\n",
    "two_stage = TwoStageModel(first_stage,\n",
    "                          splitter,\n",
    "                          RerankerBase(LGBMClassifier()),\n",
    "                          feature_collector=CustomFeatureCollectorLGBM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = two_stage.get_train_with_targets_for_reranker(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>PopularModel_1_score</th>\n",
       "      <th>PopularModel_1_rank</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_score</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_rank</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>689820</td>\n",
       "      <td>13865</td>\n",
       "      <td>92354.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.209987</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1089243</td>\n",
       "      <td>4436</td>\n",
       "      <td>15115.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423967</td>\n",
       "      <td>4151</td>\n",
       "      <td>62343.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.632890</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>613250</td>\n",
       "      <td>7571</td>\n",
       "      <td>21718.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307964</td>\n",
       "      <td>4471</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.166363</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88022</td>\n",
       "      <td>13865</td>\n",
       "      <td>92354.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>544358</td>\n",
       "      <td>8387</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.065108</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>944197</td>\n",
       "      <td>7571</td>\n",
       "      <td>21718.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.245627</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39366</td>\n",
       "      <td>9054</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.242150</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>166229</td>\n",
       "      <td>11312</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.060993</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>76543</td>\n",
       "      <td>4436</td>\n",
       "      <td>15115.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>267658</td>\n",
       "      <td>2657</td>\n",
       "      <td>40010.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>793748</td>\n",
       "      <td>12192</td>\n",
       "      <td>24217.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.458715</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>664392</td>\n",
       "      <td>3734</td>\n",
       "      <td>56265.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.094645</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>612312</td>\n",
       "      <td>8891</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.209761</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>835151</td>\n",
       "      <td>11237</td>\n",
       "      <td>22232.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>554196</td>\n",
       "      <td>4457</td>\n",
       "      <td>17938.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>697970</td>\n",
       "      <td>7102</td>\n",
       "      <td>14827.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>749604</td>\n",
       "      <td>8821</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.558087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>729671</td>\n",
       "      <td>11863</td>\n",
       "      <td>13623.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  PopularModel_1_score  PopularModel_1_rank  \\\n",
       "0    689820    13865              92354.00                  4.0   \n",
       "1   1089243     4436              15115.00                 21.0   \n",
       "2    423967     4151              62343.00                  3.0   \n",
       "3    613250     7571              21718.00                 16.0   \n",
       "4    307964     4471                  1.01                 31.0   \n",
       "5     88022    13865              92354.00                  4.0   \n",
       "6    544358     8387                  1.01                 31.0   \n",
       "7    944197     7571              21718.00                 16.0   \n",
       "8     39366     9054                  1.01                 31.0   \n",
       "9    166229    11312                  1.01                 31.0   \n",
       "10    76543     4436              15115.00                 19.0   \n",
       "11   267658     2657              40010.00                  7.0   \n",
       "12   793748    12192              24217.00                 12.0   \n",
       "13   664392     3734              56265.00                  6.0   \n",
       "14   612312     8891                  1.01                 31.0   \n",
       "15   835151    11237              22232.00                 14.0   \n",
       "16   554196     4457              17938.00                 19.0   \n",
       "17   697970     7102              14827.00                 23.0   \n",
       "18   749604     8821                  1.01                 31.0   \n",
       "19   729671    11863              13623.00                 26.0   \n",
       "\n",
       "    ImplicitItemKNNWrapperModel_1_score  ImplicitItemKNNWrapperModel_1_rank  \\\n",
       "0                              0.209987                                 5.0   \n",
       "1                              1.000000                                31.0   \n",
       "2                              0.632890                                 2.0   \n",
       "3                              1.000000                                31.0   \n",
       "4                              0.166363                                20.0   \n",
       "5                              1.000000                                31.0   \n",
       "6                              0.065108                                10.0   \n",
       "7                              0.245627                                21.0   \n",
       "8                              0.242150                                25.0   \n",
       "9                              0.060993                                10.0   \n",
       "10                             1.000000                                31.0   \n",
       "11                             1.000000                                31.0   \n",
       "12                             0.458715                                16.0   \n",
       "13                             0.094645                                 6.0   \n",
       "14                             0.209761                                21.0   \n",
       "15                             1.000000                                31.0   \n",
       "16                             1.000000                                31.0   \n",
       "17                             1.000000                                31.0   \n",
       "18                             0.558087                                 1.0   \n",
       "19                             1.000000                                31.0   \n",
       "\n",
       "    target age income sex  kids_flg  \n",
       "0        0   1      4   1         1  \n",
       "1        0   0      2   0         1  \n",
       "2        1   0      2   0         0  \n",
       "3        1   2      2   0         1  \n",
       "4        1   3      3   0         0  \n",
       "5        1   0      2   1         0  \n",
       "6        0   2      3   0         0  \n",
       "7        0   0      2   1         0  \n",
       "8        0   2      4   1         1  \n",
       "9        0   2      4   1         0  \n",
       "10       0   2      3   1         1  \n",
       "11       0   1      2   1         0  \n",
       "12       0   2      3   0         1  \n",
       "13       1  -1     -1  -1         0  \n",
       "14       1   2      2   1         0  \n",
       "15       1   0      2   1         0  \n",
       "16       0   3      2   0         0  \n",
       "17       1   1      3   0         0  \n",
       "18       0   3      3   0         1  \n",
       "19       0   2      4   0         0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now our candidates also have features for users (no empty values)\n",
    "# LGBMClassifier cannot work with empty values\n",
    "candidates.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['age', 'income', 'sex']\n",
    "\n",
    "# example parameters for running model training \n",
    "# more valid parameters here https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier.fit\n",
    "fit_params = {\n",
    "    'categorical_feature': cat_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 62765, number of negative: 269784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 398\n",
      "[LightGBM] [Info] Number of data points in the train set: 332549, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.188739 -> initscore=-1.458224\n",
      "[LightGBM] [Info] Start training from score -1.458224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.rerank.TwoStageModel at 0x7f89335d5730>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_stage.fit(dataset, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = two_stage.recommend(\n",
    "                    users=users, \n",
    "                    dataset=dataset,\n",
    "                    k=10,\n",
    "                    filter_viewed=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11088450</th>\n",
       "      <td>1097557</td>\n",
       "      <td>10440</td>\n",
       "      <td>0.568291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088451</th>\n",
       "      <td>1097557</td>\n",
       "      <td>9728</td>\n",
       "      <td>0.487937</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088452</th>\n",
       "      <td>1097557</td>\n",
       "      <td>13865</td>\n",
       "      <td>0.484011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088453</th>\n",
       "      <td>1097557</td>\n",
       "      <td>3734</td>\n",
       "      <td>0.361763</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088454</th>\n",
       "      <td>1097557</td>\n",
       "      <td>4880</td>\n",
       "      <td>0.292965</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088479</th>\n",
       "      <td>1097557</td>\n",
       "      <td>16228</td>\n",
       "      <td>0.288336</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088456</th>\n",
       "      <td>1097557</td>\n",
       "      <td>142</td>\n",
       "      <td>0.251141</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088459</th>\n",
       "      <td>1097557</td>\n",
       "      <td>12192</td>\n",
       "      <td>0.220386</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28315820</th>\n",
       "      <td>1097557</td>\n",
       "      <td>5658</td>\n",
       "      <td>0.213797</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088461</th>\n",
       "      <td>1097557</td>\n",
       "      <td>7571</td>\n",
       "      <td>0.212762</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id     score  rank\n",
       "11088450  1097557    10440  0.568291     1\n",
       "11088451  1097557     9728  0.487937     2\n",
       "11088452  1097557    13865  0.484011     3\n",
       "11088453  1097557     3734  0.361763     4\n",
       "11088454  1097557     4880  0.292965     5\n",
       "11088479  1097557    16228  0.288336     6\n",
       "11088456  1097557      142  0.251141     7\n",
       "11088459  1097557    12192  0.220386     8\n",
       "28315820  1097557     5658  0.213797     9\n",
       "11088461  1097557     7571  0.212762    10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CrossValidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMRanker guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we specify our custom feature collector for TwoStageModel\n",
    "\n",
    "two_stage = TwoStageModel(first_stage,\n",
    "                          splitter,\n",
    "                          RerankerBase(LGBMRanker()),\n",
    "                          feature_collector=CustomFeatureCollectorLGBM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = two_stage.get_train_with_targets_for_reranker(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>PopularModel_1_score</th>\n",
       "      <th>PopularModel_1_rank</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_score</th>\n",
       "      <th>ImplicitItemKNNWrapperModel_1_rank</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306574</td>\n",
       "      <td>12324</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.311469</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>773247</td>\n",
       "      <td>10440</td>\n",
       "      <td>125533.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.318116</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288928</td>\n",
       "      <td>7784</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94181</td>\n",
       "      <td>11985</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.156980</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>427974</td>\n",
       "      <td>6774</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.301239</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1069352</td>\n",
       "      <td>4495</td>\n",
       "      <td>15845.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.433809</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>950223</td>\n",
       "      <td>4436</td>\n",
       "      <td>15115.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>802889</td>\n",
       "      <td>4436</td>\n",
       "      <td>15115.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.164605</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>925367</td>\n",
       "      <td>16509</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.172052</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>495023</td>\n",
       "      <td>15297</td>\n",
       "      <td>118602.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.398827</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>615815</td>\n",
       "      <td>3587</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.438813</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>714390</td>\n",
       "      <td>7829</td>\n",
       "      <td>15455.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>156995</td>\n",
       "      <td>9996</td>\n",
       "      <td>26372.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.251975</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>215142</td>\n",
       "      <td>3734</td>\n",
       "      <td>56265.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.487233</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>762691</td>\n",
       "      <td>5250</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.075237</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>425084</td>\n",
       "      <td>13463</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.294317</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>800308</td>\n",
       "      <td>9214</td>\n",
       "      <td>1.01</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.068488</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>399865</td>\n",
       "      <td>10440</td>\n",
       "      <td>125533.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.295255</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47113</td>\n",
       "      <td>7829</td>\n",
       "      <td>15455.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.338799</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>793614</td>\n",
       "      <td>1844</td>\n",
       "      <td>20398.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  PopularModel_1_score  PopularModel_1_rank  \\\n",
       "0    306574    12324                  1.01                 31.0   \n",
       "1    773247    10440             125533.00                  1.0   \n",
       "2    288928     7784                  1.01                 31.0   \n",
       "3     94181    11985                  1.01                 31.0   \n",
       "4    427974     6774                  1.01                 31.0   \n",
       "5   1069352     4495              15845.00                 20.0   \n",
       "6    950223     4436              15115.00                 21.0   \n",
       "7    802889     4436              15115.00                 22.0   \n",
       "8    925367    16509                  1.01                 31.0   \n",
       "9    495023    15297             118602.00                  2.0   \n",
       "10   615815     3587                  1.01                 31.0   \n",
       "11   714390     7829              15455.00                 22.0   \n",
       "12   156995     9996              26372.00                 11.0   \n",
       "13   215142     3734              56265.00                  5.0   \n",
       "14   762691     5250                  1.01                 31.0   \n",
       "15   425084    13463                  1.01                 31.0   \n",
       "16   800308     9214                  1.01                 31.0   \n",
       "17   399865    10440             125533.00                  1.0   \n",
       "18    47113     7829              15455.00                 16.0   \n",
       "19   793614     1844              20398.00                 10.0   \n",
       "\n",
       "    ImplicitItemKNNWrapperModel_1_score  ImplicitItemKNNWrapperModel_1_rank  \\\n",
       "0                              0.311469                                18.0   \n",
       "1                              0.318116                                 2.0   \n",
       "2                              0.055205                                22.0   \n",
       "3                              0.156980                                20.0   \n",
       "4                              0.301239                                15.0   \n",
       "5                              0.433809                                15.0   \n",
       "6                              1.000000                                31.0   \n",
       "7                              0.164605                                20.0   \n",
       "8                              0.172052                                22.0   \n",
       "9                              1.398827                                13.0   \n",
       "10                             2.438813                                 7.0   \n",
       "11                             1.000000                                31.0   \n",
       "12                             0.251975                                 4.0   \n",
       "13                             0.487233                                 9.0   \n",
       "14                             0.075237                                29.0   \n",
       "15                             0.294317                                22.0   \n",
       "16                             0.068488                                26.0   \n",
       "17                             0.295255                                 3.0   \n",
       "18                             0.338799                                15.0   \n",
       "19                             1.000000                                31.0   \n",
       "\n",
       "    target age income sex  kids_flg  \n",
       "0        0   1      2   0         0  \n",
       "1        1   3      2   0         0  \n",
       "2        0   4      2   0         0  \n",
       "3        0   2      2   0         0  \n",
       "4        0   2      2   1         1  \n",
       "5        0   3      2   1         1  \n",
       "6        0   1      2   0         0  \n",
       "7        0   0      4   0         0  \n",
       "8        0   4      2   0         0  \n",
       "9        1   2      2   0         0  \n",
       "10       1   1      2   0         0  \n",
       "11       0   2      2   0         1  \n",
       "12       0   2      2   1         0  \n",
       "13       1   3      3   1         0  \n",
       "14       1   1      3   0         0  \n",
       "15       0   1      2   0         1  \n",
       "16       0   3      2   1         1  \n",
       "17       1   1      3   1         1  \n",
       "18       0   1      4   1         1  \n",
       "19       0   5      2   0         0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now our candidates also have features for users (no empty values)\n",
    "# LGBMRanker cannot work with empty values\n",
    "candidates.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn ranking, you need to correctly compose groups. And I will pass them inside `fit_params`\n",
    "\n",
    "Documentation on how to form groups for ranker (read about `group`):\n",
    "https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html#lightgbm.LGBMRanker.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(df: pd.DataFrame) -> np.ndarray:\n",
    "    return np.array(\n",
    "        df[['user_id', 'item_id']]\n",
    "        .groupby(by=['user_id']).count()\n",
    "        ['item_id']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['age', 'income', 'sex']\n",
    "groups = get_group(candidates)\n",
    "\n",
    "# example parameters for running model training \n",
    "# more valid parameters here\n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html#lightgbm.LGBMRanker.fit\n",
    "fit_params = {\n",
    "    'categorical_feature': cat_cols,\n",
    "    'group': groups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 397\n",
      "[LightGBM] [Info] Number of data points in the train set: 332549, number of used features: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.rerank.TwoStageModel at 0x7f88e12d3640>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_stage.fit(dataset, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = two_stage.recommend(\n",
    "                    users=users, \n",
    "                    dataset=dataset,\n",
    "                    k=10,\n",
    "                    filter_viewed=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11088450</th>\n",
       "      <td>1097557</td>\n",
       "      <td>10440</td>\n",
       "      <td>1.737577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088452</th>\n",
       "      <td>1097557</td>\n",
       "      <td>13865</td>\n",
       "      <td>1.396927</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088451</th>\n",
       "      <td>1097557</td>\n",
       "      <td>9728</td>\n",
       "      <td>1.315158</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088453</th>\n",
       "      <td>1097557</td>\n",
       "      <td>3734</td>\n",
       "      <td>0.830932</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088454</th>\n",
       "      <td>1097557</td>\n",
       "      <td>4880</td>\n",
       "      <td>0.232542</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15156</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>-0.042750</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15176</th>\n",
       "      <td>0</td>\n",
       "      <td>12173</td>\n",
       "      <td>-0.096649</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22337349</th>\n",
       "      <td>0</td>\n",
       "      <td>12324</td>\n",
       "      <td>-0.150246</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22337350</th>\n",
       "      <td>0</td>\n",
       "      <td>5658</td>\n",
       "      <td>-0.274890</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>0</td>\n",
       "      <td>4880</td>\n",
       "      <td>-0.292354</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442880 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  item_id     score  rank\n",
       "11088450  1097557    10440  1.737577     1\n",
       "11088452  1097557    13865  1.396927     2\n",
       "11088451  1097557     9728  1.315158     3\n",
       "11088453  1097557     3734  0.830932     4\n",
       "11088454  1097557     4880  0.232542     5\n",
       "...           ...      ...       ...   ...\n",
       "15156           0      142 -0.042750     6\n",
       "15176           0    12173 -0.096649     7\n",
       "22337349        0    12324 -0.150246     8\n",
       "22337350        0     5658 -0.274890     9\n",
       "15154           0     4880 -0.292354    10\n",
       "\n",
       "[7442880 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CrossValidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "two_stage",
   "language": "python",
   "name": "two_stage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
