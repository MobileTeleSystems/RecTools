{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rectools import Columns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from rectools.models.sasrec import save_pickle \n",
    "\n",
    "from rectools.models.sasrec import (\n",
    "    SASRecConfig,\n",
    "    SASRecProcessorConfig,\n",
    "    TrainPreprocessingConfig,\n",
    "    TrainConfig,\n",
    "    ItemModelConfig,\n",
    "    SequenceTaskConverterConfig,\n",
    "    train_sasrec_script,\n",
    "    SASRecRecommeder\n",
    ")\n",
    "\n",
    "from rectools.metrics import MAP, calc_metrics, MeanInvUserFreq, Serendipity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_original.zip\n",
      "  inflating: data_original/interactions.csv  \n",
      "  inflating: __MACOSX/data_original/._interactions.csv  \n",
      "  inflating: data_original/users.csv  \n",
      "  inflating: __MACOSX/data_original/._users.csv  \n",
      "  inflating: data_original/items.csv  \n",
      "  inflating: __MACOSX/data_original/._items.csv  \n",
      "CPU times: user 1.12 s, sys: 573 ms, total: 1.69 s\n",
      "Wall time: 59.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_original\")\n",
    "\n",
    "user_features = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "item_features = pd.read_csv(DATA_PATH / 'items.csv')\n",
    "user_item_interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": \"first_intr_dt\", \"total_dur\": \"score\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features[\"user_id\"] = user_features[\"user_id\"].astype(str)\n",
    "item_features[\"item_id\"] = item_features[\"item_id\"].astype(str)\n",
    "user_item_interactions[\"user_id\"] = user_item_interactions[\"user_id\"].astype(str)\n",
    "user_item_interactions[\"item_id\"] = user_item_interactions[\"item_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_path = \"rectools/models/train_interactions_splitted_wtg.pkl\"\n",
    "test_ds_path=\"rectools/models/test_interactions_splitted_wtg.pkl\"\n",
    "\n",
    "user_item_interactions[Columns.Weight] = np.where(user_item_interactions['watched_pct'] > 10, 3, 1)\n",
    "\n",
    "# Split to train / test\n",
    "max_date = user_item_interactions[\"first_intr_dt\"].max()\n",
    "train_df = user_item_interactions[user_item_interactions[\"first_intr_dt\"] < max_date - pd.Timedelta(days=7)].copy()\n",
    "test_df = user_item_interactions[user_item_interactions[\"first_intr_dt\"] >= max_date - pd.Timedelta(days=7)].copy()\n",
    "train_df.drop(train_df.query(\"score < 300\").index, inplace=True)\n",
    "\n",
    "# drop items with less than 20 interactions in train\n",
    "items = train_df['item_id'].value_counts()\n",
    "items = items[items >= 20]\n",
    "items = items.index.to_list()\n",
    "train_df = train_df[train_df['item_id'].isin(items)]\n",
    "    \n",
    "# drop users with less than 2 interactions in train\n",
    "users = train_df['user_id'].value_counts()\n",
    "users = users[users >= 2]\n",
    "users = users.index.to_list()\n",
    "train_df = train_df[(train_df['user_id'].isin(users)) & (train_df['item_id'].isin(items))]\n",
    "\n",
    "# leave item features for items only from train\n",
    "items = train_df['item_id'].drop_duplicates().to_list()\n",
    "users = train_df['user_id'].drop_duplicates().to_list()\n",
    "item_features_train = item_features[item_features['item_id'].isin(items)]\n",
    "\n",
    "# drop cold users from test\n",
    "cold_users = set(test_df[Columns.User]) - set(train_df[Columns.User])\n",
    "test_df.drop(test_df[test_df[Columns.User].isin(cold_users)].index, inplace=True)\n",
    "test_users = test_df[Columns.User].unique()\n",
    "\n",
    "train_ds = (train_df, pd.DataFrame(), pd.DataFrame())\n",
    "test_ds = (test_df, pd.DataFrame(), pd.DataFrame())\n",
    "\n",
    "save_pickle(train_ds, train_ds_path)\n",
    "save_pickle(test_ds, test_ds_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_137214/1922638199.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  item_features_train[\"tags_set\"] = ''\n"
     ]
    }
   ],
   "source": [
    "savepath = \"rectools/models/kion_pers_recs_item_features_test.parquet\"\n",
    "item_features_train[\"tags_set\"] = ''\n",
    "item_features_train = item_features_train[['item_id', 'tags_set']].copy().drop_duplicates()\n",
    "os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "item_features_train.to_parquet(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"rectools/models/kion_pers_recs_item_features_test.parquet\"\n",
    "item_features[\"tags_set\"] = ''\n",
    "item_features = item_features[['item_id', 'tags_set']].copy().drop_duplicates()\n",
    "# os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "# item_features.to_parquet(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units=128\n",
    "session_maxlen=32\n",
    "\n",
    "\n",
    "item_model_config = ItemModelConfig(\n",
    "    name=\"idemb\",\n",
    "    hidden_units=hidden_units,\n",
    ")\n",
    "\n",
    "model_cfg = SASRecConfig(\n",
    "    maxlen=session_maxlen,\n",
    "    hidden_units=hidden_units,  # 50\n",
    "    num_blocks=2,\n",
    "    num_heads=1,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    use_sm_head=True,\n",
    "    item_model=item_model_config,\n",
    ")\n",
    "\n",
    "# TODO reused in train config\n",
    "processor_config = SASRecProcessorConfig(\n",
    "    session_maxlen=session_maxlen,\n",
    "    enable_item_features=False,  # True,\n",
    "    # item_tags_maxlen=64,\n",
    ")\n",
    "\n",
    "train_preprocessing_config = TrainPreprocessingConfig(\n",
    "    min_item_freq=20,  # 1\n",
    "    min_user_freq=2,  # 2 is minimal to generate target\n",
    "    # keep_tags_types=[\"genres_\"],\n",
    "    keep_tags_types=[],\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    l2_emb=0.0,\n",
    "    device=\"cuda:1\",\n",
    "    # device=\"cpu\",\n",
    "    negative_samples=0,\n",
    "    loss=\"sm_ce\",\n",
    "    processor_config=processor_config,\n",
    ")\n",
    "\n",
    "task_converter_config = SequenceTaskConverterConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rectools.models.sasrec:loading datasets\n",
      "INFO:rectools.models.sasrec:running training script\n",
      "INFO:rectools.models.sasrec:testing dataset\n",
      "INFO:rectools.models.sasrec:converting datasets to task format\n",
      "INFO:rectools.models.sasrec:sessions lens: 0.95q: 24.0; 0.5q: 4.0\n",
      "INFO:rectools.models.sasrec:building preprocessor\n",
      "INFO:rectools.models.sasrec:building train dataset\n",
      "INFO:rectools.models.sasrec:building model\n",
      "INFO:rectools.models.sasrec:building trainer\n",
      "INFO:rectools.models.sasrec:used sm_ce loss\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.0.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.0.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.1.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.1.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.0.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.0.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.1.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.1.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param last_layernorm.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param last_layernorm.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:training epoch 1\n",
      "INFO:rectools.models.sasrec:training epoch 2\n",
      "INFO:rectools.models.sasrec:training epoch 3\n",
      "INFO:rectools.models.sasrec:training epoch 4\n",
      "INFO:rectools.models.sasrec:training epoch 5\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"rectools/models/sasrec_test_model\"\n",
    "\n",
    "train_sasrec_script(\n",
    "    train_ds_path=\"rectools/models/train_interactions_splitted_wtg.pkl\",\n",
    "    item_features_path=\"rectools/models/kion_pers_recs_item_features_test.parquet\",\n",
    "    model_dir=model_dir,\n",
    "    processor_config=processor_config,\n",
    "    model_config=model_cfg,\n",
    "    train_config=train_config,\n",
    "    train_preprocessing_config=train_preprocessing_config,\n",
    "    task_converter_config=task_converter_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = {\n",
    "    'MAP': MAP,\n",
    "    'MIUF': MeanInvUserFreq,\n",
    "    'Serendipity': Serendipity\n",
    "    \n",
    "\n",
    "}\n",
    "metrics = {}\n",
    "for metric_name, metric in metrics_name.items():\n",
    "    for k in (1, 5, 10):\n",
    "        metrics[f'{metric_name}@{k}'] = metric(k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = train_df[train_df['user_id'].isin(np.unique(test_df['user_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rectools.models.sasrec:filtered out 10310 candidate items which are not supported by model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rectools.models.sasrec:sessions lens: 0.95q: 41.0; 0.5q: 7.0\n",
      "100%|██████████| 740/740 [00:10<00:00, 71.10it/s]\n",
      "100%|██████████| 94705/94705 [00:03<00:00, 25686.73it/s]\n"
     ]
    }
   ],
   "source": [
    "recommender = SASRecRecommeder.load(model_dir)\n",
    "x = rec_df\n",
    "y = test_df\n",
    "candidate_items = item_features['item_id']\n",
    "\n",
    "pred_top_k = 10\n",
    "recs = recommender.recommend(\n",
    "    user_item_interactions=x, \n",
    "    user_features=user_features, \n",
    "    item_features=item_features,\n",
    "    top_k=pred_top_k, \n",
    "    candidate_items=candidate_items, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:computing metrics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP@1': 0.03996276581801799,\n",
       " 'MAP@5': 0.06481679718888116,\n",
       " 'MAP@10': 0.07257142857770682,\n",
       " 'MIUF@1': 3.3982965266764427,\n",
       " 'MIUF@5': 4.820015979809291,\n",
       " 'MIUF@10': 5.19301814529131,\n",
       " 'Serendipity@1': 0.0003231127097184948,\n",
       " 'Serendipity@5': 0.0002893187185587979,\n",
       " 'Serendipity@10': 0.0002688154142529778}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"computing metrics\")\n",
    "catalog=train_df[Columns.Item].unique().astype(str)\n",
    "calc_metrics(metrics, recs, test_df, train_df, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
