{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-27T14:29:22.494979Z",
     "iopub.status.busy": "2024-06-27T14:29:22.494423Z",
     "iopub.status.idle": "2024-06-27T14:29:22.812073Z",
     "shell.execute_reply": "2024-06-27T14:29:22.811404Z",
     "shell.execute_reply.started": "2024-06-27T14:29:22.494879Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rectools import Columns\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from rectools.models import ImplicitALSWrapperModel\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from rectools.models.sasrec import SasRecRecommenderModel\n",
    "\n",
    "from rectools.metrics import MAP, calc_metrics, MeanInvUserFreq, Serendipity\n",
    "from rectools.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_original.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of data_original.zip or\n",
      "        data_original.zip.zip, and cannot find data_original.zip.ZIP, period.\n",
      "CPU times: user 8.75 ms, sys: 369 ms, total: 377 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_original\")\n",
    "\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": \"datetime\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "\n",
    "# Split to train / test\n",
    "max_date = interactions[Columns.Datetime].max()\n",
    "train = interactions[interactions[Columns.Datetime] < max_date - pd.Timedelta(days=7)].copy()\n",
    "test = interactions[interactions[Columns.Datetime] >= max_date - pd.Timedelta(days=7)].copy()\n",
    "train.drop(train.query(\"total_dur < 300\").index, inplace=True)\n",
    "\n",
    "# drop items with less than 20 interactions in train\n",
    "items = train[\"item_id\"].value_counts()\n",
    "items = items[items >= 20]\n",
    "items = items.index.to_list()\n",
    "train = train[train[\"item_id\"].isin(items)]\n",
    "    \n",
    "# drop users with less than 2 interactions in train\n",
    "users = train[\"user_id\"].value_counts()\n",
    "users = users[users >= 2]\n",
    "users = users.index.to_list()\n",
    "train = train[(train[\"user_id\"].isin(users))]\n",
    "\n",
    "# leave item features for items only from train\n",
    "# items = train[\"item_id\"].drop_duplicates().to_list()\n",
    "users = train[\"user_id\"].drop_duplicates().to_list()\n",
    "\n",
    "# drop cold users from test\n",
    "test_users = test[Columns.User].unique()\n",
    "cold_users = set(test[Columns.User]) - set(train[Columns.User])\n",
    "test.drop(test[test[Columns.User].isin(cold_users)].index, inplace=True)\n",
    "\n",
    "catalog=train[Columns.Item].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.construct(\n",
    "    interactions_df=train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sasrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 32\n"
     ]
    }
   ],
   "source": [
    "factors=128\n",
    "session_maxlen=32\n",
    "model = SasRecRecommenderModel(\n",
    "    random_state=32,\n",
    "    factors=factors,  # 50\n",
    "    n_blocks=2,\n",
    "    n_heads=1,\n",
    "    dropout_rate=0.2,\n",
    "    item_net_dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    session_maxlen=session_maxlen,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    device=\"cuda:1\",\n",
    "    loss=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rectools.models.sasrec:building model\n",
      "INFO:rectools.models.sasrec:building trainer\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layers.0.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layers.0.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layers.1.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.attention_layers.1.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layers.0.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layers.0.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layers.1.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param encoder.forward_layers.1.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param last_layernorm.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:unable to init param last_layernorm.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:training epoch 1\n",
      "INFO:rectools.models.sasrec:training epoch 2\n",
      "INFO:rectools.models.sasrec:training epoch 3\n",
      "INFO:rectools.models.sasrec:training epoch 4\n",
      "INFO:rectools.models.sasrec:training epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 12s, sys: 3.65 s, total: 5min 15s\n",
      "Wall time: 5min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rectools.models.sasrec.SasRecRecommenderModel at 0x7f58340f6400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maspirina1/Tasks/RecTools/rectools/models/sasrec.py:146: UserWarning: 91202 users were filtered out as cold users\n",
      "  warnings.warn(f\"{n_cold} users were filtered out as cold users\")\n",
      "100%|██████████| 740/740 [00:02<00:00, 301.83it/s]\n",
      "OpenBLAS warning: precompiled NUM_THREADS exceeded, adding auxiliary array for thread metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 12min 59s, total: 15min 34s\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recs = model.recommend(\n",
    "    users = test_users, \n",
    "    dataset = dataset,\n",
    "    k = 10,\n",
    "    filter_viewed = True,\n",
    "    assume_external_ids = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7793</td>\n",
       "      <td>3.059519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15297</td>\n",
       "      <td>2.744265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3784</td>\n",
       "      <td>2.680801</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7829</td>\n",
       "      <td>2.679824</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>14899</td>\n",
       "      <td>2.337226</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947045</th>\n",
       "      <td>1097544</td>\n",
       "      <td>11118</td>\n",
       "      <td>2.289302</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947046</th>\n",
       "      <td>1097544</td>\n",
       "      <td>6162</td>\n",
       "      <td>2.216834</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947047</th>\n",
       "      <td>1097544</td>\n",
       "      <td>10440</td>\n",
       "      <td>2.208683</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947048</th>\n",
       "      <td>1097544</td>\n",
       "      <td>5434</td>\n",
       "      <td>2.208431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947049</th>\n",
       "      <td>1097544</td>\n",
       "      <td>7597</td>\n",
       "      <td>2.118901</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947050 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id item_id     score  rank\n",
       "0             3    7793  3.059519     1\n",
       "1             3   15297  2.744265     2\n",
       "2             3    3784  2.680801     3\n",
       "3             3    7829  2.679824     4\n",
       "4             3   14899  2.337226     5\n",
       "...         ...     ...       ...   ...\n",
       "947045  1097544   11118  2.289302     6\n",
       "947046  1097544    6162  2.216834     7\n",
       "947047  1097544   10440  2.208683     8\n",
       "947048  1097544    5434  2.208431     9\n",
       "947049  1097544    7597  2.118901    10\n",
       "\n",
       "[947050 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = {\n",
    "    'MAP': MAP,\n",
    "    'MIUF': MeanInvUserFreq,\n",
    "    'Serendipity': Serendipity\n",
    "    \n",
    "\n",
    "}\n",
    "metrics = {}\n",
    "for metric_name, metric in metrics_name.items():\n",
    "    for k in (1, 5, 10):\n",
    "        metrics[f'{metric_name}@{k}'] = metric(k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs[\"item_id\"] = recs[\"item_id\"].apply(str)\n",
    "test[\"item_id\"] = test[\"item_id\"].astype(str)\n",
    "features_results = []\n",
    "metric_values = calc_metrics(metrics, recs[[\"user_id\", \"item_id\", \"rank\"]], test, train, catalog)\n",
    "metric_values[\"model\"] = \"sasrec\"\n",
    "features_results.append(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MAP@1': 0.047579110560324996,\n",
       "  'MAP@5': 0.081092572796464,\n",
       "  'MAP@10': 0.09032230539383843,\n",
       "  'MIUF@1': 18.824620072061013,\n",
       "  'MIUF@5': 18.824620072061013,\n",
       "  'MIUF@10': 18.824620072061013,\n",
       "  'Serendipity@1': 0.09816799535399398,\n",
       "  'Serendipity@5': 0.059982713365428986,\n",
       "  'Serendipity@10': 0.044268025003728055,\n",
       "  'model': 'sasrec'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "items = pd.read_csv(DATA_PATH / 'items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process user features to the form of a flatten dataframe\n",
    "users.fillna('Unknown', inplace=True)\n",
    "users = users.loc[users[Columns.User].isin(train[Columns.User])].copy()\n",
    "user_features_frames = []\n",
    "for feature in [\"sex\", \"age\", \"income\"]:\n",
    "    feature_frame = users.reindex(columns=[Columns.User, feature])\n",
    "    feature_frame.columns = [\"id\", \"value\"]\n",
    "    feature_frame[\"feature\"] = feature\n",
    "    user_features_frames.append(feature_frame)\n",
    "user_features = pd.concat(user_features_frames)\n",
    "\n",
    "# Process item features to the form of a flatten dataframe\n",
    "items = items.loc[items[Columns.Item].isin(train[Columns.Item])].copy()\n",
    "items[\"genre\"] = items[\"genres\"].str.lower().str.replace(\", \", \",\", regex=False).str.split(\",\")\n",
    "genre_feature = items[[\"item_id\", \"genre\"]].explode(\"genre\")\n",
    "genre_feature.columns = [\"id\", \"value\"]\n",
    "genre_feature[\"feature\"] = \"genre\"\n",
    "content_feature = items.reindex(columns=[Columns.Item, \"content_type\"])\n",
    "content_feature.columns = [\"id\", \"value\"]\n",
    "content_feature[\"feature\"] = \"content_type\"\n",
    "item_features = pd.concat((genre_feature, content_feature))\n",
    "\n",
    "candidate_items = interactions['item_id'].drop_duplicates().astype(int)\n",
    "test[\"user_id\"] = test[\"user_id\"].astype(int)\n",
    "test[\"item_id\"] = test[\"item_id\"].astype(int)\n",
    "catalog=train[Columns.Item].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_no_features = Dataset.construct(\n",
    "    interactions_df=train,\n",
    ")\n",
    "\n",
    "dataset_full_features = Dataset.construct(\n",
    "    interactions_df=train,\n",
    "    user_features_df=user_features,\n",
    "    cat_user_features=[\"sex\", \"age\", \"income\"],\n",
    "    item_features_df=item_features,\n",
    "    cat_item_features=[\"genre\", \"content_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RECOS = 10\n",
    "NUM_THREADS = 32\n",
    "RANDOM_STATE = 32\n",
    "ITERATIONS = 10\n",
    "\n",
    "def make_base_model(factors: int, regularization: float, alpha: float, fit_features_together: bool=False):\n",
    "    return ImplicitALSWrapperModel(\n",
    "        AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            regularization=regularization,\n",
    "            alpha=alpha,\n",
    "            random_state=RANDOM_STATE,\n",
    "            use_gpu=False,\n",
    "            num_threads = NUM_THREADS,\n",
    "            iterations=ITERATIONS),\n",
    "        fit_features_together = fit_features_together,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maspirina1/Tasks/RecTools/.venv/lib/python3.8/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 64 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 128\n",
    "regularization = 0.5\n",
    "alpha = 10\n",
    "\n",
    "model = make_base_model(factors=n_factors, regularization=regularization, alpha=alpha)\n",
    "model.fit(dataset_no_features)\n",
    "recos = model.recommend(\n",
    "    users=test_users.astype(int),\n",
    "    dataset=dataset_no_features,\n",
    "    k=K_RECOS,\n",
    "    filter_viewed=True,\n",
    ")\n",
    "metric_values = calc_metrics(metrics, recos, test, train, catalog)\n",
    "metric_values[\"model\"] = \"no_features_factors_128_alpha_10_reg_0.5\"\n",
    "features_results.append(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maspirina1/Tasks/RecTools/rectools/dataset/features.py:424: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    }
   ],
   "source": [
    "model = make_base_model(factors = n_factors, regularization=regularization, alpha=alpha, fit_features_together=True)\n",
    "model.fit(dataset_full_features)\n",
    "recos = model.recommend(\n",
    "    users=test_users.astype(int),\n",
    "    dataset=dataset_full_features,\n",
    "    k=K_RECOS,\n",
    "    filter_viewed=True,\n",
    ")\n",
    "metric_values = calc_metrics(metrics, recos, test, train, catalog)\n",
    "metric_values[\"model\"] = \"full_features_factors_128_fit_together_True\"\n",
    "features_results.append(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP@1</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>MIUF@1</th>\n",
       "      <th>MIUF@5</th>\n",
       "      <th>MIUF@10</th>\n",
       "      <th>Serendipity@1</th>\n",
       "      <th>Serendipity@5</th>\n",
       "      <th>Serendipity@10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sasrec</th>\n",
       "      <td>0.047579</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.090322</td>\n",
       "      <td>18.824620</td>\n",
       "      <td>18.824620</td>\n",
       "      <td>18.824620</td>\n",
       "      <td>0.098168</td>\n",
       "      <td>0.059983</td>\n",
       "      <td>0.044268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_features_factors_128_fit_together_True</th>\n",
       "      <td>0.033849</td>\n",
       "      <td>0.056533</td>\n",
       "      <td>0.062486</td>\n",
       "      <td>4.339514</td>\n",
       "      <td>5.338082</td>\n",
       "      <td>6.044169</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_features_factors_128_alpha_10_reg_0.5</th>\n",
       "      <td>0.015530</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>0.032820</td>\n",
       "      <td>6.603847</td>\n",
       "      <td>6.943217</td>\n",
       "      <td>7.146507</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                MAP@1     MAP@5    MAP@10  \\\n",
       "model                                                                       \n",
       "sasrec                                       0.047579  0.081093  0.090322   \n",
       "full_features_factors_128_fit_together_True  0.033849  0.056533  0.062486   \n",
       "no_features_factors_128_alpha_10_reg_0.5     0.015530  0.028466  0.032820   \n",
       "\n",
       "                                                MIUF@1     MIUF@5    MIUF@10  \\\n",
       "model                                                                          \n",
       "sasrec                                       18.824620  18.824620  18.824620   \n",
       "full_features_factors_128_fit_together_True   4.339514   5.338082   6.044169   \n",
       "no_features_factors_128_alpha_10_reg_0.5      6.603847   6.943217   7.146507   \n",
       "\n",
       "                                             Serendipity@1  Serendipity@5  \\\n",
       "model                                                                       \n",
       "sasrec                                            0.098168       0.059983   \n",
       "full_features_factors_128_fit_together_True       0.000429       0.000460   \n",
       "no_features_factors_128_alpha_10_reg_0.5          0.001047       0.000904   \n",
       "\n",
       "                                             Serendipity@10  \n",
       "model                                                        \n",
       "sasrec                                             0.044268  \n",
       "full_features_factors_128_fit_together_True        0.000459  \n",
       "no_features_factors_128_alpha_10_reg_0.5           0.000815  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = (\n",
    "    pd.DataFrame(features_results)\n",
    "    .set_index(\"model\")\n",
    "    .sort_values(by=[\"MAP@10\", \"Serendipity@10\"], ascending=False)\n",
    ")\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
