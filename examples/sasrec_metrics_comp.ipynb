{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rectools import Columns\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from rectools.models.sasrec import save_pickle \n",
    "\n",
    "from rectools.models.sasrec import (\n",
    "    SASRecConfig,\n",
    "    SASRecProcessorConfig,\n",
    "    TrainPreprocessingConfig,\n",
    "    TrainConfig,\n",
    "    ItemModelConfig,\n",
    "    SequenceTaskConverterConfig,\n",
    "    train_sasrec_script,\n",
    "    SASRecRecommeder\n",
    ")\n",
    "\n",
    "from rectools.metrics import MAP, calc_metrics, MeanInvUserFreq, Serendipity\n",
    "from rectools.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_original.zip\n",
      "  inflating: data_original/interactions.csv  \n",
      "  inflating: __MACOSX/data_original/._interactions.csv  \n",
      "  inflating: data_original/users.csv  \n",
      "  inflating: __MACOSX/data_original/._users.csv  \n",
      "  inflating: data_original/items.csv  \n",
      "  inflating: __MACOSX/data_original/._items.csv  \n",
      "CPU times: user 241 ms, sys: 91.3 ms, total: 332 ms\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_original\")\n",
    "\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": \"datetime\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "\n",
    "# Split to train / test\n",
    "max_date = interactions[Columns.Datetime].max()\n",
    "train = interactions[interactions[Columns.Datetime] < max_date - pd.Timedelta(days=7)].copy()\n",
    "test = interactions[interactions[Columns.Datetime] >= max_date - pd.Timedelta(days=7)].copy()\n",
    "train.drop(train.query(\"total_dur < 300\").index, inplace=True)\n",
    "\n",
    "# drop items with less than 20 interactions in train\n",
    "items = train[\"item_id\"].value_counts()\n",
    "items = items[items >= 20]\n",
    "items = items.index.to_list()\n",
    "train = train[train[\"item_id\"].isin(items)]\n",
    "    \n",
    "# drop users with less than 2 interactions in train\n",
    "users = train[\"user_id\"].value_counts()\n",
    "users = users[users >= 2]\n",
    "users = users.index.to_list()\n",
    "train = train[(train[\"user_id\"].isin(users))]\n",
    "\n",
    "# leave item features for items only from train\n",
    "items = train[\"item_id\"].drop_duplicates().to_list()\n",
    "users = train[\"user_id\"].drop_duplicates().to_list()\n",
    "\n",
    "# drop cold users from test\n",
    "cold_users = set(test[Columns.User]) - set(train[Columns.User])\n",
    "test.drop(test[test[Columns.User].isin(cold_users)].index, inplace=True)\n",
    "test_users = test[Columns.User].unique().astype(str)\n",
    "\n",
    "item_features = pd.DataFrame()\n",
    "item_features[\"item_id\"] = train[\"item_id\"].copy().drop_duplicates()\n",
    "item_features[\"value\"] = \"\"\n",
    "item_features[\"feature\"] = \"tags_set\"\n",
    "\n",
    "catalog=train[Columns.Item].unique().astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.construct(\n",
    "    interactions_df=train,\n",
    "    item_features_df=item_features,\n",
    "    cat_item_features=[\"tags_set\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units=128\n",
    "session_maxlen=32\n",
    "\n",
    "\n",
    "item_model_config = ItemModelConfig(\n",
    "    name=\"idemb\",\n",
    "    hidden_units=hidden_units,\n",
    ")\n",
    "\n",
    "model_cfg = SASRecConfig(\n",
    "    maxlen=session_maxlen,\n",
    "    hidden_units=hidden_units,  # 50\n",
    "    num_blocks=2,\n",
    "    num_heads=1,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    use_sm_head=True,\n",
    "    item_model=item_model_config,\n",
    ")\n",
    "\n",
    "# TODO reused in train config\n",
    "processor_config = SASRecProcessorConfig(\n",
    "    session_maxlen=session_maxlen,\n",
    "    enable_item_features=False,  # True,\n",
    "    # item_tags_maxlen=64,\n",
    ")\n",
    "\n",
    "train_preprocessing_config = TrainPreprocessingConfig(\n",
    "    min_item_freq=20,  # 1\n",
    "    min_user_freq=2,  # 2 is minimal to generate target\n",
    "    # keep_tags_types=[\"genres_\"],\n",
    "    keep_tags_types=[],\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    l2_emb=0.0,\n",
    "    device=\"cuda:1\",\n",
    "    # device=\"cpu\",\n",
    "    negative_samples=0,\n",
    "    loss=\"sm_ce\",\n",
    "    processor_config=processor_config,\n",
    ")\n",
    "\n",
    "task_converter_config = SequenceTaskConverterConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools.models.sasrec import run_train_script\n",
    "model_dir = \"rectools/models/sasrec_test_model\"\n",
    "\n",
    "def train_sasrec(\n",
    "        dataset: Dataset,\n",
    "        processor_config: SASRecProcessorConfig,\n",
    "        model_config: SASRecConfig,\n",
    "        train_config: TrainConfig,\n",
    "        train_preprocessing_config: TrainPreprocessingConfig,\n",
    "        task_converter_config: SequenceTaskConverterConfig,\n",
    "):\n",
    "    train = dataset.get_raw_interactions()\n",
    "    train[\"user_id\"] = train[\"user_id\"].astype(str)\n",
    "    train[\"item_id\"] = train[\"item_id\"].astype(str)\n",
    "    item_features = pd.DataFrame()\n",
    "    item_features[\"item_id\"] = train[\"item_id\"].copy().drop_duplicates().astype(str)\n",
    "    item_features[\"tags_set\"] = \"\"\n",
    "    train.rename(columns={\"datetime\": \"first_intr_dt\", \"weight\": \"score\"}, inplace=True)\n",
    "\n",
    "    if task_converter_config is None:\n",
    "        task_converter_config = SequenceTaskConverterConfig() # TODO do we need it?\n",
    "\n",
    "    logger.info(\"running training script\")\n",
    "    run_train_script(\n",
    "        user_item_interactions=train,\n",
    "        item_features=item_features,\n",
    "        user_features=None,\n",
    "        processor_config=processor_config,\n",
    "        model_config=model_config,\n",
    "        train_config=train_config,\n",
    "        train_preprocessing_config=train_preprocessing_config,\n",
    "        task_converter_config=task_converter_config,\n",
    "        model_dir=model_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:running training script\n",
      "INFO:rectools.models.sasrec:testing dataset\n",
      "INFO:rectools.models.sasrec:converting datasets to task format\n",
      "INFO:rectools.models.sasrec:sessions lens: 0.95q: 24.0; 0.5q: 4.0\n",
      "INFO:rectools.models.sasrec:building preprocessor\n",
      "INFO:rectools.models.sasrec:building train dataset\n",
      "INFO:rectools.models.sasrec:building model\n",
      "INFO:rectools.models.sasrec:building trainer\n",
      "INFO:rectools.models.sasrec:used sm_ce loss\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.0.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.0.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.1.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.1.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.0.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.0.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.1.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.1.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param last_layernorm.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param last_layernorm.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:training epoch 1\n",
      "INFO:rectools.models.sasrec:training epoch 2\n",
      "INFO:rectools.models.sasrec:training epoch 3\n",
      "INFO:rectools.models.sasrec:training epoch 4\n",
      "INFO:rectools.models.sasrec:training epoch 5\n"
     ]
    }
   ],
   "source": [
    "train_sasrec(dataset, processor_config, model_cfg, train_config, train_preprocessing_config, task_converter_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = {\n",
    "    'MAP': MAP,\n",
    "    'MIUF': MeanInvUserFreq,\n",
    "    'Serendipity': Serendipity\n",
    "    \n",
    "\n",
    "}\n",
    "metrics = {}\n",
    "for metric_name, metric in metrics_name.items():\n",
    "    for k in (1, 5, 10):\n",
    "        metrics[f'{metric_name}@{k}'] = metric(k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rectools import AnyIds\n",
    "import typing as tp\n",
    "\n",
    "def recommend(\n",
    "      dataset: Dataset,\n",
    "      k: int,\n",
    "      items_to_recommend: tp.Optional[AnyIds] = None,\n",
    "):\n",
    "      train = dataset.get_raw_interactions()\n",
    "\n",
    "      train[\"user_id\"] = train[\"user_id\"].astype(str)\n",
    "      train[\"item_id\"] = train[\"item_id\"].astype(str)\n",
    "      item_features = pd.DataFrame()\n",
    "      item_features[\"item_id\"] = train[\"item_id\"].copy().drop_duplicates().astype(str)\n",
    "      item_features[\"tags_set\"] = \"\"\n",
    "      train.rename(columns={\"datetime\": \"first_intr_dt\", \"weight\": \"score\"}, inplace=True)\n",
    "\n",
    "      test[\"user_id\"] = test[\"user_id\"].astype(str)\n",
    "      test[\"item_id\"] = test[\"item_id\"].astype(str)\n",
    "\n",
    "      rec_df = train[train[\"user_id\"].isin(users)]\n",
    "      recommender = SASRecRecommeder.load(model_dir)\n",
    "\n",
    "      recs = recommender.recommend(\n",
    "            user_item_interactions=rec_df, \n",
    "            user_features=users, \n",
    "            item_features=item_features,\n",
    "            top_k=k, \n",
    "            candidate_items=items_to_recommend, \n",
    "      )\n",
    "      return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rectools.models.sasrec:filtered out 10053 candidate items which are not supported by model\n",
      "INFO:rectools.models.sasrec:sessions lens: 0.95q: 41.0; 0.5q: 7.0\n",
      "100%|██████████| 740/740 [00:08<00:00, 84.37it/s]\n",
      "100%|██████████| 94705/94705 [00:02<00:00, 31979.40it/s]\n"
     ]
    }
   ],
   "source": [
    "candidate_items = interactions['item_id'].drop_duplicates().astype(str)\n",
    "recs = recommend(test_users, dataset, k=10, items_to_recommend=candidate_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@1': 0.048131569733957345,\n",
       " 'MAP@5': 0.0821316195172286,\n",
       " 'MAP@10': 0.09132761212357746,\n",
       " 'MIUF@1': 18.824620072061013,\n",
       " 'MIUF@5': 18.824620072061013,\n",
       " 'MIUF@10': 18.824620072061013,\n",
       " 'Serendipity@1': 0.09934005596325432,\n",
       " 'Serendipity@5': 0.06045158580034103,\n",
       " 'Serendipity@10': 0.04451197076609255}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metrics(metrics, recs, test, train, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
