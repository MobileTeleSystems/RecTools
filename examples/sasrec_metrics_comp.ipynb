{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rectools import Columns\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from rectools.models import ImplicitALSWrapperModel\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from rectools.models.sasrec import (SasRecRecommenderModel)\n",
    "\n",
    "from rectools.metrics import MAP, calc_metrics, MeanInvUserFreq, Serendipity\n",
    "from rectools.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_original.zip\n",
      "  inflating: data_original/interactions.csv  \n",
      "  inflating: __MACOSX/data_original/._interactions.csv  \n",
      "  inflating: data_original/users.csv  \n",
      "  inflating: __MACOSX/data_original/._users.csv  \n",
      "  inflating: data_original/items.csv  \n",
      "  inflating: __MACOSX/data_original/._items.csv  \n",
      "CPU times: user 611 ms, sys: 142 ms, total: 752 ms\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_original\")\n",
    "\n",
    "interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": \"datetime\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[Columns.Weight] = np.where(interactions['watched_pct'] > 10, 3, 1)\n",
    "\n",
    "# Split to train / test\n",
    "max_date = interactions[Columns.Datetime].max()\n",
    "train = interactions[interactions[Columns.Datetime] < max_date - pd.Timedelta(days=7)].copy()\n",
    "test = interactions[interactions[Columns.Datetime] >= max_date - pd.Timedelta(days=7)].copy()\n",
    "train.drop(train.query(\"total_dur < 300\").index, inplace=True)\n",
    "\n",
    "# drop items with less than 20 interactions in train\n",
    "items = train[\"item_id\"].value_counts()\n",
    "items = items[items >= 20]\n",
    "items = items.index.to_list()\n",
    "train = train[train[\"item_id\"].isin(items)]\n",
    "    \n",
    "# drop users with less than 2 interactions in train\n",
    "users = train[\"user_id\"].value_counts()\n",
    "users = users[users >= 2]\n",
    "users = users.index.to_list()\n",
    "train = train[(train[\"user_id\"].isin(users))]\n",
    "\n",
    "# leave item features for items only from train\n",
    "items = train[\"item_id\"].drop_duplicates().to_list()\n",
    "users = train[\"user_id\"].drop_duplicates().to_list()\n",
    "\n",
    "# drop cold users from test\n",
    "cold_users = set(test[Columns.User]) - set(train[Columns.User])\n",
    "test.drop(test[test[Columns.User].isin(cold_users)].index, inplace=True)\n",
    "test_users = test[Columns.User].unique().astype(str)\n",
    "\n",
    "catalog=train[Columns.Item].unique().astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.construct(\n",
    "    interactions_df=train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sasrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units=128\n",
    "session_maxlen=32\n",
    "model = SasRecRecommenderModel(\n",
    "    name=\"idemb\",\n",
    "    hidden_units_item=hidden_units,\n",
    "    maxlen=session_maxlen,\n",
    "    hidden_units=hidden_units,  # 50\n",
    "    num_blocks=2,\n",
    "    num_heads=1,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    use_sm_head=True,\n",
    "    session_maxlen=session_maxlen,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    l2_emb=0.0,\n",
    "    device=\"cuda:1\",\n",
    "    # device=\"cpu\",\n",
    "    negative_samples=0,\n",
    "    loss=\"sm_ce\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rectools.models.sasrec:converting datasets to task format\n",
      "INFO:rectools.models.sasrec:sessions lens: 0.95q: 24.0; 0.5q: 4.0\n",
      "INFO:rectools.models.sasrec:building preprocessor\n",
      "INFO:rectools.models.sasrec:building train dataset\n",
      "INFO:rectools.models.sasrec:building model\n",
      "INFO:rectools.models.sasrec:building trainer\n",
      "INFO:rectools.models.sasrec:used sm_ce loss\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.0.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.0.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.1.in_proj_bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.attention_layers.1.out_proj.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.0.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.0.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.1.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layernorms.1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.0.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.0.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.1.conv1.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param encoder.forward_layers.1.conv2.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param last_layernorm.weight with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:undable to init param last_layernorm.bias with xavier: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
      "INFO:rectools.models.sasrec:training epoch 1\n",
      "INFO:rectools.models.sasrec:training epoch 2\n",
      "INFO:rectools.models.sasrec:training epoch 3\n",
      "INFO:rectools.models.sasrec:training epoch 4\n",
      "INFO:rectools.models.sasrec:training epoch 5\n"
     ]
    }
   ],
   "source": [
    "model._fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rectools.models.sasrec:filtered out 10053 candidate items which are not supported by model\n",
      "INFO:rectools.models.sasrec:sessions lens: 0.95q: 41.0; 0.5q: 7.0\n",
      "100%|██████████| 740/740 [00:09<00:00, 74.49it/s]\n",
      "100%|██████████| 94705/94705 [00:03<00:00, 27916.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# recommender = SASRecRecommeder(model.processor, model.model, model.task_converter)\n",
    "candidate_items = interactions['item_id'].drop_duplicates().astype(str)\n",
    "recs = model.recommend(dataset, 10, test_users, candidate_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = {\n",
    "    'MAP': MAP,\n",
    "    'MIUF': MeanInvUserFreq,\n",
    "    'Serendipity': Serendipity\n",
    "    \n",
    "\n",
    "}\n",
    "metrics = {}\n",
    "for metric_name, metric in metrics_name.items():\n",
    "    for k in (1, 5, 10):\n",
    "        metrics[f'{metric_name}@{k}'] = metric(k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"user_id\"] = test[\"user_id\"].astype(str)\n",
    "test[\"item_id\"] = test[\"item_id\"].astype(str)\n",
    "features_results = []\n",
    "metric_values = calc_metrics(metrics, recs, test, train, catalog)\n",
    "metric_values[\"model\"] = \"sasrec\"\n",
    "features_results.append(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MAP@1': 0.04726213852168703,\n",
       "  'MAP@5': 0.08124079823642769,\n",
       "  'MAP@10': 0.09035620127339238,\n",
       "  'MIUF@1': 18.824620072061013,\n",
       "  'MIUF@5': 18.824620072061013,\n",
       "  'MIUF@10': 18.824620072061013,\n",
       "  'Serendipity@1': 0.0981046407264664,\n",
       "  'Serendipity@5': 0.06047044537352403,\n",
       "  'Serendipity@10': 0.04435788554276184,\n",
       "  'model': 'sasrec'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "items = pd.read_csv(DATA_PATH / 'items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process user features to the form of a flatten dataframe\n",
    "users.fillna('Unknown', inplace=True)\n",
    "users = users.loc[users[Columns.User].isin(train[Columns.User])].copy()\n",
    "user_features_frames = []\n",
    "for feature in [\"sex\", \"age\", \"income\"]:\n",
    "    feature_frame = users.reindex(columns=[Columns.User, feature])\n",
    "    feature_frame.columns = [\"id\", \"value\"]\n",
    "    feature_frame[\"feature\"] = feature\n",
    "    user_features_frames.append(feature_frame)\n",
    "user_features = pd.concat(user_features_frames)\n",
    "\n",
    "# Process item features to the form of a flatten dataframe\n",
    "items = items.loc[items[Columns.Item].isin(train[Columns.Item])].copy()\n",
    "items[\"genre\"] = items[\"genres\"].str.lower().str.replace(\", \", \",\", regex=False).str.split(\",\")\n",
    "genre_feature = items[[\"item_id\", \"genre\"]].explode(\"genre\")\n",
    "genre_feature.columns = [\"id\", \"value\"]\n",
    "genre_feature[\"feature\"] = \"genre\"\n",
    "content_feature = items.reindex(columns=[Columns.Item, \"content_type\"])\n",
    "content_feature.columns = [\"id\", \"value\"]\n",
    "content_feature[\"feature\"] = \"content_type\"\n",
    "item_features = pd.concat((genre_feature, content_feature))\n",
    "\n",
    "candidate_items = interactions['item_id'].drop_duplicates().astype(int)\n",
    "test[\"user_id\"] = test[\"user_id\"].astype(int)\n",
    "test[\"item_id\"] = test[\"item_id\"].astype(int)\n",
    "catalog=train[Columns.Item].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_no_features = Dataset.construct(\n",
    "    interactions_df=train,\n",
    ")\n",
    "\n",
    "dataset_full_features = Dataset.construct(\n",
    "    interactions_df=train,\n",
    "    user_features_df=user_features,\n",
    "    cat_user_features=[\"sex\", \"age\", \"income\"],\n",
    "    item_features_df=item_features,\n",
    "    cat_item_features=[\"genre\", \"content_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RECOS = 10\n",
    "NUM_THREADS = 32\n",
    "RANDOM_STATE = 32\n",
    "ITERATIONS = 10\n",
    "\n",
    "def make_base_model(factors: int, regularization: float, alpha: float, fit_features_together: bool=False):\n",
    "    return ImplicitALSWrapperModel(\n",
    "        AlternatingLeastSquares(\n",
    "            factors=factors,\n",
    "            regularization=regularization,\n",
    "            alpha=alpha,\n",
    "            random_state=RANDOM_STATE,\n",
    "            use_gpu=False,\n",
    "            num_threads = NUM_THREADS,\n",
    "            iterations=ITERATIONS),\n",
    "        fit_features_together = fit_features_together,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maspirina1/Tasks/RecTools/.venv/lib/python3.8/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 64 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "n_factors = 128\n",
    "regularization = 0.5\n",
    "alpha = 10\n",
    "\n",
    "model = make_base_model(factors=n_factors, regularization=regularization, alpha=alpha)\n",
    "model.fit(dataset_no_features)\n",
    "recos = model.recommend(\n",
    "    users=test_users.astype(int),\n",
    "    dataset=dataset_no_features,\n",
    "    k=K_RECOS,\n",
    "    filter_viewed=True,\n",
    ")\n",
    "metric_values = calc_metrics(metrics, recos, test, train, catalog)\n",
    "metric_values[\"model\"] = \"no_features_factors_128_alpha_10_reg_0.5\"\n",
    "features_results.append(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/maspirina1/Tasks/RecTools/rectools/dataset/features.py:424: UserWarning: Converting sparse features to dense array may cause MemoryError\n",
      "  warnings.warn(\"Converting sparse features to dense array may cause MemoryError\")\n"
     ]
    }
   ],
   "source": [
    "model = make_base_model(factors = n_factors, regularization=regularization, alpha=alpha, fit_features_together=True)\n",
    "model.fit(dataset_full_features)\n",
    "recos = model.recommend(\n",
    "    users=test_users.astype(int),\n",
    "    dataset=dataset_full_features,\n",
    "    k=K_RECOS,\n",
    "    filter_viewed=True,\n",
    ")\n",
    "metric_values = calc_metrics(metrics, recos, test, train, catalog)\n",
    "metric_values[\"model\"] = \"full_features_factors_128_fit_together_True\"\n",
    "features_results.append(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP@1</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>MIUF@1</th>\n",
       "      <th>MIUF@5</th>\n",
       "      <th>MIUF@10</th>\n",
       "      <th>Serendipity@1</th>\n",
       "      <th>Serendipity@5</th>\n",
       "      <th>Serendipity@10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sasrec</th>\n",
       "      <td>0.047262</td>\n",
       "      <td>0.081241</td>\n",
       "      <td>0.090356</td>\n",
       "      <td>18.824620</td>\n",
       "      <td>18.824620</td>\n",
       "      <td>18.824620</td>\n",
       "      <td>0.098105</td>\n",
       "      <td>0.060470</td>\n",
       "      <td>0.044358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_features_factors_128_fit_together_True</th>\n",
       "      <td>0.033849</td>\n",
       "      <td>0.056533</td>\n",
       "      <td>0.062486</td>\n",
       "      <td>4.339514</td>\n",
       "      <td>5.338082</td>\n",
       "      <td>6.044169</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_features_factors_128_alpha_10_reg_0.5</th>\n",
       "      <td>0.015530</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>0.032820</td>\n",
       "      <td>6.603847</td>\n",
       "      <td>6.943217</td>\n",
       "      <td>7.146507</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                MAP@1     MAP@5    MAP@10  \\\n",
       "model                                                                       \n",
       "sasrec                                       0.047262  0.081241  0.090356   \n",
       "full_features_factors_128_fit_together_True  0.033849  0.056533  0.062486   \n",
       "no_features_factors_128_alpha_10_reg_0.5     0.015530  0.028466  0.032820   \n",
       "\n",
       "                                                MIUF@1     MIUF@5    MIUF@10  \\\n",
       "model                                                                          \n",
       "sasrec                                       18.824620  18.824620  18.824620   \n",
       "full_features_factors_128_fit_together_True   4.339514   5.338082   6.044169   \n",
       "no_features_factors_128_alpha_10_reg_0.5      6.603847   6.943217   7.146507   \n",
       "\n",
       "                                             Serendipity@1  Serendipity@5  \\\n",
       "model                                                                       \n",
       "sasrec                                            0.098105       0.060470   \n",
       "full_features_factors_128_fit_together_True       0.000429       0.000460   \n",
       "no_features_factors_128_alpha_10_reg_0.5          0.001047       0.000904   \n",
       "\n",
       "                                             Serendipity@10  \n",
       "model                                                        \n",
       "sasrec                                             0.044358  \n",
       "full_features_factors_128_fit_together_True        0.000459  \n",
       "no_features_factors_128_alpha_10_reg_0.5           0.000815  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = (\n",
    "    pd.DataFrame(features_results)\n",
    "    .set_index(\"model\")\n",
    "    .sort_values(by=[\"MAP@10\", \"Serendipity@10\"], ascending=False)\n",
    ")\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
