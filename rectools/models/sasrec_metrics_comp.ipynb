{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rectools import Columns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from rectools.models.sasrec import load_pickle, save_pickle \n",
    "\n",
    "from rectools.models.sasrec import (\n",
    "    SASRecConfig,\n",
    "    SASRecProcessorConfig,\n",
    "    TrainPreprocessingConfig,\n",
    "    TrainConfig,\n",
    "    ItemModelConfig,\n",
    "    SequenceTaskConverterConfig,\n",
    "    TargetTransform,\n",
    "    train_sasrec_script,\n",
    "    run_test_sasrec_script,\n",
    "    SASRecRecommeder\n",
    ")\n",
    "from datetime import date, timedelta\n",
    "from rectools.metrics import MAP, calc_metrics, MeanInvUserFreq, Serendipity\n",
    "from rectools.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_original.zip\n",
      "  inflating: data_original/interactions.csv  \n",
      "  inflating: __MACOSX/data_original/._interactions.csv  \n",
      "  inflating: data_original/users.csv  \n",
      "  inflating: __MACOSX/data_original/._users.csv  \n",
      "  inflating: data_original/items.csv  \n",
      "  inflating: __MACOSX/data_original/._items.csv  \n",
      "CPU times: user 400 ms, sys: 131 ms, total: 532 ms\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget -q https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip -O data_original.zip\n",
    "!unzip -o data_original.zip\n",
    "!rm data_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data_original\")\n",
    "\n",
    "user_features = pd.read_csv(DATA_PATH / 'users.csv')\n",
    "item_features = pd.read_csv(DATA_PATH / 'items.csv')\n",
    "user_item_interactions = (\n",
    "    pd.read_csv(DATA_PATH / 'interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={\"last_watch_dt\": \"first_intr_dt\", \"total_dur\": \"score\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features[\"user_id\"] = user_features[\"user_id\"].astype(str)\n",
    "item_features[\"item_id\"] = item_features[\"item_id\"].astype(str)\n",
    "user_item_interactions[\"user_id\"] = user_item_interactions[\"user_id\"].astype(str)\n",
    "user_item_interactions[\"item_id\"] = user_item_interactions[\"item_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = user_item_interactions.copy()\n",
    "# intr = user_item_interactions\n",
    "# test_ratio = 0.1\n",
    "# SPLIT_KEY = \"user_id\"\n",
    "# x_min_score = 0\n",
    "# y_pos_watch_seconds_th = 300\n",
    "\n",
    "# train_ds_path = \"rectools/models/train_interactions_splitted_wtg.pkl\"\n",
    "# test_ds_path=\"rectools/models/test_interactions_splitted_wtg.pkl\"\n",
    "\n",
    "\n",
    "# assert 0 <= test_ratio <= 1\n",
    "\n",
    "# users = df[SPLIT_KEY].unique()\n",
    "# test_users_cnt = int(len(users) * test_ratio)\n",
    "\n",
    "# users = np.random.permutation(users)\n",
    "# test_users, train_users = users[:test_users_cnt], users[test_users_cnt:]\n",
    "\n",
    "# train_df = df[df[SPLIT_KEY].isin(train_users)]\n",
    "# test_df = df[df[SPLIT_KEY].isin(test_users)]\n",
    "\n",
    "# train_intr = train_df\n",
    "# test_intr = test_df\n",
    "# assert train_intr[\"user_id\"].isin(test_intr[\"user_id\"]).any() == False\n",
    "\n",
    "# train_item_candidates = train_intr[\"item_id\"].drop_duplicates().to_list()\n",
    "# test_item_candidates = intr[\"item_id\"].drop_duplicates().to_list()\n",
    "\n",
    "# max_date = user_item_interactions[\"first_intr_dt\"].max()\n",
    "# test_start_date = max_date - pd.Timedelta(days=7)\n",
    "\n",
    "# train_intr_x = train_intr[train_intr[\"first_intr_dt\"].dt.date < test_start_date]\n",
    "# test_intr_x = test_intr[test_intr[\"first_intr_dt\"].dt.date < test_start_date]\n",
    "\n",
    "# train_intr_y = train_intr[train_intr[\"first_intr_dt\"].dt.date >= test_start_date]\n",
    "# test_intr_y = test_intr[test_intr[\"first_intr_dt\"].dt.date >= test_start_date]\n",
    "\n",
    "# # remove users from y part which did not appeare in x part\n",
    "# train_intr_y = train_intr_y[train_intr_y[\"user_id\"].isin(train_intr_x[\"user_id\"])]\n",
    "# test_intr_y = test_intr_y[test_intr_y[\"user_id\"].isin(test_intr_x[\"user_id\"])]\n",
    "\n",
    "\n",
    "# x_target_transform=TargetTransform.THRESHOLD\n",
    "\n",
    "# train_intr_x = train_intr_x[train_intr_x[\"score\"] > x_min_score]\n",
    "# test_intr_x = test_intr_x[test_intr_x[\"score\"] > x_min_score]\n",
    "\n",
    "# train_intr_y = train_intr_y[train_intr_y[\"score\"] > y_pos_watch_seconds_th]\n",
    "# test_intr_y = test_intr_y[test_intr_y[\"score\"] > y_pos_watch_seconds_th]\n",
    "\n",
    "# train_ds = (train_intr_x, train_intr_y, train_item_candidates)\n",
    "# test_ds = (test_intr_x, test_intr_y, test_item_candidates)\n",
    "\n",
    "# save_pickle(train_ds, train_ds_path)\n",
    "# save_pickle(test_ds, test_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_path = \"rectools/models/train_interactions_splitted_wtg.pkl\"\n",
    "test_ds_path=\"rectools/models/test_interactions_splitted_wtg.pkl\"\n",
    "\n",
    "user_item_interactions[Columns.Weight] = np.where(user_item_interactions['watched_pct'] > 10, 3, 1)\n",
    "\n",
    "# Split to train / test\n",
    "max_date = user_item_interactions[\"first_intr_dt\"].max()\n",
    "train_df = user_item_interactions[user_item_interactions[\"first_intr_dt\"] < max_date - pd.Timedelta(days=7)].copy()\n",
    "test_df = user_item_interactions[user_item_interactions[\"first_intr_dt\"] >= max_date - pd.Timedelta(days=7)].copy()\n",
    "train_df.drop(train_df.query(\"score < 300\").index, inplace=True)\n",
    "\n",
    "# drop items with less than 20 interactions in train\n",
    "items = train_df['item_id'].value_counts()\n",
    "items = items[items >= 20]\n",
    "items = items.index.to_list()\n",
    "train_df = train_df[train_df['item_id'].isin(items)]\n",
    "    \n",
    "# drop users with less than 2 interactions in train\n",
    "users = train_df['user_id'].value_counts()\n",
    "users = users[users >= 2]\n",
    "users = users.index.to_list()\n",
    "train_df = train_df[(train_df['user_id'].isin(users)) & (train_df['item_id'].isin(items))]\n",
    "\n",
    "# drop cold users from test\n",
    "cold_users = set(test_df[Columns.User]) - set(train_df[Columns.User])\n",
    "test_df.drop(test_df[test_df[Columns.User].isin(cold_users)].index, inplace=True)\n",
    "test_users = test_df[Columns.User].unique()\n",
    "\n",
    "cold_items = set(test_df[Columns.Item]) - set(train_df[Columns.Item])\n",
    "test_df.drop(test_df[test_df[Columns.Item].isin(cold_items)].index, inplace=True)\n",
    "\n",
    "item_features = item_features.loc[item_features[Columns.Item].isin(train_df[Columns.Item])].copy()\n",
    "\n",
    "train_ds = (train_df, pd.DataFrame(), pd.DataFrame())\n",
    "test_ds = (test_df, pd.DataFrame(), pd.DataFrame())\n",
    "\n",
    "save_pickle(train_ds, train_ds_path)\n",
    "save_pickle(test_ds, test_ds_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"rectools/models/kion_pers_recs_item_features_test.parquet\"\n",
    "item_features[\"tags_set\"] = ''\n",
    "item_features = item_features[['item_id', 'tags_set']].copy().drop_duplicates()\n",
    "os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "item_features.to_parquet(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units=128\n",
    "session_maxlen=32\n",
    "\n",
    "\n",
    "item_model_config = ItemModelConfig(\n",
    "    name=\"idemb\",\n",
    "    hidden_units=hidden_units,\n",
    ")\n",
    "\n",
    "model_cfg = SASRecConfig(\n",
    "    maxlen=session_maxlen,\n",
    "    hidden_units=hidden_units,  # 50\n",
    "    num_blocks=2,\n",
    "    num_heads=1,\n",
    "    dropout_rate=0.2,\n",
    "    use_pos_emb=True,\n",
    "    use_sm_head=True,\n",
    "    item_model=item_model_config,\n",
    ")\n",
    "\n",
    "# TODO reused in train config\n",
    "processor_config = SASRecProcessorConfig(\n",
    "    session_maxlen=session_maxlen,\n",
    "    enable_item_features=False,  # True,\n",
    "    # item_tags_maxlen=64,\n",
    ")\n",
    "\n",
    "train_preprocessing_config = TrainPreprocessingConfig(\n",
    "    min_item_freq=20,  # 1\n",
    "    min_user_freq=2,  # 2 is minimal to generate target\n",
    "    # keep_tags_types=[\"genres_\"],\n",
    "    keep_tags_types=[],\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    l2_emb=0.0,\n",
    "    device=\"cuda:1\",\n",
    "    # device=\"cpu\",\n",
    "    negative_samples=0,\n",
    "    loss=\"sm_ce\",\n",
    "    processor_config=processor_config,\n",
    ")\n",
    "\n",
    "task_converter_config = SequenceTaskConverterConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"rectools/models/sasrec_test_model\"\n",
    "\n",
    "train_sasrec_script(\n",
    "    train_ds_path=\"rectools/models/train_interactions_splitted_wtg.pkl\",\n",
    "    item_features_path=\"rectools/models/kion_pers_recs_item_features_test.parquet\",\n",
    "    model_dir=model_dir,\n",
    "    processor_config=processor_config,\n",
    "    model_config=model_cfg,\n",
    "    train_config=train_config,\n",
    "    train_preprocessing_config=train_preprocessing_config,\n",
    "    task_converter_config=task_converter_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = {\n",
    "    'MAP': MAP,\n",
    "    'MIUF': MeanInvUserFreq,\n",
    "    'Serendipity': Serendipity\n",
    "    \n",
    "\n",
    "}\n",
    "metrics = {}\n",
    "for metric_name, metric in metrics_name.items():\n",
    "    for k in (1, 5, 10):\n",
    "        metrics[f'{metric_name}@{k}'] = metric(k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = train_df[train_df['user_id'].isin(np.unique(test_df['user_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:10<00:00, 71.63it/s]\n",
      "100%|██████████| 93516/93516 [00:02<00:00, 34247.56it/s]\n"
     ]
    }
   ],
   "source": [
    "recommender = SASRecRecommeder.load(model_dir)\n",
    "x = rec_df\n",
    "y = test_df\n",
    "candidate_items = item_features['item_id']\n",
    "\n",
    "pred_top_k = 10\n",
    "recs = recommender.recommend(\n",
    "    user_item_interactions=x, \n",
    "    user_features=user_features, \n",
    "    item_features=item_features,\n",
    "    top_k=pred_top_k, \n",
    "    candidate_items=candidate_items, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP@1': 0.041042036775140275,\n",
       " 'MAP@5': 0.0667955345783929,\n",
       " 'MAP@10': 0.07467896800535924,\n",
       " 'MIUF@1': 3.3346319783960356,\n",
       " 'MIUF@5': 4.735062167926775,\n",
       " 'MIUF@10': 5.132194375143549,\n",
       " 'Serendipity@1': 0.0003361417990098743,\n",
       " 'Serendipity@5': 0.0002930853827333228,\n",
       " 'Serendipity@10': 0.000272484260108242}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog=train_df[Columns.Item].unique().astype(str)\n",
    "calc_metrics(metrics, recs, test_df, train_df, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_test_sasrec_script(\n",
    "#     ds_path=\"rectools/models/train_interactions_splitted_wtg.pkl\",\n",
    "#     label=\"train\",\n",
    "#     item_features_path=\"rectools/models/kion_pers_recs_item_features_test.parquet\",\n",
    "#     model_path=\"rectools/models/sasrec_test_model\",\n",
    "#     #genres_test_ds_path=\"data/processed/genres_dataset.parquet\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_test_sasrec_script(\n",
    "#     ds_path=\"rectools/models/test_interactions_splitted_wtg.pkl\",\n",
    "#     label=\"test\",\n",
    "#     item_features_path=\"rectools/models/kion_pers_recs_item_features_test.parquet\",\n",
    "#     model_path=\"rectools/models/sasrec_test_model\",\n",
    "#     #genres_test_ds_path=\"data/processed/genres_dataset.parquet\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"rectools/models/sasrec_test_model/artifacts/test/metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"rectools/models/sasrec_test_model/artifacts/train/metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
